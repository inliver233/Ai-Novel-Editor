#!/usr/bin/env python3
"""
2025å¹´APIä¿®å¤éªŒè¯æµ‹è¯• - ç®€åŒ–ç‰ˆæœ¬
æ— éœ€å¤–éƒ¨ä¾èµ–çš„æ ¸å¿ƒåŠŸèƒ½éªŒè¯
"""

import sys
from pathlib import Path
import json

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

# æ¨¡æ‹Ÿå¿…è¦çš„ç±»å‹
class MockToolDefinition:
    def __init__(self, name, description, parameters):
        self.name = name
        self.description = description
        self.parameters = parameters
    
    def to_claude_format(self):
        return {
            "name": self.name,
            "description": self.description,
            "input_schema": {
                "type": "object",
                "properties": {p["name"]: {"type": p["type"]} for p in self.parameters},
                "required": [p["name"] for p in self.parameters if p.get("required", False)]
            }
        }

try:
    from core.ai_client import AIConfig, AIProvider
    print("âœ… æˆåŠŸå¯¼å…¥AIé…ç½®æ¨¡å—")
except ImportError as e:
    print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
    sys.exit(1)


# ç®€åŒ–ç‰ˆçš„AIClientç”¨äºæµ‹è¯•
class TestAIClient:
    def __init__(self, config):
        self.config = config
    
    def _is_reasoning_model(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜¯reasoning model"""
        reasoning_models = ['o1', 'o3', 'o4-mini', 'o1-mini', 'o1-preview', 'o3-mini', 'o4']
        model_name = self.config.model.lower()
        return any(rm in model_name for rm in reasoning_models)
    
    def _is_thinking_model(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜¯æ”¯æŒæ€è€ƒæ¨¡å¼çš„Geminiæ¨¡å‹"""
        if self.config.provider != AIProvider.GEMINI:
            return False
        
        thinking_models = [
            'gemini-2.5-pro', 'gemini-2.5-flash', 'gemini-2.5-flash-lite',
            'gemini-2.0-flash-thinking'
        ]
        model_name = self.config.model.lower()
        return any(tm in model_name for tm in thinking_models)
    
    def _build_request_data(self, messages, stream=False, **kwargs):
        """ç®€åŒ–ç‰ˆçš„è¯·æ±‚æ„å»º"""
        data = {
            "model": self.config.model,
            "stream": stream
        }
        
        is_reasoning_model = self._is_reasoning_model()
        
        if self.config.provider == AIProvider.CLAUDE:
            data["messages"] = messages
            data["max_tokens"] = self.config.max_tokens
            data["temperature"] = self.config.temperature
            
        elif self.config.provider == AIProvider.GEMINI:
            contents = []
            generation_config = {
                "temperature": self.config.temperature,
                "maxOutputTokens": self.config.max_tokens,
                "topP": self.config.top_p
            }
            
            # æ€è€ƒæ¨¡å¼é…ç½®
            if self._is_thinking_model():
                thinking_config = {}
                
                include_thoughts = kwargs.get("include_thoughts", kwargs.get("includeThoughts", False))
                if include_thoughts:
                    thinking_config["includeThoughts"] = True
                
                thinking_budget = kwargs.get("thinking_budget", kwargs.get("thinkingBudget"))
                if thinking_budget is not None:
                    thinking_config["thinkingBudget"] = thinking_budget
                elif include_thoughts:
                    thinking_config["thinkingBudget"] = 1024
                
                if thinking_config:
                    generation_config["thinkingConfig"] = thinking_config
            
            for msg in messages:
                gemini_role = "model" if msg["role"] == "assistant" else msg["role"]
                contents.append({
                    "role": gemini_role,
                    "parts": [{"text": msg["content"]}]
                })
            
            data = {
                "contents": contents,
                "generationConfig": generation_config
            }
            
        elif self.config.provider == AIProvider.OLLAMA:
            data["messages"] = messages
            data["max_tokens"] = self.config.max_tokens
            data["temperature"] = self.config.temperature
            data["top_p"] = self.config.top_p
            
            # Ollamaç‰¹æœ‰å‚æ•°
            ollama_options = {}
            for param in ["num_ctx", "num_predict", "repeat_penalty", "top_k", "seed"]:
                if param in kwargs:
                    ollama_options[param] = kwargs[param]
            
            if ollama_options:
                data["options"] = ollama_options
                
        elif is_reasoning_model:
            data["messages"] = messages
            data["max_completion_tokens"] = self.config.max_tokens
            
            if "reasoning_effort" in kwargs:
                data["reasoning_effort"] = kwargs["reasoning_effort"]
            elif hasattr(self.config, 'reasoning_effort'):
                data["reasoning_effort"] = getattr(self.config, 'reasoning_effort', 'medium')
                
        else:
            # æ ‡å‡†OpenAIæ ¼å¼
            data["messages"] = messages
            data["max_tokens"] = self.config.max_tokens
            data["temperature"] = self.config.temperature
            data["top_p"] = self.config.top_p
        
        # å¤„ç†é¢å¤–å‚æ•°ï¼Œæ’é™¤å®¢æˆ·ç«¯ä¸“ç”¨å‚æ•°
        for key, value in kwargs.items():
            if self.config.provider == AIProvider.GEMINI and key == "max_tokens":
                if "generationConfig" in data:
                    data["generationConfig"]["maxOutputTokens"] = value
                continue
            elif key == "max_tokens" and is_reasoning_model:
                data["max_completion_tokens"] = value
            elif key not in ["max_tokens", "temperature", "top_p", "timeout", "max_retries", 
                           "disable_ssl_verify", "num_ctx", "num_predict", "repeat_penalty", 
                           "top_k", "seed", "include_thoughts", "includeThoughts", 
                           "thinking_budget", "thinkingBudget", "reasoning_effort"]:
                data[key] = value
        
        return data
    
    def _get_headers(self):
        """è·å–è¯·æ±‚å¤´"""
        headers = {'Content-Type': 'application/json'}
        
        if self.config.provider == AIProvider.OPENAI:
            headers['Authorization'] = f'Bearer {self.config.api_key}'
        elif self.config.provider == AIProvider.CLAUDE:
            headers['x-api-key'] = self.config.api_key
        elif self.config.provider == AIProvider.GEMINI:
            headers['x-goog-api-key'] = self.config.api_key
        elif self.config.provider == AIProvider.OLLAMA:
            pass  # ä¸éœ€è¦è®¤è¯
        
        return headers


def test_openai_reasoning_models():
    """æµ‹è¯•OpenAIæ¨ç†æ¨¡å‹"""
    print("\nğŸ§ª æµ‹è¯•OpenAIæ¨ç†æ¨¡å‹...")
    
    config = AIConfig(
        provider=AIProvider.OPENAI,
        model="o3-mini",
        reasoning_effort="high"
    )
    
    client = TestAIClient(config)
    
    # éªŒè¯æ¨¡å‹è¯†åˆ«
    if not client._is_reasoning_model():
        print("    âŒ o3-mini æ²¡æœ‰è¢«è¯†åˆ«ä¸ºæ¨ç†æ¨¡å‹")
        return False
    
    # æµ‹è¯•è¯·æ±‚æ„å»º
    messages = [{"role": "user", "content": "Test"}]
    data = client._build_request_data(messages, max_tokens=500, reasoning_effort="medium")
    
    if "max_completion_tokens" not in data:
        print("    âŒ ç¼ºå°‘max_completion_tokens")
        return False
    
    if "temperature" in data:
        print("    âŒ æ¨ç†æ¨¡å‹ä¸åº”è¯¥æœ‰temperature")
        return False
    
    if data.get("reasoning_effort") != "medium":
        print(f"    âŒ reasoning_efforté”™è¯¯: {data.get('reasoning_effort')}")
        return False
    
    print("    âœ… OpenAIæ¨ç†æ¨¡å‹å‚æ•°æ­£ç¡®")
    return True


def test_gemini_thinking_mode():
    """æµ‹è¯•Geminiæ€è€ƒæ¨¡å¼"""
    print("\nğŸ§ª æµ‹è¯•Geminiæ€è€ƒæ¨¡å¼...")
    
    config = AIConfig(
        provider=AIProvider.GEMINI,
        model="gemini-2.5-pro"
    )
    
    client = TestAIClient(config)
    
    # éªŒè¯æ€è€ƒæ¨¡å‹è¯†åˆ«
    if not client._is_thinking_model():
        print("    âŒ gemini-2.5-pro æ²¡æœ‰è¢«è¯†åˆ«ä¸ºæ€è€ƒæ¨¡å‹")
        return False
    
    # æµ‹è¯•æ€è€ƒé…ç½®
    messages = [{"role": "user", "content": "Think"}]
    data = client._build_request_data(
        messages, 
        include_thoughts=True,
        thinking_budget=2048
    )
    
    if "generationConfig" not in data:
        print("    âŒ ç¼ºå°‘generationConfig")
        return False
    
    thinking_config = data["generationConfig"].get("thinkingConfig", {})
    
    if not thinking_config.get("includeThoughts"):
        print("    âŒ includeThoughtsæœªè®¾ç½®")
        return False
    
    if thinking_config.get("thinkingBudget") != 2048:
        print(f"    âŒ thinkingBudgeté”™è¯¯: {thinking_config.get('thinkingBudget')}")
        return False
    
    print("    âœ… Geminiæ€è€ƒæ¨¡å¼é…ç½®æ­£ç¡®")
    return True


def test_claude_format():
    """æµ‹è¯•Claudeæ ¼å¼"""
    print("\nğŸ§ª æµ‹è¯•Claudeæ ¼å¼...")
    
    config = AIConfig(
        provider=AIProvider.CLAUDE,
        model="claude-3-5-sonnet-20241022"
    )
    
    client = TestAIClient(config)
    
    # æµ‹è¯•å·¥å…·æ ¼å¼
    tool = MockToolDefinition(
        name="get_weather",
        description="è·å–å¤©æ°”",
        parameters=[{"name": "location", "type": "string", "required": True}]
    )
    
    claude_format = tool.to_claude_format()
    
    if "input_schema" not in claude_format:
        print("    âŒ Claudeå·¥å…·æ ¼å¼ç¼ºå°‘input_schema")
        return False
    
    if "parameters" in claude_format:
        print("    âŒ Claudeå·¥å…·æ ¼å¼ä¸åº”è¯¥æœ‰parameterså­—æ®µ")
        return False
    
    print("    âœ… Claudeå·¥å…·æ ¼å¼æ­£ç¡®")
    return True


def test_ollama_integration():
    """æµ‹è¯•Ollamaé›†æˆ"""
    print("\nğŸ§ª æµ‹è¯•Ollamaé›†æˆ...")
    
    config = AIConfig(
        provider=AIProvider.OLLAMA,
        model="llama3.1:8b"
    )
    
    client = TestAIClient(config)
    
    # æµ‹è¯•å¤´éƒ¨ï¼ˆä¸åº”è¯¥æœ‰è®¤è¯ï¼‰
    headers = client._get_headers()
    
    if "Authorization" in headers or "x-api-key" in headers:
        print("    âŒ Ollamaä¸åº”è¯¥æœ‰è®¤è¯å¤´")
        return False
    
    # æµ‹è¯•ç‰¹æœ‰å‚æ•°
    messages = [{"role": "user", "content": "Test"}]
    data = client._build_request_data(
        messages,
        num_ctx=4096,
        num_predict=512,
        repeat_penalty=1.1
    )
    
    if "options" not in data:
        print("    âŒ ç¼ºå°‘optionså‚æ•°")
        return False
    
    options = data["options"]
    if options.get("num_ctx") != 4096:
        print(f"    âŒ num_ctxé”™è¯¯: {options.get('num_ctx')}")
        return False
    
    print("    âœ… Ollamaé›†æˆæ­£ç¡®")
    return True


def test_config_serialization():
    """æµ‹è¯•é…ç½®åºåˆ—åŒ–"""
    print("\nğŸ§ª æµ‹è¯•é…ç½®åºåˆ—åŒ–...")
    
    config = AIConfig(
        provider=AIProvider.OPENAI,
        model="o3-mini",
        reasoning_effort="high"
    )
    
    # æµ‹è¯•åºåˆ—åŒ–
    data = config.to_dict()
    
    if "reasoning_effort" not in data:
        print("    âŒ åºåˆ—åŒ–ç¼ºå°‘reasoning_effort")
        return False
    
    # æµ‹è¯•ååºåˆ—åŒ–
    restored = AIConfig.from_dict(data)
    
    if restored.reasoning_effort != "high":
        print("    âŒ ååºåˆ—åŒ–reasoning_efforté”™è¯¯")
        return False
    
    print("    âœ… é…ç½®åºåˆ—åŒ–æ­£ç¡®")
    return True


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹APIä¿®å¤éªŒè¯æµ‹è¯•...")
    
    tests = [
        test_openai_reasoning_models,
        test_gemini_thinking_mode,
        test_claude_format,
        test_ollama_integration,
        test_config_serialization
    ]
    
    passed = 0
    failed = 0
    
    for test in tests:
        try:
            if test():
                passed += 1
            else:
                failed += 1
        except Exception as e:
            print(f"âŒ {test.__name__} å¼‚å¸¸: {e}")
            failed += 1
    
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
    print(f"âœ… é€šè¿‡: {passed}")
    print(f"âŒ å¤±è´¥: {failed}")
    
    if failed == 0:
        print("\nğŸ‰ æ‰€æœ‰æ ¸å¿ƒä¿®å¤éªŒè¯é€šè¿‡!")
        print("\nğŸ”§ 2025å¹´APIä¿®å¤æ€»ç»“:")
        print("  âœ¨ OpenAIæ¨ç†æ¨¡å‹: max_completion_tokens, reasoning_effortæ”¯æŒ")
        print("  âœ¨ Geminiæ€è€ƒæ¨¡å¼: æ­£ç¡®çš„thinkingConfigæ ¼å¼")
        print("  âœ¨ Claudeå·¥å…·è°ƒç”¨: input_schemaæ ¼å¼")
        print("  âœ¨ Ollamaé›†æˆ: æ— éœ€è®¤è¯, ç‰¹æœ‰å‚æ•°æ”¯æŒ")
        print("  âœ¨ é…ç½®å…¼å®¹æ€§: æ–°å‚æ•°åºåˆ—åŒ–æ”¯æŒ")
        
        print("\nğŸ“‹ æ–°å¢APIç‰¹æ€§æ”¯æŒ:")
        print("  ğŸ”¹ OpenAI o1/o3/o4ç³»åˆ—æ¨ç†æ¨¡å‹")
        print("  ğŸ”¹ Gemini 2.5æ€è€ƒæ¨¡å¼é…ç½®")
        print("  ğŸ”¹ Claudeæœ€æ–°å·¥å…·è°ƒç”¨æ ¼å¼")
        print("  ğŸ”¹ Ollamaæœ¬åœ°éƒ¨ç½²ä¼˜åŒ–")
        
        return True
    else:
        print(f"\nâš ï¸ {failed}ä¸ªæµ‹è¯•å¤±è´¥")
        return False


if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1)