#!/usr/bin/env python3
"""
æµ‹è¯•åŸç”ŸAPIæ ¼å¼æ”¯æŒ - Geminiå’ŒOllama
éªŒè¯æ–°æ·»åŠ çš„åŸç”ŸAPIæä¾›å•†æ”¯æŒæ˜¯å¦æ­£ç¡®å®ç°
"""

import json
from typing import Dict, Any

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

try:
    from core.ai_client import AIConfig, AIProvider, AIClient
    from core.tool_types import ToolDefinition, ToolParameter, ToolPermission
except ImportError as e:
    print(f"å¯¼å…¥é”™è¯¯: {e}")
    print("è¯·ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œæ­¤æµ‹è¯•")
    sys.exit(1)


class TestNativeAPISupport:
    """æµ‹è¯•åŸç”ŸAPIæ ¼å¼æ”¯æŒ"""
    
    def setup_method(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.gemini_config = AIConfig(
            provider=AIProvider.GEMINI,
            model="gemini-1.5-pro",
            max_tokens=1000,
            temperature=0.7
        )
        
        self.ollama_config = AIConfig(
            provider=AIProvider.OLLAMA,
            model="llama3.1:8b",
            max_tokens=1000,
            temperature=0.7
        )
    
    def test_provider_enum_extended(self):
        """æµ‹è¯•AIProvideræšä¸¾æ˜¯å¦æ­£ç¡®æ‰©å±•"""
        # éªŒè¯æ–°å¢çš„æä¾›å•†
        assert AIProvider.GEMINI.value == "gemini"
        assert AIProvider.OLLAMA.value == "ollama"
        
        # éªŒè¯æ‰€æœ‰æä¾›å•†
        expected_providers = {"openai", "claude", "gemini", "ollama", "custom"}
        actual_providers = {p.value for p in AIProvider}
        assert actual_providers == expected_providers
    
    def test_gemini_headers(self):
        """æµ‹è¯•Geminiè®¤è¯å¤´è®¾ç½®"""
        self.gemini_config.set_api_key("test-gemini-key")
        
        with patch('core.ai_client.get_secure_key_manager') as mock_key_manager:
            mock_manager = Mock()
            mock_manager.retrieve_api_key.return_value = "test-gemini-key"
            mock_key_manager.return_value = mock_manager
            
            client = AIClient(self.gemini_config)
            headers = client._get_headers()
            
            # éªŒè¯Geminiè®¤è¯å¤´
            assert headers['x-goog-api-key'] == "test-gemini-key"
            assert 'Authorization' not in headers
            assert headers['Content-Type'] == 'application/json'
    
    def test_ollama_headers(self):
        """æµ‹è¯•Ollamaè®¤è¯å¤´è®¾ç½®"""
        client = AIClient(self.ollama_config)
        headers = client._get_headers()
        
        # Ollamaæœ¬åœ°APIä¸éœ€è¦è®¤è¯
        assert 'Authorization' not in headers
        assert 'x-api-key' not in headers
        assert 'x-goog-api-key' not in headers
        assert headers['Content-Type'] == 'application/json'
    
    def test_gemini_endpoint_url(self):
        """æµ‹è¯•Geminiç«¯ç‚¹URLç”Ÿæˆ"""
        client = AIClient(self.gemini_config)
        endpoint = client._get_endpoint_url()
        
        expected = f"https://generativelanguage.googleapis.com/v1beta/models/{self.gemini_config.model}:generateContent"
        assert endpoint == expected
    
    def test_ollama_endpoint_url(self):
        """æµ‹è¯•Ollamaç«¯ç‚¹URLç”Ÿæˆ"""
        client = AIClient(self.ollama_config)
        endpoint = client._get_endpoint_url()
        
        # é»˜è®¤æœ¬åœ°ç«¯ç‚¹
        assert endpoint == "http://localhost:11434/v1/chat/completions"
        
        # è‡ªå®šä¹‰ç«¯ç‚¹
        custom_config = AIConfig(
            provider=AIProvider.OLLAMA,
            model="llama3.1:8b",
            endpoint_url="http://192.168.1.100:11434"
        )
        custom_client = AIClient(custom_config)
        custom_endpoint = custom_client._get_endpoint_url()
        assert custom_endpoint == "http://192.168.1.100:11434/v1/chat/completions"
    
    def test_gemini_request_format(self):
        """æµ‹è¯•Geminiè¯·æ±‚æ ¼å¼"""
        client = AIClient(self.gemini_config)
        
        messages = [
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": "Hello, how are you?"}
        ]
        
        request_data = client._build_request_data(messages, stream=False)
        
        # éªŒè¯Geminiè¯·æ±‚æ ¼å¼
        assert "contents" in request_data
        assert "generationConfig" in request_data
        assert "model" not in request_data  # Geminiåœ¨URLä¸­æŒ‡å®šæ¨¡å‹
        
        # éªŒè¯generation config
        gen_config = request_data["generationConfig"]
        assert gen_config["temperature"] == 0.7
        assert gen_config["maxOutputTokens"] == 1000
        assert gen_config["topP"] == 0.9
        
        # éªŒè¯contentsæ ¼å¼
        contents = request_data["contents"]
        assert len(contents) == 1  # ç³»ç»Ÿæ¶ˆæ¯åˆå¹¶åˆ°ç”¨æˆ·æ¶ˆæ¯
        assert contents[0]["role"] == "user"
        assert "parts" in contents[0]
        assert contents[0]["parts"][0]["text"].startswith("You are a helpful assistant.")
    
    def test_ollama_request_format(self):
        """æµ‹è¯•Ollamaè¯·æ±‚æ ¼å¼"""
        client = AIClient(self.ollama_config)
        
        messages = [
            {"role": "user", "content": "Hello"}
        ]
        
        request_data = client._build_request_data(messages, stream=False)
        
        # éªŒè¯Ollamaä½¿ç”¨OpenAIå…¼å®¹æ ¼å¼
        assert request_data["model"] == "llama3.1:8b"
        assert request_data["messages"] == messages
        assert request_data["max_tokens"] == 1000
        assert request_data["temperature"] == 0.7
        assert request_data["top_p"] == 0.9
    
    def test_gemini_tool_calling_format(self):
        """æµ‹è¯•Geminiå·¥å…·è°ƒç”¨æ ¼å¼"""
        client = AIClient(self.gemini_config)
        
        # åˆ›å»ºæµ‹è¯•å·¥å…·
        test_tool = ToolDefinition(
            name="get_weather",
            description="Get weather information",
            parameters=[
                ToolParameter(name="location", param_type="string", description="Location", required=True)
            ],
            function=lambda location: f"Weather in {location}",
            permission=ToolPermission.READ_ONLY
        )
        
        messages = [{"role": "user", "content": "What's the weather?"}]
        request_data = client._build_request_data(messages, tools=[test_tool])
        
        # éªŒè¯Geminiå·¥å…·æ ¼å¼
        assert "tools" in request_data
        tools = request_data["tools"]
        assert len(tools) == 1
        assert "functionDeclarations" in tools[0]
        
        func_decl = tools[0]["functionDeclarations"][0]
        assert func_decl["name"] == "get_weather"
        assert func_decl["description"] == "Get weather information"
        assert "parameters" in func_decl
    
    def test_gemini_response_parsing(self):
        """æµ‹è¯•Geminiå“åº”è§£æ"""
        client = AIClient(self.gemini_config)
        
        # æ¨¡æ‹ŸGeminiå“åº”æ ¼å¼
        gemini_response = {
            "candidates": [
                {
                    "content": {
                        "parts": [
                            {"text": "Hello! I'm doing well, thank you for asking."}
                        ]
                    }
                }
            ]
        }
        
        content = client._extract_content(gemini_response)
        assert content == "Hello! I'm doing well, thank you for asking."
    
    def test_ollama_response_parsing(self):
        """æµ‹è¯•Ollamaå“åº”è§£æ"""
        client = AIClient(self.ollama_config)
        
        # æ¨¡æ‹ŸOpenAIå…¼å®¹å“åº”
        openai_response = {
            "choices": [
                {
                    "message": {
                        "content": "Hello! How can I help you?"
                    }
                }
            ]
        }
        
        content = client._extract_content(openai_response)
        assert content == "Hello! How can I help you?"
        
        # æ¨¡æ‹ŸåŸç”ŸOllamaå“åº”
        ollama_response = {
            "response": "This is a native Ollama response"
        }
        
        content = client._extract_content(ollama_response)
        assert content == "This is a native Ollama response"
    
    def test_gemini_tool_call_extraction(self):
        """æµ‹è¯•Geminiå·¥å…·è°ƒç”¨æå–"""
        client = AIClient(self.gemini_config)
        
        # æ¨¡æ‹ŸåŒ…å«å·¥å…·è°ƒç”¨çš„Geminiå“åº”
        gemini_tool_response = {
            "candidates": [
                {
                    "content": {
                        "parts": [
                            {
                                "functionCall": {
                                    "name": "get_weather",
                                    "args": {
                                        "location": "Beijing"
                                    }
                                }
                            }
                        ]
                    }
                }
            ]
        }
        
        tool_calls = client._extract_tool_calls(gemini_tool_response)
        assert len(tool_calls) == 1
        
        tool_call = tool_calls[0]
        assert tool_call.tool_name == "get_weather"
        assert tool_call.parameters == {"location": "Beijing"}
        assert tool_call.id.startswith("call_")
    
    def test_has_tool_calls_detection(self):
        """æµ‹è¯•å·¥å…·è°ƒç”¨æ£€æµ‹"""
        gemini_client = AIClient(self.gemini_config)
        ollama_client = AIClient(self.ollama_config)
        
        # Geminiå·¥å…·è°ƒç”¨æ£€æµ‹
        gemini_with_tools = {
            "candidates": [
                {
                    "content": {
                        "parts": [
                            {"functionCall": {"name": "test_func", "args": {}}}
                        ]
                    }
                }
            ]
        }
        assert gemini_client._has_tool_calls(gemini_with_tools) == True
        
        gemini_no_tools = {
            "candidates": [
                {
                    "content": {
                        "parts": [
                            {"text": "Regular response"}
                        ]
                    }
                }
            ]
        }
        assert gemini_client._has_tool_calls(gemini_no_tools) == False
        
        # Ollamaå·¥å…·è°ƒç”¨æ£€æµ‹ï¼ˆOpenAIæ ¼å¼ï¼‰
        ollama_with_tools = {
            "choices": [
                {
                    "message": {
                        "tool_calls": [
                            {"id": "call_123", "function": {"name": "test"}}
                        ]
                    }
                }
            ]
        }
        assert ollama_client._has_tool_calls(ollama_with_tools) == True


def test_api_integration():
    """é›†æˆæµ‹è¯• - éªŒè¯æ‰€æœ‰APIæä¾›å•†ç±»å‹"""
    providers_to_test = [
        (AIProvider.OPENAI, "gpt-4"),
        (AIProvider.CLAUDE, "claude-3-5-sonnet-20241022"),
        (AIProvider.GEMINI, "gemini-1.5-pro"),
        (AIProvider.OLLAMA, "llama3.1:8b"),
        (AIProvider.CUSTOM, "custom-model")
    ]
    
    for provider, model in providers_to_test:
        config = AIConfig(provider=provider, model=model)
        client = AIClient(config)
        
        # éªŒè¯æ¯ä¸ªæä¾›å•†éƒ½èƒ½æ­£ç¡®åˆå§‹åŒ–
        assert client.config.provider == provider
        assert client.config.model == model
        
        # éªŒè¯ç«¯ç‚¹URLç”Ÿæˆä¸ä¼šæŠ¥é”™
        try:
            if provider != AIProvider.CUSTOM:  # CUSTOMéœ€è¦endpoint_url
                endpoint = client._get_endpoint_url()
                assert endpoint is not None
                assert len(endpoint) > 0
        except Exception as e:
            if provider != AIProvider.CUSTOM:
                pytest.fail(f"Provider {provider} endpoint generation failed: {e}")


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    test_suite = TestNativeAPISupport()
    test_suite.setup_method()
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•æ–¹æ³•
    methods = [method for method in dir(test_suite) if method.startswith('test_')]
    passed = 0
    failed = 0
    
    for method_name in methods:
        try:
            method = getattr(test_suite, method_name)
            method()
            print(f"âœ… {method_name}")
            passed += 1
        except Exception as e:
            print(f"âŒ {method_name}: {e}")
            failed += 1
    
    # è¿è¡Œé›†æˆæµ‹è¯•
    try:
        test_api_integration()
        print("âœ… test_api_integration")
        passed += 1
    except Exception as e:
        print(f"âŒ test_api_integration: {e}")
        failed += 1
    
    print(f"\næµ‹è¯•ç»“æœ: {passed} é€šè¿‡, {failed} å¤±è´¥")
    
    if failed == 0:
        print("ğŸ‰ æ‰€æœ‰åŸç”ŸAPIæ ¼å¼æ”¯æŒæµ‹è¯•é€šè¿‡ï¼")
        print("âœ… GeminiåŸç”ŸAPIæ”¯æŒå·²å®ç°")
        print("âœ… OllamaåŸç”ŸAPIæ”¯æŒå·²å®ç°")
        print("âœ… å·¥å…·è°ƒç”¨æ ¼å¼è½¬æ¢æ­£ç¡®")
        print("âœ… å“åº”è§£æåŠŸèƒ½æ­£å¸¸")
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®ç°")