#!/usr/bin/env python3
"""
ç®€åŒ–çš„åŸç”ŸAPIæ ¼å¼æ”¯æŒæµ‹è¯•
éªŒè¯æ–°æ·»åŠ çš„åŸç”ŸAPIæä¾›å•†æ”¯æŒæ˜¯å¦æ­£ç¡®å®ç°ï¼ˆä¸ä¾èµ–pytestï¼‰
"""

import json
import sys
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

try:
    from core.ai_client import AIConfig, AIProvider, AIClient
    from core.tool_types import ToolDefinition, ToolParameter, ToolPermission
    print("âœ… æˆåŠŸå¯¼å…¥æ‰€éœ€æ¨¡å—")
except ImportError as e:
    print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
    sys.exit(1)


def test_provider_enum():
    """æµ‹è¯•AIProvideræšä¸¾æ‰©å±•"""
    print("\nğŸ§ª æµ‹è¯•AIProvideræšä¸¾æ‰©å±•...")
    
    # éªŒè¯æ–°å¢çš„æä¾›å•†
    assert AIProvider.GEMINI.value == "gemini", "GEMINIæä¾›å•†å€¼é”™è¯¯"
    assert AIProvider.OLLAMA.value == "ollama", "OLLAMAæä¾›å•†å€¼é”™è¯¯"
    
    # éªŒè¯æ‰€æœ‰æä¾›å•†
    expected_providers = {"openai", "claude", "gemini", "ollama", "custom"}
    actual_providers = {p.value for p in AIProvider}
    assert actual_providers == expected_providers, f"æä¾›å•†ä¸åŒ¹é…: æœŸæœ›{expected_providers}, å®é™…{actual_providers}"
    
    print("âœ… AIProvideræšä¸¾æ‰©å±•æ­£ç¡®")


def test_gemini_endpoint():
    """æµ‹è¯•Geminiç«¯ç‚¹URLç”Ÿæˆ"""
    print("\nğŸ§ª æµ‹è¯•Geminiç«¯ç‚¹URLç”Ÿæˆ...")
    
    config = AIConfig(
        provider=AIProvider.GEMINI,
        model="gemini-1.5-pro"
    )
    
    client = AIClient(config)
    endpoint = client._get_endpoint_url()
    
    expected = "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro:generateContent"
    assert endpoint == expected, f"Geminiç«¯ç‚¹é”™è¯¯: æœŸæœ›{expected}, å®é™…{endpoint}"
    
    print("âœ… Geminiç«¯ç‚¹URLç”Ÿæˆæ­£ç¡®")


def test_ollama_endpoint():
    """æµ‹è¯•Ollamaç«¯ç‚¹URLç”Ÿæˆ"""
    print("\nğŸ§ª æµ‹è¯•Ollamaç«¯ç‚¹URLç”Ÿæˆ...")
    
    config = AIConfig(
        provider=AIProvider.OLLAMA,
        model="llama3.1:8b"
    )
    
    client = AIClient(config)
    endpoint = client._get_endpoint_url()
    
    expected = "http://localhost:11434/v1/chat/completions"
    assert endpoint == expected, f"Ollamaç«¯ç‚¹é”™è¯¯: æœŸæœ›{expected}, å®é™…{endpoint}"
    
    print("âœ… Ollamaç«¯ç‚¹URLç”Ÿæˆæ­£ç¡®")


def test_gemini_request_format():
    """æµ‹è¯•Geminiè¯·æ±‚æ ¼å¼"""
    print("\nğŸ§ª æµ‹è¯•Geminiè¯·æ±‚æ ¼å¼...")
    
    config = AIConfig(
        provider=AIProvider.GEMINI,
        model="gemini-1.5-pro",
        temperature=0.7,
        max_tokens=1000
    )
    
    client = AIClient(config)
    messages = [
        {"role": "system", "content": "You are helpful."},
        {"role": "user", "content": "Hello"}
    ]
    
    request_data = client._build_request_data(messages, stream=False)
    
    # éªŒè¯Geminiæ ¼å¼
    assert "contents" in request_data, "ç¼ºå°‘contentså­—æ®µ"
    assert "generationConfig" in request_data, "ç¼ºå°‘generationConfigå­—æ®µ"
    
    gen_config = request_data["generationConfig"]
    assert gen_config["temperature"] == 0.7, "temperatureé…ç½®é”™è¯¯"
    assert gen_config["maxOutputTokens"] == 1000, "maxOutputTokensé…ç½®é”™è¯¯"
    
    print("âœ… Geminiè¯·æ±‚æ ¼å¼æ­£ç¡®")


def test_ollama_request_format():
    """æµ‹è¯•Ollamaè¯·æ±‚æ ¼å¼"""
    print("\nğŸ§ª æµ‹è¯•Ollamaè¯·æ±‚æ ¼å¼...")
    
    config = AIConfig(
        provider=AIProvider.OLLAMA,
        model="llama3.1:8b",
        temperature=0.7,
        max_tokens=1000
    )
    
    client = AIClient(config)
    messages = [{"role": "user", "content": "Hello"}]
    
    request_data = client._build_request_data(messages, stream=False)
    
    # éªŒè¯OpenAIå…¼å®¹æ ¼å¼
    assert request_data["model"] == "llama3.1:8b", "æ¨¡å‹åç§°é”™è¯¯"
    assert request_data["messages"] == messages, "æ¶ˆæ¯æ ¼å¼é”™è¯¯"
    assert request_data["temperature"] == 0.7, "temperatureé”™è¯¯"
    assert request_data["max_tokens"] == 1000, "max_tokensé”™è¯¯"
    
    print("âœ… Ollamaè¯·æ±‚æ ¼å¼æ­£ç¡®")


def test_gemini_response_parsing():
    """æµ‹è¯•Geminiå“åº”è§£æ"""
    print("\nğŸ§ª æµ‹è¯•Geminiå“åº”è§£æ...")
    
    config = AIConfig(provider=AIProvider.GEMINI, model="gemini-1.5-pro")
    client = AIClient(config)
    
    # æ¨¡æ‹ŸGeminiå“åº”
    gemini_response = {
        "candidates": [
            {
                "content": {
                    "parts": [
                        {"text": "Hello! How can I help you?"}
                    ]
                }
            }
        ]
    }
    
    content = client._extract_content(gemini_response)
    expected = "Hello! How can I help you?"
    assert content == expected, f"Geminiå“åº”è§£æé”™è¯¯: æœŸæœ›'{expected}', å®é™…'{content}'"
    
    print("âœ… Geminiå“åº”è§£ææ­£ç¡®")


def test_ollama_response_parsing():
    """æµ‹è¯•Ollamaå“åº”è§£æ"""
    print("\nğŸ§ª æµ‹è¯•Ollamaå“åº”è§£æ...")
    
    config = AIConfig(provider=AIProvider.OLLAMA, model="llama3.1:8b")
    client = AIClient(config)
    
    # æµ‹è¯•OpenAIå…¼å®¹å“åº”
    openai_response = {
        "choices": [
            {
                "message": {
                    "content": "Hello from Ollama!"
                }
            }
        ]
    }
    
    content = client._extract_content(openai_response)
    expected = "Hello from Ollama!"
    assert content == expected, f"Ollama OpenAIæ ¼å¼è§£æé”™è¯¯: æœŸæœ›'{expected}', å®é™…'{content}'"
    
    # æµ‹è¯•åŸç”ŸOllamaå“åº”
    ollama_response = {
        "response": "Native Ollama response"
    }
    
    content = client._extract_content(ollama_response)
    expected = "Native Ollama response"
    assert content == expected, f"OllamaåŸç”Ÿæ ¼å¼è§£æé”™è¯¯: æœŸæœ›'{expected}', å®é™…'{content}'"
    
    print("âœ… Ollamaå“åº”è§£ææ­£ç¡®")


def test_tool_calling_support():
    """æµ‹è¯•å·¥å…·è°ƒç”¨æ”¯æŒ"""
    print("\nğŸ§ª æµ‹è¯•å·¥å…·è°ƒç”¨æ”¯æŒ...")
    
    # åˆ›å»ºæµ‹è¯•å·¥å…·
    test_tool = ToolDefinition(
        name="get_weather",
        description="Get weather info",
        parameters=[
            ToolParameter(name="location", param_type="string", description="Location", required=True)
        ],
        function=lambda location: f"Weather in {location}",
        permission=ToolPermission.READ_ONLY
    )
    
    # æµ‹è¯•Geminiå·¥å…·æ ¼å¼
    gemini_config = AIConfig(provider=AIProvider.GEMINI, model="gemini-1.5-pro")
    gemini_client = AIClient(gemini_config)
    
    messages = [{"role": "user", "content": "What's the weather?"}]
    request_data = gemini_client._build_request_data(messages, tools=[test_tool])
    
    assert "tools" in request_data, "Geminiç¼ºå°‘toolså­—æ®µ"
    tools = request_data["tools"]
    assert len(tools) == 1, "Geminiå·¥å…·æ•°é‡é”™è¯¯"
    assert "functionDeclarations" in tools[0], "Geminiç¼ºå°‘functionDeclarations"
    
    # æµ‹è¯•Ollamaå·¥å…·æ ¼å¼
    ollama_config = AIConfig(provider=AIProvider.OLLAMA, model="llama3.1:8b")
    ollama_client = AIClient(ollama_config)
    
    request_data = ollama_client._build_request_data(messages, tools=[test_tool])
    assert "tools" in request_data, "Ollamaç¼ºå°‘toolså­—æ®µ"
    
    print("âœ… å·¥å…·è°ƒç”¨æ”¯æŒæ­£ç¡®")


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹åŸç”ŸAPIæ ¼å¼æ”¯æŒæµ‹è¯•...")
    
    tests = [
        test_provider_enum,
        test_gemini_endpoint,
        test_ollama_endpoint,
        test_gemini_request_format,
        test_ollama_request_format,
        test_gemini_response_parsing,
        test_ollama_response_parsing,
        test_tool_calling_support
    ]
    
    passed = 0
    failed = 0
    
    for test in tests:
        try:
            test()
            passed += 1
        except Exception as e:
            print(f"âŒ {test.__name__} å¤±è´¥: {e}")
            failed += 1
    
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
    print(f"âœ… é€šè¿‡: {passed}")
    print(f"âŒ å¤±è´¥: {failed}")
    
    if failed == 0:
        print("\nğŸ‰ æ‰€æœ‰åŸç”ŸAPIæ ¼å¼æ”¯æŒæµ‹è¯•é€šè¿‡!")
        print("âœ¨ GeminiåŸç”ŸAPIæ”¯æŒå·²å®Œå…¨å®ç°")
        print("âœ¨ OllamaåŸç”ŸAPIæ”¯æŒå·²å®Œå…¨å®ç°")
        print("âœ¨ å·¥å…·è°ƒç”¨æ ¼å¼è½¬æ¢åŠŸèƒ½æ­£å¸¸")
        print("âœ¨ å“åº”è§£æåŠŸèƒ½æ­£å¸¸")
        print("\nğŸ“ˆ å®ç°çš„åŠŸèƒ½:")
        print("  â€¢ AIProvideræšä¸¾æ‰©å±•")
        print("  â€¢ Geminiè®¤è¯å’Œç«¯ç‚¹é…ç½®")
        print("  â€¢ Ollamaæœ¬åœ°APIæ”¯æŒ")
        print("  â€¢ åŸç”Ÿè¯·æ±‚æ ¼å¼è½¬æ¢")
        print("  â€¢ å“åº”è§£æé€‚é…")
        print("  â€¢ å·¥å…·è°ƒç”¨æ ¼å¼æ”¯æŒ")
        return True
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®ç°")
        return False


if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1)