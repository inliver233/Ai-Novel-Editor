"""
PyQt6é›†æˆçš„AIå®¢æˆ·ç«¯
æä¾›ä¿¡å·æ§½æœºåˆ¶çš„AIè°ƒç”¨æ¥å£ï¼Œä¸ç°æœ‰AIManageræ— ç¼é›†æˆ
"""

import asyncio
import logging
from typing import Dict, Any, Optional, List
from PyQt6.QtCore import QObject, pyqtSignal, QThread, QTimer
from PyQt6.QtWidgets import QApplication

from .ai_client import AIClient, AsyncAIClient, AIConfig, AIClientError
from .multimodal_types import MultimodalMessage
from .tool_types import ToolDefinition, ToolCall
from .tool_manager import ToolManager, get_tool_manager

logger = logging.getLogger(__name__)


class AIWorkerThread(QThread):
    """AIå·¥ä½œçº¿ç¨‹"""
    
    # ä¿¡å·å®šä¹‰
    responseReceived = pyqtSignal(str)  # å®Œæ•´å“åº”
    streamChunkReceived = pyqtSignal(str)  # æµå¼æ•°æ®å—
    errorOccurred = pyqtSignal(str)  # é”™è¯¯ä¿¡æ¯
    requestCompleted = pyqtSignal()  # è¯·æ±‚å®Œæˆ
    toolCallStarted = pyqtSignal(str, dict)  # å·¥å…·è°ƒç”¨å¼€å§‹ (tool_name, parameters)
    toolCallCompleted = pyqtSignal(str, dict)  # å·¥å…·è°ƒç”¨å®Œæˆ (tool_name, result)
    
    def __init__(self, config: AIConfig, parent=None):
        super().__init__(parent)
        self.config = config
        self.prompt = ""
        self.messages = None  # å¤šæ¨¡æ€æ¶ˆæ¯åˆ—è¡¨
        self.system_prompt = None
        self.stream_mode = False
        self.multimodal_mode = False
        self.tool_calling_mode = False  # å·¥å…·è°ƒç”¨æ¨¡å¼
        self.tools = None  # å·¥å…·åˆ—è¡¨
        self.tool_manager = None  # å·¥å…·ç®¡ç†å™¨
        self.kwargs = {}
        self._cancelled = False
        
        logger.debug("AIå·¥ä½œçº¿ç¨‹åˆå§‹åŒ–")
    
    def set_request(self, prompt: str, system_prompt: Optional[str] = None, 
                   stream: bool = False, **kwargs):
        """è®¾ç½®è¯·æ±‚å‚æ•°"""
        self.prompt = prompt
        self.messages = None
        self.system_prompt = system_prompt
        self.stream_mode = stream
        self.multimodal_mode = False
        self.tool_calling_mode = False
        self.tools = None
        self.tool_manager = None
        self.kwargs = kwargs
        self._cancelled = False
        
        logger.debug(f"è®¾ç½®AIè¯·æ±‚: stream={stream}, prompt={prompt[:50]}...")
    
    def set_multimodal_request(self, messages: List[MultimodalMessage], system_prompt: Optional[str] = None,
                              stream: bool = False, **kwargs):
        """è®¾ç½®å¤šæ¨¡æ€è¯·æ±‚å‚æ•°"""
        self.messages = messages
        self.prompt = ""
        self.system_prompt = system_prompt
        self.stream_mode = stream
        self.multimodal_mode = True
        self.tool_calling_mode = False
        self.tools = None
        self.tool_manager = None
        self.kwargs = kwargs
        self._cancelled = False
        
        logger.debug(f"è®¾ç½®å¤šæ¨¡æ€AIè¯·æ±‚: stream={stream}, messages={len(messages)} æ¡")
    
    def set_tool_calling_request(self, prompt: str, tools: List[ToolDefinition], 
                                system_prompt: Optional[str] = None, stream: bool = False, **kwargs):
        """è®¾ç½®å·¥å…·è°ƒç”¨è¯·æ±‚å‚æ•°"""
        self.prompt = prompt
        self.messages = None
        self.system_prompt = system_prompt
        self.stream_mode = stream
        self.multimodal_mode = False
        self.tool_calling_mode = True
        self.tools = tools
        self.tool_manager = get_tool_manager()
        self.kwargs = kwargs
        self._cancelled = False
        
        logger.debug(f"è®¾ç½®å·¥å…·è°ƒç”¨AIè¯·æ±‚: stream={stream}, tools={len(tools)} ä¸ª, prompt={prompt[:50]}...")
    
    def cancel_request(self):
        """å–æ¶ˆè¯·æ±‚"""
        self._cancelled = True
        logger.debug("AIè¯·æ±‚å·²å–æ¶ˆ")
    
    def run(self):
        """æ‰§è¡ŒAIè¯·æ±‚"""
        try:
            if self.stream_mode:
                self._run_stream_request()
            else:
                self._run_sync_request()
        except Exception as e:
            logger.error(f"AIå·¥ä½œçº¿ç¨‹æ‰§è¡Œå¤±è´¥: {e}")
            self.errorOccurred.emit(str(e))
        finally:
            self.requestCompleted.emit()
    
    def _run_sync_request(self):
        """æ‰§è¡ŒåŒæ­¥è¯·æ±‚ - æ”¯æŒå–æ¶ˆå’Œå¤šæ¨¡æ€"""
        try:
            logger.debug(f"å¼€å§‹åŒæ­¥AIè¯·æ±‚ - å¤šæ¨¡æ€: {self.multimodal_mode}")
            
            # åœ¨å¼€å§‹è¯·æ±‚å‰æ£€æŸ¥å–æ¶ˆçŠ¶æ€
            if self._cancelled:
                logger.debug("è¯·æ±‚åœ¨å¼€å§‹å‰å·²è¢«å–æ¶ˆ")
                return
            
            with AIClient(self.config) as client:
                # å†æ¬¡æ£€æŸ¥å–æ¶ˆçŠ¶æ€
                if self._cancelled:
                    logger.debug("è¯·æ±‚åœ¨å®¢æˆ·ç«¯åˆ›å»ºåå·²è¢«å–æ¶ˆ")
                    return
                
                # æ ¹æ®æ¨¡å¼æ‰§è¡Œä¸åŒç±»å‹çš„è¯·æ±‚
                # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨é…ç½®ä¸­çš„è¶…æ—¶æ—¶é—´è€Œä¸æ˜¯ç¡¬ç¼–ç 
                timeout_value = self.config.timeout if hasattr(self.config, 'timeout') else 30
                
                if self.tool_calling_mode and self.tools:
                    response = client.complete_with_tools(
                        self.prompt,
                        self.tools,
                        self.system_prompt,
                        timeout=timeout_value,  # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨é…ç½®çš„è¶…æ—¶æ—¶é—´
                        **self.kwargs
                    )
                elif self.multimodal_mode and self.messages:
                    response = client.complete_multimodal(
                        self.messages,
                        self.system_prompt,
                        timeout=timeout_value,  # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨é…ç½®çš„è¶…æ—¶æ—¶é—´
                        **self.kwargs
                    )
                else:
                    response = client.complete(
                        self.prompt, 
                        self.system_prompt, 
                        timeout=timeout_value,  # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨é…ç½®çš„è¶…æ—¶æ—¶é—´
                        **self.kwargs
                    )
                
                # è¯·æ±‚å®Œæˆåå†æ¬¡æ£€æŸ¥å–æ¶ˆçŠ¶æ€
                if not self._cancelled and response:
                    self.responseReceived.emit(response)
                    mode_text = "å¤šæ¨¡æ€" if self.multimodal_mode else "æ–‡æœ¬"
                    logger.info(f"åŒæ­¥{mode_text}AIè¯·æ±‚å®Œæˆ: {len(response)} å­—ç¬¦")
                elif self._cancelled:
                    logger.debug("è¯·æ±‚åœ¨å®Œæˆåè¢«å–æ¶ˆï¼Œä¸å‘é€å“åº”")
                
        except AIClientError as e:
            if not self._cancelled:
                self.errorOccurred.emit(str(e))
        except Exception as e:
            if not self._cancelled:
                self.errorOccurred.emit(f"åŒæ­¥è¯·æ±‚å¤±è´¥: {e}")
    
    def _run_stream_request(self):
        """æ‰§è¡Œæµå¼è¯·æ±‚"""
        try:
            logger.debug("å¼€å§‹æµå¼AIè¯·æ±‚")
            
            # ä½¿ç”¨ç°æœ‰çš„æˆ–åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
            try:
                loop = asyncio.get_event_loop()
                if loop.is_closed():
                    raise RuntimeError("Event loop is closed")
            except RuntimeError:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
            
            try:
                # åœ¨å½“å‰çº¿ç¨‹ä¸­è¿è¡Œå¼‚æ­¥ä»»åŠ¡
                loop.run_until_complete(self._async_stream_request())
            except Exception as e:
                if not self._cancelled:
                    raise
                
        except Exception as e:
            if not self._cancelled:
                self.errorOccurred.emit(f"æµå¼è¯·æ±‚å¤±è´¥: {e}")
    
    async def _async_stream_request(self):
        """å¼‚æ­¥æµå¼è¯·æ±‚ - æ›´é¢‘ç¹çš„å–æ¶ˆæ£€æŸ¥ï¼Œæ”¯æŒå¤šæ¨¡æ€"""
        try:
            async with AsyncAIClient(self.config) as client:
                # å¼€å§‹å‰æ£€æŸ¥å–æ¶ˆçŠ¶æ€
                if self._cancelled:
                    logger.debug("æµå¼è¯·æ±‚åœ¨å¼€å§‹å‰å·²è¢«å–æ¶ˆ")
                    return
                
                full_response = ""
                chunk_count = 0
                
                # æ ¹æ®æ¨¡å¼é€‰æ‹©ä¸åŒçš„æµå¼æ–¹æ³•
                if self.tool_calling_mode and self.tools:
                    stream_generator = client.complete_with_tools_async(
                        self.prompt,
                        self.tools,
                        self.system_prompt,
                        **self.kwargs
                    )
                elif self.multimodal_mode and self.messages:
                    stream_generator = client.complete_multimodal_stream(
                        self.messages,
                        self.system_prompt,
                        **self.kwargs
                    )
                else:
                    stream_generator = client.complete_stream(
                        self.prompt, 
                        self.system_prompt, 
                        **self.kwargs
                    )
                
                async for chunk in stream_generator:
                    # æ¯ä¸ªchunkéƒ½æ£€æŸ¥å–æ¶ˆçŠ¶æ€
                    if self._cancelled:
                        logger.debug(f"æµå¼è¯·æ±‚åœ¨ç¬¬{chunk_count}ä¸ªchunkåè¢«å–æ¶ˆ")
                        break
                    
                    if chunk:
                        chunk_count += 1
                        full_response += chunk
                        self.streamChunkReceived.emit(chunk)
                        
                        # æ¯10ä¸ªchunkæ£€æŸ¥ä¸€æ¬¡å–æ¶ˆçŠ¶æ€ï¼ˆæé«˜å“åº”æ€§ï¼‰
                        if chunk_count % 10 == 0 and self._cancelled:
                            logger.debug(f"æµå¼è¯·æ±‚åœ¨ç¬¬{chunk_count}ä¸ªchunkåè¢«å–æ¶ˆï¼ˆæ‰¹é‡æ£€æŸ¥ï¼‰")
                            break
                
                # å®Œæˆåæ£€æŸ¥å–æ¶ˆçŠ¶æ€
                if not self._cancelled and full_response:
                    self.responseReceived.emit(full_response)
                    mode_text = "å¤šæ¨¡æ€" if self.multimodal_mode else "æ–‡æœ¬"
                    logger.info(f"{mode_text}æµå¼AIè¯·æ±‚å®Œæˆ: {len(full_response)} å­—ç¬¦ï¼Œå…±{chunk_count}ä¸ªchunk")
                elif self._cancelled:
                    logger.debug("æµå¼è¯·æ±‚è¢«å–æ¶ˆï¼Œä¸å‘é€æœ€ç»ˆå“åº”")
                    
        except AIClientError as e:
            if not self._cancelled:
                self.errorOccurred.emit(str(e))
        except Exception as e:
            if not self._cancelled:
                self.errorOccurred.emit(f"æµå¼è¯·æ±‚å¤±è´¥: {e}")


class QtAIClient(QObject):
    """PyQt6é›†æˆçš„AIå®¢æˆ·ç«¯"""
    
    # ä¿¡å·å®šä¹‰
    responseReceived = pyqtSignal(str, dict)  # å“åº”å†…å®¹, è¯·æ±‚ä¸Šä¸‹æ–‡
    streamChunkReceived = pyqtSignal(str, dict)  # æµå¼æ•°æ®å—, è¯·æ±‚ä¸Šä¸‹æ–‡
    errorOccurred = pyqtSignal(str, dict)  # é”™è¯¯ä¿¡æ¯, è¯·æ±‚ä¸Šä¸‹æ–‡
    requestStarted = pyqtSignal(dict)  # è¯·æ±‚å¼€å§‹
    requestCompleted = pyqtSignal(dict)  # è¯·æ±‚å®Œæˆ
    connectionTested = pyqtSignal(bool, str)  # è¿æ¥æµ‹è¯•ç»“æœ, æ¶ˆæ¯
    
    def __init__(self, config: AIConfig, parent=None):
        super().__init__(parent)
        self.config = config
        self._worker_thread = None
        self._current_context = {}
        
        logger.info(f"QtAIå®¢æˆ·ç«¯åˆå§‹åŒ–: {config.provider.value}")
    
    def update_config(self, config: AIConfig):
        """æ›´æ–°é…ç½®"""
        self.config = config
        logger.info(f"AIé…ç½®å·²æ›´æ–°: {config.provider.value}")
    
    def test_connection_async(self):
        """å¼‚æ­¥æµ‹è¯•è¿æ¥"""
        logger.info("å¼€å§‹å¼‚æ­¥è¿æ¥æµ‹è¯•")
        
        # åˆ›å»ºæµ‹è¯•çº¿ç¨‹
        test_thread = AIWorkerThread(self.config, self)
        test_thread.set_request("Hello", max_tokens=5)
        
        # è¿æ¥ä¿¡å·
        test_thread.responseReceived.connect(
            lambda response: self.connectionTested.emit(True, "è¿æ¥æµ‹è¯•æˆåŠŸ")
        )
        test_thread.errorOccurred.connect(
            lambda error: self.connectionTested.emit(False, f"è¿æ¥æµ‹è¯•å¤±è´¥: {error}")
        )
        test_thread.requestCompleted.connect(test_thread.deleteLater)
        
        # å¯åŠ¨æµ‹è¯•
        test_thread.start()
    
    def complete_async(self, prompt: str, context: Optional[Dict[str, Any]] = None, 
                      system_prompt: Optional[str] = None, **kwargs):
        """å¼‚æ­¥è¡¥å…¨"""
        if self._worker_thread and self._worker_thread.isRunning():
            logger.warning("AIè¯·æ±‚æ­£åœ¨è¿›è¡Œä¸­ï¼Œå¿½ç•¥æ–°è¯·æ±‚")
            return
        
        # å‡†å¤‡ä¸Šä¸‹æ–‡
        self._current_context = context or {}
        self._current_context.update({
            'prompt': prompt,
            'system_prompt': system_prompt,
            'stream': False,
            'kwargs': kwargs
        })
        
        logger.info(f"å¼€å§‹å¼‚æ­¥è¡¥å…¨: {prompt[:50]}...")
        
        # åˆ›å»ºå·¥ä½œçº¿ç¨‹
        self._worker_thread = AIWorkerThread(self.config, self)
        self._worker_thread.set_request(prompt, system_prompt, stream=False, **kwargs)
        
        # è¿æ¥ä¿¡å·
        self._worker_thread.responseReceived.connect(self._on_response_received)
        self._worker_thread.errorOccurred.connect(self._on_error_occurred)
        self._worker_thread.requestCompleted.connect(self._on_request_completed)
        
        # å‘å‡ºå¼€å§‹ä¿¡å·
        self.requestStarted.emit(self._current_context.copy())
        
        # å¯åŠ¨çº¿ç¨‹
        self._worker_thread.start()
    
    def complete_stream_async(self, prompt: str, context: Optional[Dict[str, Any]] = None,
                             system_prompt: Optional[str] = None, **kwargs):
        """å¼‚æ­¥æµå¼è¡¥å…¨"""
        if self._worker_thread and self._worker_thread.isRunning():
            logger.warning("AIè¯·æ±‚æ­£åœ¨è¿›è¡Œä¸­ï¼Œå¿½ç•¥æ–°è¯·æ±‚")
            return
        
        # å‡†å¤‡ä¸Šä¸‹æ–‡
        self._current_context = context or {}
        self._current_context.update({
            'prompt': prompt,
            'system_prompt': system_prompt,
            'stream': True,
            'kwargs': kwargs
        })
        
        logger.info(f"å¼€å§‹å¼‚æ­¥æµå¼è¡¥å…¨: {prompt[:50]}...")
        
        # åˆ›å»ºå·¥ä½œçº¿ç¨‹
        self._worker_thread = AIWorkerThread(self.config, self)
        self._worker_thread.set_request(prompt, system_prompt, stream=True, **kwargs)
        
        # è¿æ¥ä¿¡å·
        self._worker_thread.responseReceived.connect(self._on_response_received)
        self._worker_thread.streamChunkReceived.connect(self._on_stream_chunk_received)
        self._worker_thread.errorOccurred.connect(self._on_error_occurred)
        self._worker_thread.requestCompleted.connect(self._on_request_completed)
        
        # å‘å‡ºå¼€å§‹ä¿¡å·
        self.requestStarted.emit(self._current_context.copy())
        
        # å¯åŠ¨çº¿ç¨‹
        self._worker_thread.start()
    
    def complete_multimodal_async(self, messages: List[MultimodalMessage], context: Optional[Dict[str, Any]] = None,
                                 system_prompt: Optional[str] = None, **kwargs):
        """å¼‚æ­¥å¤šæ¨¡æ€è¡¥å…¨"""
        if self._worker_thread and self._worker_thread.isRunning():
            logger.warning("AIè¯·æ±‚æ­£åœ¨è¿›è¡Œä¸­ï¼Œå¿½ç•¥æ–°çš„å¤šæ¨¡æ€è¯·æ±‚")
            return
        
        # å‡†å¤‡ä¸Šä¸‹æ–‡
        self._current_context = context or {}
        self._current_context.update({
            'messages': [str(msg) for msg in messages],  # è½¬æ¢ä¸ºå­—ç¬¦ä¸²ç”¨äºæ—¥å¿—
            'system_prompt': system_prompt,
            'stream': False,
            'multimodal': True,
            'kwargs': kwargs
        })
        
        logger.info(f"å¼€å§‹å¼‚æ­¥å¤šæ¨¡æ€è¡¥å…¨: {len(messages)} æ¡æ¶ˆæ¯")
        
        # åˆ›å»ºå·¥ä½œçº¿ç¨‹
        self._worker_thread = AIWorkerThread(self.config, self)
        self._worker_thread.set_multimodal_request(messages, system_prompt, stream=False, **kwargs)
        
        # è¿æ¥ä¿¡å·
        self._worker_thread.responseReceived.connect(self._on_response_received)
        self._worker_thread.errorOccurred.connect(self._on_error_occurred)
        self._worker_thread.requestCompleted.connect(self._on_request_completed)
        
        # å‘å‡ºå¼€å§‹ä¿¡å·
        self.requestStarted.emit(self._current_context.copy())
        
        # å¯åŠ¨çº¿ç¨‹
        self._worker_thread.start()
    
    def complete_multimodal_stream_async(self, messages: List[MultimodalMessage], context: Optional[Dict[str, Any]] = None,
                                        system_prompt: Optional[str] = None, **kwargs):
        """å¼‚æ­¥å¤šæ¨¡æ€æµå¼è¡¥å…¨"""
        if self._worker_thread and self._worker_thread.isRunning():
            logger.warning("AIè¯·æ±‚æ­£åœ¨è¿›è¡Œä¸­ï¼Œå¿½ç•¥æ–°çš„å¤šæ¨¡æ€æµå¼è¯·æ±‚")
            return
        
        # å‡†å¤‡ä¸Šä¸‹æ–‡
        self._current_context = context or {}
        self._current_context.update({
            'messages': [str(msg) for msg in messages],  # è½¬æ¢ä¸ºå­—ç¬¦ä¸²ç”¨äºæ—¥å¿—
            'system_prompt': system_prompt,
            'stream': True,
            'multimodal': True,
            'kwargs': kwargs
        })
        
        logger.info(f"å¼€å§‹å¼‚æ­¥å¤šæ¨¡æ€æµå¼è¡¥å…¨: {len(messages)} æ¡æ¶ˆæ¯")
        
        # åˆ›å»ºå·¥ä½œçº¿ç¨‹
        self._worker_thread = AIWorkerThread(self.config, self)
        self._worker_thread.set_multimodal_request(messages, system_prompt, stream=True, **kwargs)
        
        # è¿æ¥ä¿¡å·
        self._worker_thread.responseReceived.connect(self._on_response_received)
        self._worker_thread.streamChunkReceived.connect(self._on_stream_chunk_received)
        self._worker_thread.errorOccurred.connect(self._on_error_occurred)
        self._worker_thread.requestCompleted.connect(self._on_request_completed)
        
        # å‘å‡ºå¼€å§‹ä¿¡å·
        self.requestStarted.emit(self._current_context.copy())
        
        # å¯åŠ¨çº¿ç¨‹
        self._worker_thread.start()
    
    def complete_with_tools_async(self, prompt: str, tools: List[ToolDefinition], context: Optional[Dict[str, Any]] = None,
                                 system_prompt: Optional[str] = None, **kwargs):
        """å¼‚æ­¥å·¥å…·è°ƒç”¨è¡¥å…¨"""
        if self._worker_thread and self._worker_thread.isRunning():
            logger.warning("AIè¯·æ±‚æ­£åœ¨è¿›è¡Œä¸­ï¼Œå¿½ç•¥æ–°çš„å·¥å…·è°ƒç”¨è¯·æ±‚")
            return
        
        # å‡†å¤‡ä¸Šä¸‹æ–‡
        self._current_context = context or {}
        self._current_context.update({
            'prompt': prompt,
            'tools': [tool.name for tool in tools],  # å·¥å…·åç§°åˆ—è¡¨ç”¨äºæ—¥å¿—
            'system_prompt': system_prompt,
            'stream': False,
            'tool_calling': True,
            'kwargs': kwargs
        })
        
        logger.info(f"å¼€å§‹å¼‚æ­¥å·¥å…·è°ƒç”¨è¡¥å…¨: {len(tools)} ä¸ªå·¥å…·, prompt={prompt[:50]}...")
        
        # åˆ›å»ºå·¥ä½œçº¿ç¨‹
        self._worker_thread = AIWorkerThread(self.config, self)
        self._worker_thread.set_tool_calling_request(prompt, tools, system_prompt, stream=False, **kwargs)
        
        # è¿æ¥ä¿¡å·
        self._worker_thread.responseReceived.connect(self._on_response_received)
        self._worker_thread.errorOccurred.connect(self._on_error_occurred)
        self._worker_thread.requestCompleted.connect(self._on_request_completed)
        self._worker_thread.toolCallStarted.connect(self._on_tool_call_started)
        self._worker_thread.toolCallCompleted.connect(self._on_tool_call_completed)
        
        # å‘å‡ºå¼€å§‹ä¿¡å·
        self.requestStarted.emit(self._current_context.copy())
        
        # å¯åŠ¨çº¿ç¨‹
        self._worker_thread.start()
    
    def complete_with_tools_stream_async(self, prompt: str, tools: List[ToolDefinition], context: Optional[Dict[str, Any]] = None,
                                        system_prompt: Optional[str] = None, **kwargs):
        """å¼‚æ­¥å·¥å…·è°ƒç”¨æµå¼è¡¥å…¨"""
        if self._worker_thread and self._worker_thread.isRunning():
            logger.warning("AIè¯·æ±‚æ­£åœ¨è¿›è¡Œä¸­ï¼Œå¿½ç•¥æ–°çš„å·¥å…·è°ƒç”¨æµå¼è¯·æ±‚")
            return
        
        # å‡†å¤‡ä¸Šä¸‹æ–‡
        self._current_context = context or {}
        self._current_context.update({
            'prompt': prompt,
            'tools': [tool.name for tool in tools],  # å·¥å…·åç§°åˆ—è¡¨ç”¨äºæ—¥å¿—
            'system_prompt': system_prompt,
            'stream': True,
            'tool_calling': True,
            'kwargs': kwargs
        })
        
        logger.info(f"å¼€å§‹å¼‚æ­¥å·¥å…·è°ƒç”¨æµå¼è¡¥å…¨: {len(tools)} ä¸ªå·¥å…·, prompt={prompt[:50]}...")
        
        # åˆ›å»ºå·¥ä½œçº¿ç¨‹
        self._worker_thread = AIWorkerThread(self.config, self)
        self._worker_thread.set_tool_calling_request(prompt, tools, system_prompt, stream=True, **kwargs)
        
        # è¿æ¥ä¿¡å·
        self._worker_thread.responseReceived.connect(self._on_response_received)
        self._worker_thread.streamChunkReceived.connect(self._on_stream_chunk_received)
        self._worker_thread.errorOccurred.connect(self._on_error_occurred)
        self._worker_thread.requestCompleted.connect(self._on_request_completed)
        self._worker_thread.toolCallStarted.connect(self._on_tool_call_started)
        self._worker_thread.toolCallCompleted.connect(self._on_tool_call_completed)
        
        # å‘å‡ºå¼€å§‹ä¿¡å·
        self.requestStarted.emit(self._current_context.copy())
        
        # å¯åŠ¨çº¿ç¨‹
        self._worker_thread.start()
    
    def cancel_request(self):
        """å–æ¶ˆå½“å‰è¯·æ±‚"""
        if self._worker_thread and self._worker_thread.isRunning():
            self._worker_thread.cancel_request()
            logger.info("AIè¯·æ±‚å·²å–æ¶ˆ")
    
    def is_busy(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ­£åœ¨å¤„ç†è¯·æ±‚"""
        return self._worker_thread and self._worker_thread.isRunning()
    
    def _on_response_received(self, response: str):
        """å“åº”æ¥æ”¶å¤„ç†"""
        self.responseReceived.emit(response, self._current_context.copy())
    
    def _on_stream_chunk_received(self, chunk: str):
        """æµå¼æ•°æ®å—æ¥æ”¶å¤„ç†"""
        self.streamChunkReceived.emit(chunk, self._current_context.copy())
    
    def _on_error_occurred(self, error: str):
        """é”™è¯¯å¤„ç†"""
        self.errorOccurred.emit(error, self._current_context.copy())
    
    def _on_request_completed(self):
        """è¯·æ±‚å®Œæˆå¤„ç†"""
        self.requestCompleted.emit(self._current_context.copy())
        
        # æ¸…ç†å·¥ä½œçº¿ç¨‹
        if self._worker_thread:
            self._worker_thread.deleteLater()
            self._worker_thread = None
    
    def _on_tool_call_started(self, tool_name: str, parameters: dict):
        """å·¥å…·è°ƒç”¨å¼€å§‹å¤„ç†"""
        logger.info(f"å·¥å…·è°ƒç”¨å¼€å§‹: {tool_name}ï¼Œå‚æ•°: {parameters}")
        # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ›´å¤šçš„å·¥å…·è°ƒç”¨å¼€å§‹å¤„ç†é€»è¾‘
    
    def _on_tool_call_completed(self, tool_name: str, result: dict):
        """å·¥å…·è°ƒç”¨å®Œæˆå¤„ç†"""
        logger.info(f"å·¥å…·è°ƒç”¨å®Œæˆ: {tool_name}ï¼Œç»“æœ: {result}")
        # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ›´å¤šçš„å·¥å…·è°ƒç”¨å®Œæˆå¤„ç†é€»è¾‘
    
    def cleanup(self):
        """å®‰å…¨åœ°æ¸…ç†èµ„æºï¼Œåº”ç”¨å…³é—­æ—¶ä½¿ç”¨å¼ºåˆ¶æ¨¡å¼"""
        logger.debug("å¼€å§‹æ¸…ç†QtAIClientèµ„æº...")
        if self._worker_thread and self._worker_thread.isRunning():
            logger.info("æ£€æµ‹åˆ°æ­£åœ¨è¿è¡Œçš„AIå·¥ä½œçº¿ç¨‹ï¼Œå¼€å§‹å¼ºåˆ¶å…³é—­æµç¨‹ã€‚")
            
            # 1. ç«‹å³è®¾ç½®å–æ¶ˆæ ‡å¿—ï¼Œé€šçŸ¥å·¥ä½œçº¿ç¨‹åœæ­¢å…¶å·¥ä½œ
            self.cancel_request()
            
            # 2. è¯·æ±‚çº¿ç¨‹çš„äº‹ä»¶å¾ªç¯é€€å‡º
            self._worker_thread.quit()
            
            # 3. å¼ºåˆ¶æ¨¡å¼ï¼šåªç­‰å¾…1ç§’ï¼Œç„¶åç«‹å³ç»ˆæ­¢
            if not self._worker_thread.wait(1000):  # åªç­‰å¾…1ç§’
                logger.warning("AIå·¥ä½œçº¿ç¨‹åœ¨1ç§’å†…æœªæ­£å¸¸ç»ˆæ­¢ï¼Œæ‰§è¡Œå¼ºåˆ¶ç»ˆæ­¢ã€‚")
                # å¼ºåˆ¶ç»ˆæ­¢çº¿ç¨‹
                self._worker_thread.terminate()
                # å†ç­‰å¾…500msç¡®ä¿ç»ˆæ­¢
                if not self._worker_thread.wait(500):
                    logger.error("AIå·¥ä½œçº¿ç¨‹å¼ºåˆ¶ç»ˆæ­¢å¤±è´¥ï¼Œå¯èƒ½å­˜åœ¨èµ„æºæ³„æ¼")
                else:
                    logger.info("AIå·¥ä½œçº¿ç¨‹å·²å¼ºåˆ¶ç»ˆæ­¢")
            else:
                logger.info("AIå·¥ä½œçº¿ç¨‹å·²æ­£å¸¸ç»ˆæ­¢")

        # 4. åœ¨çº¿ç¨‹ç¡®è®¤ç»ˆæ­¢åï¼Œå†å®‰å…¨åœ°è°ƒåº¦åˆ é™¤
        if self._worker_thread:
            self._worker_thread.deleteLater()
            self._worker_thread = None
            
        logger.info("QtAIå®¢æˆ·ç«¯å·²æ¸…ç†")
