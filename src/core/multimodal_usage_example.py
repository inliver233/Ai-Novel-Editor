"""
å¤šæ¨¡æ€åŠŸèƒ½ä½¿ç”¨ç¤ºä¾‹
å±•ç¤ºå¦‚ä½•åœ¨AIå°è¯´ç¼–è¾‘å™¨ä¸­é›†æˆå’Œä½¿ç”¨å¤šæ¨¡æ€åŠŸèƒ½
"""

import sys
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from core.multimodal_types import MultimodalMessage, TextContent, ImageContent, FileContent
from core.ai_client import AIConfig, AIProvider


class MultimodalExamples:
    """å¤šæ¨¡æ€åŠŸèƒ½ä½¿ç”¨ç¤ºä¾‹ç±»"""
    
    def __init__(self):
        self.config = AIConfig(
            provider=AIProvider.OPENAI,
            model="gpt-4o",
            max_tokens=1000,
            temperature=0.7
        )
    
    def example_1_image_analysis(self):
        """ç¤ºä¾‹1ï¼šå›¾ç‰‡åˆ†æå†™ä½œçµæ„Ÿ"""
        print("=== ç¤ºä¾‹1ï¼šå›¾ç‰‡åˆ†æå†™ä½œçµæ„Ÿ ===")
        
        # åˆ›å»ºåŒ…å«å›¾ç‰‡çš„æ¶ˆæ¯
        messages = [
            MultimodalMessage("system", [
                TextContent("ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å°è¯´åˆ›ä½œåŠ©æ‰‹ï¼Œæ“…é•¿ä»å›¾ç‰‡ä¸­è·å–å†™ä½œçµæ„Ÿã€‚")
            ]),
            MultimodalMessage("user", [
                TextContent("è¯·åŸºäºè¿™å¼ å›¾ç‰‡ä¸ºæˆ‘çš„å°è¯´æä¾›åˆ›ä½œçµæ„Ÿï¼š"),
                ImageContent.from_url("https://example.com/landscape.jpg"),
                TextContent("æˆ‘å¸Œæœ›è·å¾—ï¼š"),
                TextContent("1. åœºæ™¯æè¿°çš„å†™ä½œå»ºè®®"),
                TextContent("2. å¯èƒ½çš„æ•…äº‹æƒ…èŠ‚ç‚¹"),
                TextContent("3. è§’è‰²è®¾å®šçš„çµæ„Ÿ")
            ])
        ]
        
        # æ ¼å¼åŒ–ä¸ºä¸åŒæä¾›å•†æ ¼å¼
        for message in messages:
            print(f"\n{message.role}æ¶ˆæ¯:")
            print(f"- æ–‡æœ¬å†…å®¹: {message.get_text_content()[:100]}...")
            print(f"- åŒ…å«åª’ä½“: {message.has_media()}")
            
            if message.role == "user":
                openai_format = message.to_openai_format()
                print(f"- OpenAIæ ¼å¼å†…å®¹å—æ•°: {len(openai_format['content'])}")
        
        print("âœ… å›¾ç‰‡åˆ†æç¤ºä¾‹å®Œæˆ\n")
    
    def example_2_character_reference(self):
        """ç¤ºä¾‹2ï¼šè§’è‰²å‚è€ƒå›¾ç‰‡"""
        print("=== ç¤ºä¾‹2ï¼šè§’è‰²å‚è€ƒå›¾ç‰‡ ===")
        
        # ä½¿ç”¨base64ç¼–ç çš„ç¤ºä¾‹å›¾ç‰‡ï¼ˆ1x1åƒç´ é€æ˜PNGï¼‰
        character_image = ImageContent(
            "iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNk+M9QDwADhgGAWjR9awAAAABJRU5ErkJggg==",
            "png",
            detail="high"
        )
        
        message = MultimodalMessage("user", [
            TextContent("è¯·åŸºäºè¿™ä¸ªè§’è‰²å‚è€ƒå›¾ä¸ºæˆ‘çš„å°è¯´ä¸»è§’ç”Ÿæˆè¯¦ç»†æè¿°ï¼š"),
            character_image,
            TextContent("è¯·åŒ…æ‹¬ï¼š"),
            TextContent("- å¤–è²Œç‰¹å¾æè¿°"),
            TextContent("- æ€§æ ¼ç‰¹ç‚¹æ¨æµ‹"),
            TextContent("- é€‚åˆçš„æ•…äº‹èƒŒæ™¯"),
            TextContent("- è§’è‰²å¯èƒ½çš„èŒä¸šå’ŒæŠ€èƒ½")
        ])
        
        # æµ‹è¯•ä¸åŒæ ¼å¼
        openai_format = message.to_openai_format()
        claude_format = message.to_claude_format()
        
        print(f"OpenAIæ ¼å¼å†…å®¹: {len(openai_format['content'])} å—")
        print(f"Claudeæ ¼å¼å†…å®¹: {len(claude_format['content'])} å—")
        print(f"æ–‡æœ¬æ‘˜è¦: {message.get_text_content()[:150]}...")
        print("âœ… è§’è‰²å‚è€ƒç¤ºä¾‹å®Œæˆ\n")
    
    def example_3_document_analysis(self):
        """ç¤ºä¾‹3ï¼šæ–‡æ¡£åˆ†æï¼ˆæ¨¡æ‹Ÿï¼‰"""
        print("=== ç¤ºä¾‹3ï¼šæ–‡æ¡£åˆ†æ ===")
        
        # æ¨¡æ‹Ÿæ–‡æ¡£å†…å®¹ï¼ˆå®é™…ä½¿ç”¨æ—¶éœ€è¦çœŸå®æ–‡ä»¶ï¼‰
        document_content = TextContent("""
        è¯·åˆ†æè¿™ä¸ªç ”ç©¶æ–‡æ¡£ï¼Œå¹¶å¸®æˆ‘ä¸ºç§‘å¹»å°è¯´æå–æœ‰ç”¨ä¿¡æ¯ï¼š
        
        [æ¨¡æ‹Ÿæ–‡æ¡£å†…å®¹]
        è¿™æ˜¯ä¸€ä»½å…³äºæœªæ¥åŸå¸‚å‘å±•çš„ç ”ç©¶æŠ¥å‘Š...
        """)
        
        message = MultimodalMessage("user", [
            TextContent("è¯·ä»è¿™ä»½ç ”ç©¶æ–‡æ¡£ä¸­æå–ç§‘å¹»å°è¯´çš„åˆ›ä½œå…ƒç´ ï¼š"),
            document_content,
            TextContent("è¯·é‡ç‚¹å…³æ³¨ï¼š"),
            TextContent("1. æŠ€æœ¯æ¦‚å¿µå’Œç§‘å­¦ç†è®º"),
            TextContent("2. ç¤¾ä¼šç»“æ„å’Œåˆ¶åº¦å˜åŒ–"),
            TextContent("3. å¯èƒ½çš„å†²çªå’Œæˆå‰§å¼ åŠ›"),
            TextContent("4. ä¸–ç•Œè§‚æ„å»ºè¦ç´ ")
        ])
        
        print(f"æ–‡æ¡£åˆ†ææ¶ˆæ¯æ–‡æœ¬: {message.get_text_content()[:200]}...")
        print("âœ… æ–‡æ¡£åˆ†æç¤ºä¾‹å®Œæˆ\n")
    
    def example_4_multi_image_comparison(self):
        """ç¤ºä¾‹4ï¼šå¤šå›¾ç‰‡å¯¹æ¯”åˆ†æ"""
        print("=== ç¤ºä¾‹4ï¼šå¤šå›¾ç‰‡å¯¹æ¯”åˆ†æ ===")
        
        image1 = ImageContent.from_url("https://example.com/scene1.jpg")
        image2 = ImageContent.from_url("https://example.com/scene2.jpg")
        
        message = MultimodalMessage("user", [
            TextContent("è¯·å¯¹æ¯”åˆ†æè¿™ä¸¤ä¸ªåœºæ™¯å›¾ç‰‡ï¼Œä¸ºæˆ‘çš„å°è¯´ç« èŠ‚è¿‡æ¸¡æä¾›å»ºè®®ï¼š"),
            TextContent("\nç¬¬ä¸€ä¸ªåœºæ™¯ï¼š"),
            image1,
            TextContent("\nç¬¬äºŒä¸ªåœºæ™¯ï¼š"),
            image2,
            TextContent("\nè¯·åˆ†æï¼š"),
            TextContent("1. åœºæ™¯ä¹‹é—´çš„è§†è§‰å¯¹æ¯”"),
            TextContent("2. æƒ…ç»ªæ°›å›´çš„å˜åŒ–"),
            TextContent("3. é€‚åˆçš„è¿‡æ¸¡æå†™æŠ€å·§"),
            TextContent("4. è§’è‰²å¿ƒç†çŠ¶æ€çš„å‘¼åº”")
        ])
        
        # æµ‹è¯•Geminiæ ¼å¼ï¼ˆå¯¹å¤šå›¾ç‰‡æ”¯æŒæ›´å¥½ï¼‰
        gemini_format = message.to_gemini_format()
        print(f"Geminiæ ¼å¼partsæ•°é‡: {len(gemini_format['parts'])}")
        print(f"åŒ…å«å›¾ç‰‡æ•°é‡: {sum(1 for part in gemini_format['parts'] if 'inlineData' in part or 'fileData' in part)}")
        print("âœ… å¤šå›¾ç‰‡å¯¹æ¯”ç¤ºä¾‹å®Œæˆ\n")
    
    def example_5_integration_with_existing_system(self):
        """ç¤ºä¾‹5ï¼šä¸ç°æœ‰ç³»ç»Ÿé›†æˆ"""
        print("=== ç¤ºä¾‹5ï¼šä¸ç°æœ‰ç³»ç»Ÿé›†æˆ ===")
        
        # æ¨¡æ‹Ÿä¸ç°æœ‰AIç®¡ç†å™¨çš„é›†æˆ
        class MultimodalAIManager:
            def __init__(self, config: AIConfig):
                self.config = config
            
            def analyze_scene_image(self, image_path: str, scene_context: str) -> str:
                """åˆ†æåœºæ™¯å›¾ç‰‡å¹¶ç”Ÿæˆæè¿°"""
                try:
                    # åˆ›å»ºå¤šæ¨¡æ€æ¶ˆæ¯
                    image = ImageContent.from_url(f"file://{image_path}")
                    message = MultimodalMessage("user", [
                        TextContent(f"åœºæ™¯ä¸Šä¸‹æ–‡ï¼š{scene_context}"),
                        TextContent("è¯·åŸºäºè¿™å¼ å›¾ç‰‡ç”Ÿæˆåœºæ™¯æè¿°ï¼š"),
                        image
                    ])
                    
                    # æ ¼å¼åŒ–æ¶ˆæ¯
                    if self.config.provider == AIProvider.OPENAI:
                        formatted = message.to_openai_format()
                    elif self.config.provider == AIProvider.CLAUDE:
                        formatted = message.to_claude_format()
                    else:
                        formatted = message.to_openai_format()
                    
                    return f"å·²æ ¼å¼åŒ–æ¶ˆæ¯ï¼Œå‡†å¤‡å‘é€åˆ°{self.config.provider.value}"
                    
                except Exception as e:
                    return f"é”™è¯¯ï¼š{e}"
            
            def get_character_description(self, character_images: list, personality_notes: str) -> str:
                """åŸºäºè§’è‰²å›¾ç‰‡ç”Ÿæˆè§’è‰²æè¿°"""
                contents = [TextContent(f"è§’è‰²è®¾å®šï¼š{personality_notes}")]
                
                for i, img_path in enumerate(character_images):
                    contents.append(TextContent(f"å‚è€ƒå›¾ç‰‡{i+1}ï¼š"))
                    contents.append(ImageContent.from_url(f"file://{img_path}"))
                
                contents.append(TextContent("è¯·ç”Ÿæˆè¯¦ç»†çš„è§’è‰²å¤–è²Œæè¿°"))
                
                message = MultimodalMessage("user", contents)
                return f"åˆ›å»ºäº†åŒ…å«{len(character_images)}å¼ å›¾ç‰‡çš„è§’è‰²æè¿°è¯·æ±‚"
        
        # æµ‹è¯•é›†æˆ
        manager = MultimodalAIManager(self.config)
        
        result1 = manager.analyze_scene_image(
            "/path/to/forest_scene.jpg",
            "ä¸»è§’åœ¨ç¥ç§˜æ£®æ—ä¸­è¿·è·¯"
        )
        print(f"åœºæ™¯åˆ†æç»“æœ: {result1}")
        
        result2 = manager.get_character_description(
            ["/path/to/char1.jpg", "/path/to/char2.jpg"],
            "å†·é™ã€æ™ºæ…§ã€æœ‰ç‚¹ç¥ç§˜çš„æ³•å¸ˆ"
        )
        print(f"è§’è‰²æè¿°ç»“æœ: {result2}")
        
        print("âœ… ç³»ç»Ÿé›†æˆç¤ºä¾‹å®Œæˆ\n")
    
    def example_6_error_handling_and_fallback(self):
        """ç¤ºä¾‹6ï¼šé”™è¯¯å¤„ç†å’Œé™çº§æœºåˆ¶"""
        print("=== ç¤ºä¾‹6ï¼šé”™è¯¯å¤„ç†å’Œé™çº§æœºåˆ¶ ===")
        
        # æµ‹è¯•ä¸åŒçš„é”™è¯¯æƒ…å†µ
        test_cases = [
            {
                "name": "æ­£å¸¸å¤šæ¨¡æ€æ¶ˆæ¯",
                "message": MultimodalMessage("user", [
                    TextContent("æ­£å¸¸æ–‡æœ¬"),
                    ImageContent("valid_base64", "png")
                ])
            },
            {
                "name": "åŒ…å«URLå›¾ç‰‡çš„Claudeè¯·æ±‚",
                "message": MultimodalMessage("user", [
                    TextContent("æµ‹è¯•Claude URLå¤„ç†"),
                    ImageContent.from_url("https://example.com/image.jpg")
                ])
            },
            {
                "name": "çº¯æ–‡æœ¬æ¶ˆæ¯",
                "message": MultimodalMessage("user", [
                    TextContent("è¿™æ˜¯çº¯æ–‡æœ¬æ¶ˆæ¯")
                ])
            }
        ]
        
        for case in test_cases:
            print(f"\næµ‹è¯•æ¡ˆä¾‹: {case['name']}")
            message = case['message']
            
            try:
                # æµ‹è¯•OpenAIæ ¼å¼
                openai_result = message.to_openai_format()
                print(f"  âœ… OpenAIæ ¼å¼: æˆåŠŸ")
                
                # æµ‹è¯•Claudeæ ¼å¼ï¼ˆå¯èƒ½æœ‰é™çº§å¤„ç†ï¼‰
                claude_result = message.to_claude_format()
                print(f"  âœ… Claudeæ ¼å¼: æˆåŠŸ")
                
                # æµ‹è¯•Geminiæ ¼å¼
                gemini_result = message.to_gemini_format()
                print(f"  âœ… Geminiæ ¼å¼: æˆåŠŸ")
                
            except Exception as e:
                print(f"  âŒ é”™è¯¯: {e}")
        
        print("\nâœ… é”™è¯¯å¤„ç†ç¤ºä¾‹å®Œæˆ")


def main():
    """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("ğŸ¨ AIå°è¯´ç¼–è¾‘å™¨å¤šæ¨¡æ€åŠŸèƒ½ä½¿ç”¨ç¤ºä¾‹\n")
    
    examples = MultimodalExamples()
    
    # è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
    examples.example_1_image_analysis()
    examples.example_2_character_reference()
    examples.example_3_document_analysis()
    examples.example_4_multi_image_comparison()
    examples.example_5_integration_with_existing_system()
    examples.example_6_error_handling_and_fallback()
    
    print("\nğŸ‰ æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
    print("\nğŸ’¡ é›†æˆè¦ç‚¹:")
    print("1. åœ¨EnhancedAIManagerä¸­æ·»åŠ å¤šæ¨¡æ€æ–¹æ³•")
    print("2. åœ¨UIä¸­æ·»åŠ å›¾ç‰‡/æ–‡ä»¶ä¸Šä¼ ç»„ä»¶")
    print("3. å®ç°å›¾ç‰‡é¢„å¤„ç†ï¼ˆå‹ç¼©ã€æ ¼å¼è½¬æ¢ï¼‰")
    print("4. æ·»åŠ å†…å®¹ç±»å‹éªŒè¯å’Œå¤§å°é™åˆ¶")
    print("5. åœ¨é…ç½®ä¸­æ·»åŠ å¤šæ¨¡æ€å¼€å…³é€‰é¡¹")
    
    print("\nğŸ”§ æ¨èå®æ–½æ­¥éª¤:")
    print("1. åœ¨existing AI managersä¸­é›†æˆMultimodalMessageæ”¯æŒ")
    print("2. æ›´æ–°UIä»¥æ”¯æŒæ‹–æ‹½å›¾ç‰‡å’Œæ–‡ä»¶")
    print("3. æ·»åŠ å¤šæ¨¡æ€é…ç½®é€‰é¡¹åˆ°è®¾ç½®å¯¹è¯æ¡†")
    print("4. å®ç°å›¾ç‰‡é¢„è§ˆå’Œç®¡ç†åŠŸèƒ½")
    print("5. æ·»åŠ å¤šæ¨¡æ€ä½¿ç”¨ç»Ÿè®¡å’Œæˆæœ¬è·Ÿè¸ª")


if __name__ == "__main__":
    main()