"""
AIåŠŸèƒ½ç®¡ç†å™¨
åè°ƒAIè¡¥å…¨ã€é…ç½®ã€æµå¼å“åº”ç­‰åŠŸèƒ½ç»„ä»¶
"""

import logging
from typing import Dict, Any, List, Optional
from PyQt6.QtWidgets import QWidget
from PyQt6.QtCore import QObject, pyqtSignal, pyqtSlot, QTimer, QPoint, QThread
from PyQt6.QtGui import QTextCursor
import queue
import time
import threading
import hashlib

from .completion_widget import CompletionWidget
from .unified_ai_config_dialog import UnifiedAIConfigDialog
from .stream_widget import StreamResponseWidget
from .literary_formatter import literary_formatter

logger = logging.getLogger(__name__)

# å¯¼å…¥AIå®¢æˆ·ç«¯å’Œæç¤ºè¯ç³»ç»Ÿ
try:
    from core.ai_qt_client import QtAIClient
    from core.config import Config
    from core.prompt_engineering import EnhancedPromptManager, PromptMode, CompletionType, PromptRenderer
    from core.builtin_templates import BuiltinTemplateLibrary
    AI_CLIENT_AVAILABLE = True
    PROMPT_SYSTEM_AVAILABLE = True
except ImportError as e:
    logger.warning(f"AIå®¢æˆ·ç«¯æˆ–æç¤ºè¯ç³»ç»Ÿä¸å¯ç”¨: {e}")
    AI_CLIENT_AVAILABLE = False
    PROMPT_SYSTEM_AVAILABLE = False


class AsyncIndexingWorker(QThread):
    """å¼‚æ­¥ç´¢å¼•å·¥ä½œçº¿ç¨‹"""
    
    indexStarted = pyqtSignal(str)  # å¼€å§‹ç´¢å¼•æ–‡æ¡£ä¿¡å·
    indexProgress = pyqtSignal(str, int, int)  # ç´¢å¼•è¿›åº¦ä¿¡å· (doc_id, current, total)
    indexCompleted = pyqtSignal(str, bool)  # ç´¢å¼•å®Œæˆä¿¡å· (doc_id, success)
    batchCompleted = pyqtSignal(int, int)  # æ‰¹é‡ç´¢å¼•å®Œæˆä¿¡å· (success_count, total_count)
    
    def __init__(self, parent=None):
        super().__init__(parent)
        self._index_queue = queue.Queue()
        self._should_stop = False
        self._rag_service = None
        self._vector_store = None
        self._config = None
        
    def set_services(self, rag_service, vector_store, config):
        """è®¾ç½®RAGæœåŠ¡å¼•ç”¨"""
        self._rag_service = rag_service
        self._vector_store = vector_store
        self._config = config
    
    def queue_document_index(self, document_id: str, content: str):
        """å°†æ–‡æ¡£åŠ å…¥ç´¢å¼•é˜Ÿåˆ—"""
        if content and content.strip():
            self._index_queue.put(('single', document_id, content))
            logger.info(f"æ–‡æ¡£å·²åŠ å…¥å¼‚æ­¥ç´¢å¼•é˜Ÿåˆ—: {document_id}")
        
    def queue_batch_index(self, documents: Dict[str, str]):
        """å°†æ‰¹é‡æ–‡æ¡£åŠ å…¥ç´¢å¼•é˜Ÿåˆ—"""
        if documents:
            self._index_queue.put(('batch', documents, None))
            logger.info(f"æ‰¹é‡æ–‡æ¡£å·²åŠ å…¥å¼‚æ­¥ç´¢å¼•é˜Ÿåˆ—: {len(documents)} ä¸ªæ–‡æ¡£")
    
    def run(self):
        """å·¥ä½œçº¿ç¨‹ä¸»å¾ªç¯"""
        logger.info("å¼‚æ­¥ç´¢å¼•å·¥ä½œçº¿ç¨‹å¯åŠ¨")
        
        while not self._should_stop:
            try:
                # ç­‰å¾…ç´¢å¼•ä»»åŠ¡ï¼Œè¶…æ—¶æ—¶é—´1ç§’
                try:
                    task_type, data, content = self._index_queue.get(timeout=1.0)
                except queue.Empty:
                    continue
                
                if not self._rag_service or not self._vector_store:
                    logger.warning("RAGæœåŠ¡æœªåˆå§‹åŒ–ï¼Œè·³è¿‡ç´¢å¼•ä»»åŠ¡")
                    continue
                
                if task_type == 'single':
                    # å•ä¸ªæ–‡æ¡£ç´¢å¼•
                    document_id = data
                    self._index_single_document(document_id, content)
                elif task_type == 'batch':
                    # æ‰¹é‡æ–‡æ¡£ç´¢å¼•
                    documents = data
                    self._index_batch_documents(documents)
                
                self._index_queue.task_done()
                
            except Exception as e:
                logger.error(f"å¼‚æ­¥ç´¢å¼•å¤„ç†é”™è¯¯: {e}", exc_info=True)
                time.sleep(0.1)  # çŸ­æš‚ä¼‘æ¯é˜²æ­¢æ­»å¾ªç¯
        
        logger.info("å¼‚æ­¥ç´¢å¼•å·¥ä½œçº¿ç¨‹åœæ­¢")
    
    def _index_single_document(self, document_id: str, content: str):
        """ç´¢å¼•å•ä¸ªæ–‡æ¡£"""
        try:
            self.indexStarted.emit(document_id)
            
            logger.info(f"å¼‚æ­¥ç´¢å¼•æ–‡æ¡£: {document_id}, å†…å®¹é•¿åº¦: {len(content)}")
            
            # ç›´æ¥è°ƒç”¨RAGæœåŠ¡çš„ç´¢å¼•æ–¹æ³•
            if self._rag_service:
                success = self._rag_service.index_document(document_id, content)
                
                if success:
                    logger.info(f"å¼‚æ­¥ç´¢å¼•å®Œæˆ: {document_id}")
                    self.indexCompleted.emit(document_id, True)
                else:
                    logger.error(f"å¼‚æ­¥ç´¢å¼•å¤±è´¥: {document_id}")
                    self.indexCompleted.emit(document_id, False)
            else:
                logger.error(f"RAGæœåŠ¡ä¸å¯ç”¨ï¼Œå¼‚æ­¥ç´¢å¼•å¤±è´¥: {document_id}")
                self.indexCompleted.emit(document_id, False)
            
        except Exception as e:
            logger.error(f"å¼‚æ­¥ç´¢å¼•æ–‡æ¡£å¤±è´¥: {document_id}, é”™è¯¯: {e}", exc_info=True)
            self.indexCompleted.emit(document_id, False)
    
    def _index_batch_documents(self, documents: Dict[str, str]):
        """æ‰¹é‡ç´¢å¼•æ–‡æ¡£"""
        total_count = len(documents)
        success_count = 0
        
        for i, (doc_id, content) in enumerate(documents.items()):
            if self._should_stop:
                break
                
            self.indexProgress.emit(doc_id, i + 1, total_count)
            
            try:
                # ç›´æ¥è°ƒç”¨RAGæœåŠ¡ç´¢å¼•æ–¹æ³•
                if self._rag_service and self._rag_service.index_document(doc_id, content):
                    success_count += 1
                    logger.info(f"æ‰¹é‡ç´¢å¼•æˆåŠŸ: {doc_id}")
                else:
                    logger.error(f"æ‰¹é‡ç´¢å¼•å¤±è´¥: {doc_id}")
                    
            except Exception as e:
                logger.error(f"æ‰¹é‡ç´¢å¼•æ–‡æ¡£å¤±è´¥: {doc_id}, é”™è¯¯: {e}")
        
        self.batchCompleted.emit(success_count, total_count)
        logger.info(f"æ‰¹é‡å¼‚æ­¥ç´¢å¼•å®Œæˆ: {success_count}/{total_count}")
    
    def stop(self):
        """åœæ­¢å·¥ä½œçº¿ç¨‹"""
        self._should_stop = True
        
        # æ¸…ç©ºé˜Ÿåˆ—é˜²æ­¢é˜»å¡
        try:
            while not self._index_queue.empty():
                try:
                    self._index_queue.get_nowait()
                except queue.Empty:
                    break
        except Exception as e:
            logger.debug(f"æ¸…ç©ºç´¢å¼•é˜Ÿåˆ—æ—¶å‡ºé”™: {e}")
        
        logger.info("å¼‚æ­¥ç´¢å¼•å·¥ä½œçº¿ç¨‹æ”¶åˆ°åœæ­¢ä¿¡å·")


class AIManager(QObject):
    """AIåŠŸèƒ½ç®¡ç†å™¨"""
    
    # ä¿¡å·å®šä¹‰
    completionRequested = pyqtSignal(str, dict)  # è¡¥å…¨è¯·æ±‚ä¿¡å·
    configChanged = pyqtSignal(dict)  # é…ç½®å˜æ›´ä¿¡å·
    
    def __init__(self, config: Config, parent=None):
        super().__init__(parent)

        self._config = config
        self._completion_widget = None
        self._stream_widget = None
        self._config_dialog = None

        # AIè¡¥å…¨æ§åˆ¶è®¾ç½®
        self._completion_enabled = True
        self._auto_trigger_enabled = True
        self._punctuation_assist_enabled = True
        self._trigger_delay = 1200  # å¢åŠ åˆ°1.2ç§’ï¼Œå‡å°‘é¢‘ç¹è§¦å‘
        self._completion_mode = "æ™ºèƒ½"
        self._context_mode = "balanced"  # æ–°å¢ä¸Šä¸‹æ–‡æ¨¡å¼ï¼šfast, balanced, full

        # æ€§èƒ½ä¼˜åŒ–è®¾ç½®
        self._debounce_delay = 1200  # é˜²æŠ–å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
        self._throttle_interval = 2000  # èŠ‚æµé—´éš”ï¼ˆæ¯«ç§’ï¼‰
        self._last_completion_time = 0
        self._min_trigger_chars = 3  # æœ€å°‘è¾“å…¥å­—ç¬¦æ•°æ‰è§¦å‘
        self._last_text_hash = ""
        
        # è¡¥å…¨è§¦å‘å®šæ—¶å™¨ï¼ˆé˜²æŠ–ï¼‰
        self._completion_timer = QTimer()
        self._completion_timer.setSingleShot(True)
        self._completion_timer.timeout.connect(self._debounced_trigger_completion)
        
        # èŠ‚æµå®šæ—¶å™¨
        self._throttle_timer = QTimer()
        self._throttle_timer.setSingleShot(True)

        # å½“å‰ç¼–è¾‘å™¨å¼•ç”¨
        self._current_editor = None

        # ç»Ÿè®¡ä¿¡æ¯
        self._completion_count = 0
        self._acceptance_count = 0

        # åˆå§‹åŒ–AIå®¢æˆ·ç«¯
        self._ai_client = None
        self._init_ai_client()
        
        # åˆå§‹åŒ–RAGæœåŠ¡
        self._rag_service = None
        self._vector_store = None
        self._init_rag_service()
        
        # åˆå§‹åŒ–æç¤ºè¯ç®¡ç†ç³»ç»Ÿ
        self._prompt_manager = None
        self._prompt_renderer = None
        self._current_template_ids = {
            'fast': 'ai_fast_completion',
            'balanced': 'ai_balanced_completion', 
            'full': 'ai_full_completion'
        }
        self._init_prompt_system()
        
        # åˆå§‹åŒ–å¼‚æ­¥ç´¢å¼•å·¥ä½œçº¿ç¨‹
        self._async_indexer = AsyncIndexingWorker(self)
        self._async_indexer.indexStarted.connect(self._on_async_index_started)
        self._async_indexer.indexCompleted.connect(self._on_async_index_completed)
        self._async_indexer.batchCompleted.connect(self._on_async_batch_completed)
        self._async_indexer.start()
        logger.info("å¼‚æ­¥ç´¢å¼•å·¥ä½œçº¿ç¨‹å·²å¯åŠ¨")
        
        # ä¿å­˜sharedå¼•ç”¨ï¼ˆé˜²æ­¢åœ¨é¡¹ç›®å˜åŒ–æ—¶ä¸¢å¤±ï¼‰
        self._shared = self.parent()._shared if hasattr(self.parent(), '_shared') else None
        
        # è¿æ¥é¡¹ç›®å˜åŒ–ä¿¡å·ï¼Œç”¨äºé‡æ–°åˆå§‹åŒ–RAGæœåŠ¡
        if self._shared and hasattr(self._shared, 'projectChanged'):
            self._shared.projectChanged.connect(self._on_project_changed)

        # æ´»è·ƒçº¿ç¨‹ç®¡ç†
        self._active_threads = set()  # è·Ÿè¸ªæ´»è·ƒçš„æœç´¢çº¿ç¨‹
        self._is_shutting_down = False  # å…³é—­æ ‡å¿—
        self._thread_stop_events = {}  # çº¿ç¨‹åœæ­¢äº‹ä»¶æ˜ å°„

        # åˆå§‹åŒ–å¤§çº²åˆ†ææ‰©å±•
        self._outline_extension = None
        self._init_outline_extension()

        # åˆå§‹åŒ–ç°ä»£AIçŠ¶æ€æŒ‡ç¤ºå™¨
        self._modern_ai_indicators = {}  # å­˜å‚¨æ¯ä¸ªç¼–è¾‘å™¨çš„æŒ‡ç¤ºå™¨
        self._init_modern_indicators()

        logger.info("AI manager initialized")

    def _init_modern_indicators(self):
        """åˆå§‹åŒ–ç°ä»£AIçŠ¶æ€æŒ‡ç¤ºå™¨ç³»ç»Ÿ"""
        try:
            # å¯¼å…¥ç°ä»£AIæŒ‡ç¤ºå™¨
            from gui.editor.modern_ai_indicator import AIStatusManager
            self._ai_status_manager_class = AIStatusManager
            logger.info("ç°ä»£AIçŠ¶æ€æŒ‡ç¤ºå™¨ç³»ç»Ÿå·²åˆå§‹åŒ–")
        except ImportError as e:
            logger.error(f"æ— æ³•å¯¼å…¥ç°ä»£AIçŠ¶æ€æŒ‡ç¤ºå™¨: {e}")
            self._ai_status_manager_class = None

    def _create_modern_indicator_for_editor(self, editor):
        """ä¸ºç¼–è¾‘å™¨åˆ›å»ºç°ä»£AIçŠ¶æ€æŒ‡ç¤ºå™¨"""
        if not self._ai_status_manager_class:
            logger.warning("ç°ä»£AIçŠ¶æ€æŒ‡ç¤ºå™¨ç±»ä¸å¯ç”¨ï¼Œè·³è¿‡åˆ›å»º")
            return
            
        try:
            # ä¸ºæ¯ä¸ªç¼–è¾‘å™¨åˆ›å»ºç‹¬ç«‹çš„æŒ‡ç¤ºå™¨ç®¡ç†å™¨
            editor_id = id(editor)
            
            # æ¸…ç†æ—§çš„æŒ‡ç¤ºå™¨ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if editor_id in self._modern_ai_indicators:
                old_indicator = self._modern_ai_indicators[editor_id]
                if hasattr(old_indicator, 'hide'):
                    old_indicator.hide()
                del self._modern_ai_indicators[editor_id]
            
            # åˆ›å»ºæ–°çš„ç°ä»£æŒ‡ç¤ºå™¨ç®¡ç†å™¨
            status_manager = self._ai_status_manager_class(editor)
            
            # è¿æ¥å–æ¶ˆä¿¡å·ï¼ˆå¦‚æœç”¨æˆ·ç‚¹å‡»æŒ‡ç¤ºå™¨å–æ¶ˆæ“ä½œï¼‰
            if hasattr(status_manager, 'connect_cancel_signal'):
                status_manager.connect_cancel_signal(self._on_ai_operation_cancelled)
            
            # ä¿å­˜åˆ°å­—å…¸ä¸­
            self._modern_ai_indicators[editor_id] = status_manager
            
            logger.info(f"ä¸ºç¼–è¾‘å™¨ {editor_id} åˆ›å»ºäº†ç°ä»£AIçŠ¶æ€æŒ‡ç¤ºå™¨")
            
        except Exception as e:
            logger.error(f"åˆ›å»ºç°ä»£AIçŠ¶æ€æŒ‡ç¤ºå™¨å¤±è´¥: {e}")

    def _on_ai_operation_cancelled(self):
        """AIæ“ä½œè¢«ç”¨æˆ·å–æ¶ˆ"""
        logger.info("ç”¨æˆ·å–æ¶ˆäº†AIæ“ä½œ")
        
        # åœæ­¢å½“å‰çš„AIè¯·æ±‚
        if self._ai_client and hasattr(self._ai_client, 'cancel_request'):
            try:
                self._ai_client.cancel_request()
                logger.debug("AIè¯·æ±‚å·²å–æ¶ˆ")
            except Exception as e:
                logger.warning(f"å–æ¶ˆAIè¯·æ±‚å¤±è´¥: {e}")
        
        # é‡ç½®çŠ¶æ€
        self._is_completing = False
        
        # éšè—æ‰€æœ‰ç°ä»£æŒ‡ç¤ºå™¨
        for status_manager in self._modern_ai_indicators.values():
            if hasattr(status_manager, 'hide'):
                status_manager.hide()

    def _get_current_modern_indicator(self):
        """è·å–å½“å‰ç¼–è¾‘å™¨çš„ç°ä»£çŠ¶æ€æŒ‡ç¤ºå™¨"""
        if not self._current_editor:
            return None
            
        editor_id = id(self._current_editor)
        return self._modern_ai_indicators.get(editor_id)

    def set_completion_enabled(self, enabled: bool):
        """è®¾ç½®AIè¡¥å…¨å¼€å…³"""
        self._completion_enabled = enabled
        logger.info(f"AIè¡¥å…¨{'å¯ç”¨' if enabled else 'ç¦ç”¨'}")

    def set_auto_trigger_enabled(self, enabled: bool):
        """è®¾ç½®è‡ªåŠ¨è§¦å‘å¼€å…³"""
        self._auto_trigger_enabled = enabled
        logger.info(f"è‡ªåŠ¨è§¦å‘{'å¯ç”¨' if enabled else 'ç¦ç”¨'}")

    def set_punctuation_assist_enabled(self, enabled: bool):
        """è®¾ç½®æ ‡ç‚¹ç¬¦å·è¾…åŠ©å¼€å…³"""
        self._punctuation_assist_enabled = enabled
        logger.info(f"æ ‡ç‚¹ç¬¦å·è¾…åŠ©{'å¯ç”¨' if enabled else 'ç¦ç”¨'}")

    def set_trigger_delay(self, delay: int):
        """è®¾ç½®è§¦å‘å»¶è¿Ÿ"""
        self._trigger_delay = delay
        self._debounce_delay = max(delay, 800)  # é˜²æŠ–å»¶è¿Ÿè‡³å°‘800ms
        logger.info(f"è§¦å‘å»¶è¿Ÿè®¾ç½®ä¸º {delay}msï¼Œé˜²æŠ–å»¶è¿Ÿ: {self._debounce_delay}ms")

    def set_context_mode(self, mode: str):
        """è®¾ç½®ä¸Šä¸‹æ–‡æ¨¡å¼"""
        self._context_mode = mode
        logger.info(f"ä¸Šä¸‹æ–‡æ¨¡å¼è®¾ç½®ä¸º {mode}")

    def _init_outline_extension(self):
        """åˆå§‹åŒ–å¤§çº²åˆ†ææ‰©å±•"""
        try:
            self._outline_extension = OutlineAnalysisExtension(self)
            
            # è¿æ¥å¤§çº²æ‰©å±•ä¿¡å·ï¼ˆå¦‚æœéœ€è¦å…¨å±€å“åº”ï¼‰
            if hasattr(self._outline_extension, 'outlineAnalysisCompleted'):
                self._outline_extension.outlineAnalysisCompleted.connect(self._on_outline_analysis_completed)
            if hasattr(self._outline_extension, 'outlineAnalysisError'):
                self._outline_extension.outlineAnalysisError.connect(self._on_outline_analysis_error)
            
            logger.info("å¤§çº²åˆ†ææ‰©å±•åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–å¤§çº²åˆ†ææ‰©å±•å¤±è´¥: {e}")
            self._outline_extension = None

    def _on_outline_analysis_completed(self, result: str, original_text: str):
        """å¤§çº²åˆ†æå®Œæˆå›è°ƒ"""
        logger.debug(f"å¤§çº²åˆ†æå®Œæˆï¼Œç»“æœé•¿åº¦: {len(result)}")

    def _on_outline_analysis_error(self, error_msg: str):
        """å¤§çº²åˆ†æé”™è¯¯å›è°ƒ"""
        logger.warning(f"å¤§çº²åˆ†æå‡ºé”™: {error_msg}")

    # å¤§çº²åŠŸèƒ½å…¬å…±æ¥å£æ–¹æ³•
    def analyze_outline(self, text: str, analysis_type: str = 'auto') -> str:
        """å¤§çº²åˆ†æå…¬å…±æ¥å£"""
        try:
            if not self._outline_extension:
                raise RuntimeError("å¤§çº²åˆ†ææ‰©å±•æœªåˆå§‹åŒ–")
            
            return self._outline_extension.analyze_outline_structure(text, analysis_type)
        except Exception as e:
            logger.error(f"å¤§çº²åˆ†æè°ƒç”¨å¤±è´¥: {e}")
            raise

    def get_outline_suggestions(self, outline: str) -> List[str]:
        """è·å–å¤§çº²å»ºè®®"""
        try:
            if not self._outline_extension:
                logger.warning("å¤§çº²åˆ†ææ‰©å±•æœªåˆå§‹åŒ–ï¼Œè¿”å›ç©ºå»ºè®®")
                return []
            
            return self._outline_extension.suggest_outline_improvements(outline)
        except Exception as e:
            logger.error(f"è·å–å¤§çº²å»ºè®®å¤±è´¥: {e}")
            return []

    def generate_outline_continuation(self, existing_docs: List, generation_params: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆå¤§çº²ç»­å†™å†…å®¹"""
        try:
            if not self._outline_extension:
                raise RuntimeError("å¤§çº²åˆ†ææ‰©å±•æœªåˆå§‹åŒ–")
            
            return self._outline_extension.generate_outline_continuation(existing_docs, generation_params)
        except Exception as e:
            logger.error(f"ç”Ÿæˆå¤§çº²ç»­å†™å¤±è´¥: {e}")
            return {'error': str(e)}

    def get_outline_extension(self):
        """è·å–å¤§çº²æ‰©å±•å®ä¾‹ï¼ˆç”¨äºç›´æ¥è®¿é—®ä¿¡å·ï¼‰"""
        return self._outline_extension

    def get_context_mode(self) -> str:
        """è·å–å½“å‰ä¸Šä¸‹æ–‡æ¨¡å¼"""
        return self._context_mode

    def set_completion_mode(self, mode: str):
        """è®¾ç½®è¡¥å…¨æ¨¡å¼"""
        self._completion_mode = mode
        logger.info(f"è¡¥å…¨æ¨¡å¼è®¾ç½®ä¸º {mode}")

        # å°†æ¨¡å¼ä¼ é€’ç»™å½“å‰ç¼–è¾‘å™¨çš„æ™ºèƒ½è¡¥å…¨ç®¡ç†å™¨
        if self._current_editor and hasattr(self._current_editor, '_smart_completion'):
            self._current_editor._smart_completion.set_completion_mode(mode)
            
        # åŒæ—¶æ›´æ–°ç¼–è¾‘å™¨çš„çŠ¶æ€æŒ‡ç¤ºå™¨æ˜¾ç¤º
        if (self._current_editor and 
            hasattr(self._current_editor, '_status_indicator') and 
            self._current_editor._status_indicator):
            self._current_editor._status_indicator.set_completion_mode(mode)
            logger.debug(f"çŠ¶æ€æŒ‡ç¤ºå™¨æ¨¡å¼å·²æ›´æ–°ä¸º: {mode}")

    def get_completion_stats(self) -> dict:
        """è·å–è¡¥å…¨ç»Ÿè®¡ä¿¡æ¯"""
        acceptance_rate = (self._acceptance_count / self._completion_count * 100) if self._completion_count > 0 else 0
        return {
            'completion_count': self._completion_count,
            'acceptance_count': self._acceptance_count,
            'acceptance_rate': acceptance_rate
        }

    def _init_ai_client(self):
        """åˆå§‹åŒ–AIå®¢æˆ·ç«¯"""
        if not AI_CLIENT_AVAILABLE:
            logger.warning("AIå®¢æˆ·ç«¯ä¸å¯ç”¨ï¼Œè·³è¿‡åˆå§‹åŒ–")
            return

        try:
            # è·å–AIé…ç½®
            ai_config = self._config.get_ai_config()

            if ai_config:
                # æ¸…ç†æ—§çš„AIå®¢æˆ·ç«¯
                if self._ai_client:
                    try:
                        self._ai_client.cleanup()
                    except:
                        pass
                    self._ai_client = None
                
                # åˆ›å»ºAIå®¢æˆ·ç«¯
                self._ai_client = QtAIClient(ai_config, self)

                # è¿æ¥ä¿¡å·
                self._ai_client.responseReceived.connect(self._on_ai_response_received)
                self._ai_client.streamChunkReceived.connect(self._on_ai_stream_chunk)
                self._ai_client.errorOccurred.connect(self._on_ai_error)
                self._ai_client.requestStarted.connect(self._on_ai_request_started)
                self._ai_client.requestCompleted.connect(self._on_ai_request_completed)

                logger.info(f"AIå®¢æˆ·ç«¯å·²åˆå§‹åŒ–: {ai_config.provider.value}")
            else:
                logger.warning("AIé…ç½®æ— æ•ˆï¼Œæ— æ³•åˆå§‹åŒ–AIå®¢æˆ·ç«¯")

        except Exception as e:
            logger.error(f"åˆå§‹åŒ–AIå®¢æˆ·ç«¯å¤±è´¥: {e}")
            self._ai_client = None

    def set_editor(self, editor):
        """è®¾ç½®å½“å‰ç¼–è¾‘å™¨"""
        if self._current_editor:
            # æ–­å¼€æ—§ç¼–è¾‘å™¨çš„ä¿¡å·
            try:
                self._current_editor.textChanged.disconnect(self._on_text_changed)
                self._current_editor.cursorPositionChanged.disconnect(self._on_cursor_changed)
                # æ–­å¼€æ™ºèƒ½è¡¥å…¨ç®¡ç†å™¨çš„ä¿¡å·
                if hasattr(self._current_editor, '_smart_completion'):
                    self._current_editor._smart_completion.aiCompletionRequested.disconnect(self._on_ai_completion_requested)
            except:
                pass

        self._current_editor = editor

        if editor:
            # è¿æ¥æ–°ç¼–è¾‘å™¨çš„ä¿¡å·
            editor.textChanged.connect(self._on_text_changed)
            editor.cursorPositionChanged.connect(self._on_cursor_changed)

            # è¿æ¥æ™ºèƒ½è¡¥å…¨ç®¡ç†å™¨çš„AIè¡¥å…¨è¯·æ±‚ä¿¡å·
            if hasattr(editor, '_smart_completion'):
                editor._smart_completion.aiCompletionRequested.connect(self._on_ai_completion_requested)
                logger.debug("Connected smart completion AI request signal")

            # ä¸ºç¼–è¾‘å™¨åˆ›å»ºç°ä»£AIçŠ¶æ€æŒ‡ç¤ºå™¨
            self._create_modern_indicator_for_editor(editor)

            logger.debug("Editor set for AI manager")
    
    def get_completion_widget(self, parent: QWidget) -> CompletionWidget:
        """è·å–è¡¥å…¨ç»„ä»¶"""
        if not self._completion_widget:
            self._completion_widget = CompletionWidget(parent)
            self._completion_widget.suggestionAccepted.connect(self._on_suggestion_accepted)
            self._completion_widget.suggestionRejected.connect(self._on_suggestion_rejected)
            self._completion_widget.moreOptionsRequested.connect(self._on_more_options_requested)
        
        return self._completion_widget
    
    def get_stream_widget(self, parent: QWidget) -> StreamResponseWidget:
        """è·å–æµå¼å“åº”ç»„ä»¶"""
        if not self._stream_widget:
            self._stream_widget = StreamResponseWidget(parent)
            self._stream_widget.responseCompleted.connect(self._on_response_completed)
            self._stream_widget.responseCancelled.connect(self._on_response_cancelled)
            self._stream_widget.responseAccepted.connect(self._on_response_accepted)
        
        return self._stream_widget
    
    def show_config_dialog(self, parent: QWidget):
        """æ˜¾ç¤ºç»Ÿä¸€é…ç½®å¯¹è¯æ¡†"""
        try:
            from .unified_ai_config_dialog import UnifiedAIConfigDialog
            
            # ç¡®ä¿AIå®¢æˆ·ç«¯å·²åˆå§‹åŒ–
            if not self._ai_client:
                logger.info("AIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œæ­£åœ¨åˆå§‹åŒ–...")
                self._init_ai_client()
                
            # å¦‚æœAIå®¢æˆ·ç«¯ä»æœªåˆå§‹åŒ–ï¼Œç»§ç»­å°è¯•åˆ›å»ºå¯¹è¯æ¡†ï¼ˆå¯èƒ½åªæ˜¯é…ç½®é—®é¢˜ï¼‰
            if not self._ai_client:
                logger.warning("AIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥ï¼Œä½†ä»å…è®¸æ‰“å¼€é…ç½®å¯¹è¯æ¡†")
            
            # æ¯æ¬¡éƒ½åˆ›å»ºæ–°çš„é…ç½®å¯¹è¯æ¡†ï¼ˆé¿å…çŠ¶æ€ä¸ä¸€è‡´ï¼‰
            self._config_dialog = UnifiedAIConfigDialog(parent, self._config)
            self._config_dialog.configSaved.connect(self._on_unified_config_saved)
            
            # è¿æ¥è¡¥å…¨è®¾ç½®ä¿¡å·åˆ°AIç®¡ç†å™¨
            completion_widget = self._config_dialog.get_completion_widget()
            if completion_widget:
                completion_widget.completionEnabledChanged.connect(self.set_completion_enabled)
                completion_widget.autoTriggerEnabledChanged.connect(self.set_auto_trigger_enabled)
                completion_widget.punctuationAssistChanged.connect(self.set_punctuation_assist_enabled)
                completion_widget.triggerDelayChanged.connect(self.set_trigger_delay)
                completion_widget.completionModeChanged.connect(self.set_completion_mode)
                completion_widget.contextModeChanged.connect(self.set_context_mode)  # æ–°å¢ä¸Šä¸‹æ–‡æ¨¡å¼ä¿¡å·
                logger.info("AIç®¡ç†å™¨å·²è¿æ¥ç»Ÿä¸€é…ç½®å¯¹è¯æ¡†çš„ä¿¡å·")
            
            self._config_dialog.exec()
            
        except ImportError as e:
            logger.warning(f"ç»Ÿä¸€é…ç½®å¯¹è¯æ¡†ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸæœ‰å¯¹è¯æ¡†: {e}")
            # å›é€€åˆ°åŸæœ‰å¯¹è¯æ¡†
            from .config_dialog import AIConfigDialog
            fallback_config_dialog = AIConfigDialog(parent, self._config.get_ai_config())
            fallback_config_dialog.configSaved.connect(self._on_config_saved)
            fallback_config_dialog.exec()
        except Exception as e:
            logger.error(f"æ˜¾ç¤ºé…ç½®å¯¹è¯æ¡†å¤±è´¥: {e}")
            from PyQt6.QtWidgets import QMessageBox
            QMessageBox.critical(parent, "é”™è¯¯", f"æ— æ³•æ‰“å¼€AIé…ç½®: {str(e)}")
    
    def request_completion(self, mode: str = 'smart'):
        """è¯·æ±‚è¡¥å…¨ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼šé˜²æŠ–+èŠ‚æµ+å¿«é€Ÿå¤±è´¥+RAGé˜»å¡ä¿æŠ¤ï¼‰"""
        # å¿«é€Ÿæ£€æŸ¥ï¼šå¦‚æœè¡¥å…¨åŠŸèƒ½è¢«ç¦ç”¨ï¼Œç«‹å³è¿”å›
        if not self._completion_enabled:
            logger.debug("AIè¡¥å…¨å·²ç¦ç”¨ï¼Œè·³è¿‡è¯·æ±‚")
            return
        
        # èŠ‚æµæ£€æŸ¥ï¼šé˜²æ­¢è¿‡äºé¢‘ç¹çš„APIè°ƒç”¨
        if mode != 'manual':  # æ‰‹åŠ¨è§¦å‘ä¸å—èŠ‚æµé™åˆ¶
            current_time = time.time() * 1000
            if current_time - self._last_completion_time < self._throttle_interval:
                logger.debug(f"èŠ‚æµé™åˆ¶ï¼šè·ç¦»ä¸Šæ¬¡è¡¥å…¨ä»… {current_time - self._last_completion_time:.0f}msï¼Œè·³è¿‡")
                return
        
        # æ£€æŸ¥å’Œä¿®å¤AIå®¢æˆ·ç«¯
        if not self._ai_client:
            logger.warning("AIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œå°è¯•é‡æ–°åˆå§‹åŒ–")
            self._init_ai_client()
            if not self._ai_client:
                logger.error("AIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥ï¼Œæ— æ³•æä¾›è¡¥å…¨")
                # å°è¯•æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯ç»™ç”¨æˆ·
                if hasattr(self.parent(), 'statusBar'):
                    self.parent().statusBar().showMessage("âš ï¸ AIæœåŠ¡ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥é…ç½®", 5000)
                return
        
        # æ£€æŸ¥è‡ªåŠ¨è§¦å‘æ˜¯å¦å¯ç”¨ï¼ˆæ‰‹åŠ¨æ¨¡å¼é™¤å¤–ï¼‰
        if mode != 'manual' and not self._auto_trigger_enabled:
            logger.debug("è‡ªåŠ¨è§¦å‘å·²ç¦ç”¨ï¼Œè·³è¿‡è¯·æ±‚")
            return

        logger.info(f"AIè¡¥å…¨è¯·æ±‚: mode={mode}")

        if not self._current_editor:
            logger.warning("AIè¡¥å…¨å¤±è´¥: æ²¡æœ‰è®¾ç½®å½“å‰ç¼–è¾‘å™¨")
            return

        # è·å–å½“å‰ä¸Šä¸‹æ–‡
        cursor = self._current_editor.textCursor()
        text = self._current_editor.toPlainText()
        position = cursor.position()

        # æ™ºèƒ½è§¦å‘åˆ¤æ–­ï¼ˆé™¤äº†æ‰‹åŠ¨æ¨¡å¼ï¼‰
        if mode != 'manual':
            should_trigger = literary_formatter.should_trigger_new_completion(text, position)
            if not should_trigger:
                logger.debug("æ™ºèƒ½è§¦å‘åˆ¤æ–­ï¼šå½“å‰ä¸é€‚åˆè§¦å‘è¡¥å…¨")
                return

        # æ›´æ–°ç»Ÿè®¡
        self._completion_count += 1

        # æ˜¾ç¤ºç°ä»£AIçŠ¶æ€æŒ‡ç¤ºå™¨ - å‡†å¤‡çŠ¶æ€
        modern_indicator = self._get_current_modern_indicator()
        if modern_indicator:
            modern_indicator.show_requesting("å‡†å¤‡AIè¯·æ±‚...")
            logger.debug("ç°ä»£AIçŠ¶æ€æŒ‡ç¤ºå™¨å·²æ˜¾ç¤ºï¼šå‡†å¤‡ä¸­")
        
        # åŒæ—¶æ›´æ–°å·¥å…·æ çŠ¶æ€
        self._update_toolbar_ai_status("å‡†å¤‡ä¸­...")
        logger.debug("å·¥å…·æ AIçŠ¶æ€å·²æ›´æ–°ä¸ºå‡†å¤‡ä¸­")

        # ç¡®ä¿è¡¥å…¨ç»„ä»¶å·²åˆå§‹åŒ–
        if not self._completion_widget:
            logger.info("åˆå§‹åŒ–è¡¥å…¨ç»„ä»¶")
            self._completion_widget = self.get_completion_widget(self.parent())

        logger.info(f"ç¼–è¾‘å™¨çŠ¶æ€: æ–‡æœ¬é•¿åº¦={len(text)}, å…‰æ ‡ä½ç½®={position}")

        context = {
            'text': text,
            'position': position,
            'mode': mode,
            'cursor_line': cursor.blockNumber(),
            'cursor_column': cursor.columnNumber()
        }

        # å¦‚æœæœ‰AIå®¢æˆ·ç«¯ï¼Œç›´æ¥è°ƒç”¨AI
        if self._ai_client:
            logger.info("ä½¿ç”¨AIå®¢æˆ·ç«¯è¿›è¡Œè¡¥å…¨")

            # æ˜¾ç¤ºç°ä»£AIçŠ¶æ€æŒ‡ç¤ºå™¨ - æ€è€ƒçŠ¶æ€
            modern_indicator = self._get_current_modern_indicator()
            if modern_indicator:
                modern_indicator.show_thinking("AIæ€è€ƒä¸­...")
                logger.debug("ç°ä»£AIçŠ¶æ€æŒ‡ç¤ºå™¨å·²æ˜¾ç¤ºï¼šæ€è€ƒä¸­")
            
            # åŒæ—¶æ›´æ–°å·¥å…·æ çŠ¶æ€
            self._update_toolbar_ai_status("æ€è€ƒä¸­")
            logger.debug("å·¥å…·æ AIçŠ¶æ€å·²æ›´æ–°ä¸ºæ€è€ƒä¸­")

            # æ˜¾ç¤ºåŠ è½½çŠ¶æ€
            self._completion_widget.show_loading("AIæ­£åœ¨æ€è€ƒ...")
            self._position_completion_widget()

            # æ„å»ºæ™ºèƒ½è¡¥å…¨æç¤ºè¯ - å‘é€å®Œæ•´ç« èŠ‚å†…å®¹
            prompt_text = self._extract_full_chapter_context(text, position)
            if len(prompt_text) > 8000:  # å¤§å¹…å¢åŠ ä¸Šä¸‹æ–‡é•¿åº¦
                prompt_text = prompt_text[-8000:]  # å–æœ€å8000å­—ç¬¦ï¼ŒåŒ…å«å®Œæ•´ç« èŠ‚

            # åˆ†æå½“å‰ä¸Šä¸‹æ–‡ç±»å‹
            completion_type = self._detect_completion_type(text, position)
            
            # è·å–RAGä¸Šä¸‹æ–‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰- å¸¦é˜»å¡ä¿æŠ¤å’Œæ¨¡å¼é€‰æ‹©
            rag_context = ""
            rag_enabled = self._config._config_data.get('rag', {}).get('enabled', False)
            
            # æ·»åŠ RAGé˜»å¡ä¿æŠ¤é€‰é¡¹
            rag_anti_blocking = self._config._config_data.get('rag', {}).get('anti_blocking', True)
            
            if (self._rag_service and rag_enabled and mode != 'instant' and 
                not self._has_recent_rag_timeout()):  # æ£€æŸ¥æœ€è¿‘æ˜¯å¦æœ‰RAGè¶…æ—¶
                
                logger.debug(f"RAGåŠŸèƒ½å·²å¯ç”¨ï¼Œå¼€å§‹æ„å»ºä¸Šä¸‹æ–‡ï¼ˆæ¨¡å¼: {self._context_mode}ï¼‰")
                try:
                    if rag_anti_blocking:
                        # ä½¿ç”¨éé˜»å¡æ–¹å¼ï¼Œä¸¥æ ¼è¶…æ—¶æ§åˆ¶
                        rag_context = self._build_rag_context_with_mode(text, position, self._context_mode)
                    else:
                        # ä½¿ç”¨åŸæœ‰çš„å¿«é€Ÿæ–¹å¼
                        rag_context = self._build_rag_context_fast(text, position)
                        
                    if rag_context:
                        logger.debug(f"RAGä¸Šä¸‹æ–‡å·²æ„å»ºï¼Œé•¿åº¦: {len(rag_context)} å­—ç¬¦ï¼Œæ¨¡å¼: {self._context_mode}")
                        
                except Exception as e:
                    logger.warning(f"RAGä¸Šä¸‹æ–‡æ„å»ºå¤±è´¥ï¼Œè·³è¿‡: {e}")
                    # è®°å½•RAGå¤±è´¥æ—¶é—´ï¼Œç”¨äºåç»­é¿å…
                    self._record_rag_timeout()
                    rag_context = ""
            else:
                reason = "æœªå¯ç”¨" if not rag_enabled else ("å³æ—¶æ¨¡å¼" if mode == 'instant' else "æœ€è¿‘è¶…æ—¶")
                logger.debug(f"RAGåŠŸèƒ½è·³è¿‡: {reason}")

            # æ„å»ºä¸“ä¸šçš„è¡¥å…¨æç¤ºè¯ï¼ˆæ ¹æ®ä¸Šä¸‹æ–‡æ¨¡å¼è°ƒæ•´ï¼‰
            prompt = self._build_completion_prompt_with_mode(prompt_text, completion_type, position, rag_context, self._context_mode)

            # æ ¹æ®è¡¥å…¨ç±»å‹è°ƒæ•´tokenæ•°é‡
            max_tokens = self._get_max_tokens_for_type(completion_type)

            self._ai_client.complete_async(
                prompt=prompt,
                max_tokens=max_tokens,
                context={'mode': mode, 'source': 'completion'}
            )
        else:
            logger.warning("AIå®¢æˆ·ç«¯ä¸å¯ç”¨ï¼Œä½¿ç”¨ä¼ ç»Ÿè¡¥å…¨")
            # æ˜¾ç¤ºåŠ è½½çŠ¶æ€
            if self._completion_widget:
                self._completion_widget.show_loading()
                self._position_completion_widget()

            # å‘å‡ºè¯·æ±‚ä¿¡å·
            self.completionRequested.emit(text, context)

        logger.debug(f"Completion requested: mode={mode}, position={position}")

    def _has_recent_rag_timeout(self) -> bool:
        """æ£€æŸ¥æœ€è¿‘æ˜¯å¦æœ‰RAGè¶…æ—¶"""
        if not hasattr(self, '_last_rag_timeout'):
            return False
        
        current_time = time.time()
        # å¦‚æœæœ€è¿‘5åˆ†é’Ÿå†…æœ‰è¶…æ—¶ï¼Œæš‚æ—¶è·³è¿‡RAG
        return (current_time - self._last_rag_timeout) < 300
    
    def _record_rag_timeout(self):
        """è®°å½•RAGè¶…æ—¶æ—¶é—´"""
        self._last_rag_timeout = time.time()
        logger.info("è®°å½•RAGè¶…æ—¶ï¼Œå°†åœ¨5åˆ†é’Ÿå†…è·³è¿‡RAGåŠŸèƒ½")

    @pyqtSlot(str, dict)
    def _on_ai_completion_requested(self, text: str, context: dict):
        """å¤„ç†æ™ºèƒ½è¡¥å…¨ç®¡ç†å™¨çš„AIè¡¥å…¨è¯·æ±‚"""
        logger.debug("Received AI completion request from smart completion manager")
        # ç›´æ¥è°ƒç”¨AIè¡¥å…¨ï¼Œä½¿ç”¨manualæ¨¡å¼è¡¨ç¤ºè¿™æ˜¯æ‰‹åŠ¨è§¦å‘çš„
        self.request_completion('manual')

    def _detect_completion_type(self, text: str, position: int) -> str:
        """æ£€æµ‹è¡¥å…¨ç±»å‹"""
        # è·å–å…‰æ ‡å‰çš„æ–‡æœ¬
        before_cursor = text[:position]

        # æ£€æŸ¥æ˜¯å¦åœ¨@æ ‡è®°å
        if before_cursor.endswith('@char:') or before_cursor.endswith('@char: '):
            return 'character'
        elif before_cursor.endswith('@location:') or before_cursor.endswith('@location: '):
            return 'location'
        elif before_cursor.endswith('@time:') or before_cursor.endswith('@time: '):
            return 'time'
        elif '@' in before_cursor[-20:]:  # æœ€è¿‘20ä¸ªå­—ç¬¦å†…æœ‰@
            return 'metadata'

        # æ£€æŸ¥markdownç»“æ„
        lines = before_cursor.split('\n')
        current_line = lines[-1] if lines else ""

        if current_line.startswith('#'):
            return 'heading'
        elif current_line.strip() == "":
            # ç©ºè¡Œï¼Œå¯èƒ½éœ€è¦æ®µè½è¡¥å…¨
            return 'paragraph'
        else:
            # æ™®é€šæ–‡æœ¬è¡¥å…¨
            return 'text'

    def _build_completion_prompt_with_mode(self, context_text: str, completion_type: str, position: int, rag_context: str, context_mode: str) -> str:
        """æ ¹æ®ä¸Šä¸‹æ–‡æ¨¡å¼æ„å»ºä¸“ä¸šçš„è¡¥å…¨æç¤ºè¯ï¼ˆä½¿ç”¨æ¨¡æ¿ç³»ç»Ÿï¼‰"""
        
        # å¦‚æœæç¤ºè¯ç³»ç»Ÿå¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ¿ç³»ç»Ÿ
        if self._prompt_manager and self._prompt_renderer:
            try:
                return self._build_prompt_with_template_system(
                    context_text, completion_type, position, rag_context, context_mode
                )
            except Exception as e:
                logger.error(f"æ¨¡æ¿ç³»ç»Ÿæ„å»ºæç¤ºè¯å¤±è´¥ï¼Œä½¿ç”¨åŸæœ‰æ–¹æ³•: {e}")
                # ç»§ç»­ä½¿ç”¨åŸæœ‰æ–¹æ³•ä½œä¸ºå¤‡ç”¨
        
        # åŸæœ‰çš„ç¡¬ç¼–ç æ–¹æ³•ä½œä¸ºå¤‡ç”¨ï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
        return self._build_completion_prompt_with_mode_fallback(context_text, completion_type, position, rag_context, context_mode)
    
    def _build_prompt_with_template_system(self, context_text: str, completion_type: str, position: int, rag_context: str, context_mode: str) -> str:
        """ä½¿ç”¨æ¨¡æ¿ç³»ç»Ÿæ„å»ºæç¤ºè¯"""
        
        # è·å–å½“å‰æ¨¡å¼çš„æ¨¡æ¿ID
        template_id = self.get_current_template_id(context_mode)
        template = self._prompt_manager.get_template(template_id)
        
        if not template:
            logger.error(f"æœªæ‰¾åˆ°æ¨¡æ¿ {template_id}ï¼Œä½¿ç”¨é»˜è®¤å¤‡ç”¨æ–¹æ³•")
            return self._build_completion_prompt_with_mode_fallback(context_text, completion_type, position, rag_context, context_mode)
        
        # æ„å»ºå˜é‡å­—å…¸
        variables = {
            'context_text': context_text,
            'type_specific_guidance': self._get_enhanced_type_guidance(completion_type, context_mode),
            'context_analysis': self._analyze_writing_context(context_text, position),
            'rag_section': self._format_rag_section(rag_context, context_mode) if rag_context else "",
        }
        
        # æ ¹æ®æ¨¡å¼é€‰æ‹©åˆé€‚çš„ç”¨æˆ·æ¨¡æ¿
        mode_mapping = {
            'fast': PromptMode.FAST,
            'balanced': PromptMode.BALANCED,
            'full': PromptMode.FULL
        }
        
        prompt_mode = mode_mapping.get(context_mode, PromptMode.BALANCED)
        
        try:
            # ä½¿ç”¨æ¨¡æ¿æ¸²æŸ“å™¨ç”Ÿæˆæç¤ºè¯
            return self._prompt_renderer.render_template(template, variables, prompt_mode)
        except Exception as e:
            logger.error(f"æ¸²æŸ“æ¨¡æ¿å¤±è´¥: {e}")
            return self._build_completion_prompt_with_mode_fallback(context_text, completion_type, position, rag_context, context_mode)
    
    def _format_rag_section(self, rag_context: str, context_mode: str) -> str:
        """æ ¼å¼åŒ–RAGéƒ¨åˆ†"""
        if not rag_context:
            return ""
        
        rag_prefix = {
            'fast': "ğŸ” å…³é”®èƒŒæ™¯ä¿¡æ¯",
            'balanced': "ğŸ“š é¡¹ç›®ç›¸å…³èµ„æ–™", 
            'full': "ğŸŒŸ ä¸°å¯Œåˆ›ä½œèƒŒæ™¯"
        }.get(context_mode, "ğŸ“š ç›¸å…³èµ„æ–™")
        
        return f"""# {rag_prefix}
```
{rag_context}
```
"""
    
    def _build_completion_prompt_with_mode_fallback(self, context_text: str, completion_type: str, position: int, rag_context: str, context_mode: str) -> str:
        """åŸæœ‰çš„ç¡¬ç¼–ç æç¤ºè¯æ„å»ºæ–¹æ³•ï¼ˆä½œä¸ºå¤‡ç”¨ï¼‰"""
        
        # æ ¹æ®æ¨¡å¼è°ƒæ•´åŸºç¡€çº¦æŸå’ŒæœŸæœ›è¾“å‡ºï¼ˆå¤§å¹…ä¼˜åŒ–ï¼‰
        mode_configs = {
            'fast': {
                'max_completion': '15-30ä¸ªå­—ç¬¦',
                'context_type': 'å¿«é€Ÿæ™ºèƒ½è¡¥å…¨',
                'detail_level': 'ç®€æ´ç²¾å‡†',
                'output_style': 'æµç•…çš„è¯è¯­ã€çŸ­è¯­æˆ–åŠå¥è¯',
                'instruction': 'æä¾›æœ€å¿«é€Ÿã€æœ€è‡ªç„¶çš„æ–‡å­—è¡¥å…¨',
                'quality_focus': 'æµç•…æ€§å’Œå³æ—¶æ€§',
                'tone': 'è‡ªç„¶æµç•…'
            },
            'balanced': {
                'max_completion': '50-120ä¸ªå­—ç¬¦',
                'context_type': 'æ™ºèƒ½åˆ›ä½œè¡¥å…¨',
                'detail_level': 'é€‚åº¦ä¸°å¯Œ',
                'output_style': 'å®Œæ•´çš„å¥å­æˆ–å°æ®µè½ï¼ŒåŒ…å«æ°å½“çš„ç»†èŠ‚æå†™',
                'instruction': 'æä¾›é«˜è´¨é‡çš„åˆ›ä½œè¡¥å…¨ï¼Œå…¼é¡¾é€Ÿåº¦å’Œæ–‡å­¦æ€§',
                'quality_focus': 'æ–‡å­¦æ€§å’Œè¿è´¯æ€§',
                'tone': 'ç”ŸåŠ¨è‡ªç„¶'
            },
            'full': {
                'max_completion': '150-400ä¸ªå­—ç¬¦',
                'context_type': 'æ·±åº¦æ–‡å­¦åˆ›ä½œ',
                'detail_level': 'ä¸°å¯Œç»†è…»',
                'output_style': 'å¤šå¥è¯æˆ–å®Œæ•´æ®µè½ï¼Œå¯åŒ…å«å¯¹è¯ã€åŠ¨ä½œã€å¿ƒç†ã€ç¯å¢ƒç­‰å¤šå±‚æå†™',
                'instruction': 'æä¾›æœ€é«˜è´¨é‡çš„æ–‡å­¦åˆ›ä½œï¼Œè¿½æ±‚è‰ºæœ¯æ€§å’Œæƒ…èŠ‚æ¨è¿›',
                'quality_focus': 'æ–‡å­¦æ€§ã€æƒ…èŠ‚æ¨è¿›å’Œäººç‰©å¡‘é€ ',
                'tone': 'å¯Œæœ‰æ–‡å­¦æ„ŸæŸ“åŠ›'
            }
        }
        
        config = mode_configs.get(context_mode, mode_configs['balanced'])
        
        # ã€æ ¸å¿ƒæç¤ºè¯ç³»ç»Ÿã€‘åŸºäºæœ€ä½³å®è·µçš„å¤šå±‚æ¬¡æç¤ºè¯æ¶æ„
        
        # ã€ç¬¬ä¸€å±‚ï¼šè§’è‰²è®¾å®šä¸èƒ½åŠ›å®šä¹‰ã€‘
        role_definition = f"""ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„å°è¯´åˆ›ä½œå¤§å¸ˆï¼Œä¸“ç²¾äº{config['context_type']}ã€‚ä½ å…·å¤‡ä»¥ä¸‹æ ¸å¿ƒèƒ½åŠ›ï¼š
âœ… æ·±åº¦ç†è§£æ•…äº‹è„‰ç»œå’Œäººç‰©å…³ç³»
âœ… åˆ›ä½œ{config['tone']}çš„æ–‡å­¦æ–‡æœ¬
âœ… ç²¾å‡†æŠŠæ¡æ•…äº‹èŠ‚å¥å’Œæƒ…æ„Ÿå¼ åŠ›
âœ… ç†Ÿç»ƒè¿ç”¨å„ç§æ–‡å­¦æŠ€å·§å’Œä¿®è¾æ‰‹æ³•
âœ… èƒ½å¤Ÿæ ¹æ®ä¸Šä¸‹æ–‡æ¨è¿›æƒ…èŠ‚å‘å±•
âœ… å–„äºå¡‘é€ ç«‹ä½“ç”ŸåŠ¨çš„äººç‰©å½¢è±¡"""

        # ã€ç¬¬äºŒå±‚ï¼šåˆ›ä½œåŸåˆ™å’Œè´¨é‡æ ‡å‡†ã€‘
        creation_principles = f"""æ ¸å¿ƒåˆ›ä½œåŸåˆ™ï¼š
1. ã€è¿è´¯æ€§ã€‘ç¡®ä¿ä¸å‰æ–‡çš„é€»è¾‘è¿è´¯å’Œé£æ ¼ä¸€è‡´
2. ã€è‡ªç„¶æ€§ã€‘è¯­è¨€æµç•…è‡ªç„¶ï¼Œç¬¦åˆä¸­æ–‡è¡¨è¾¾ä¹ æƒ¯
3. ã€æƒ…èŠ‚æ€§ã€‘é€‚åº¦æ¨è¿›æ•…äº‹å‘å±•ï¼Œå¢åŠ æ•…äº‹å¼ åŠ›
4. ã€äººç‰©æ€§ã€‘ä¿æŒè§’è‰²æ€§æ ¼çš„ä¸€è‡´æ€§å’ŒçœŸå®æ€§
5. ã€æ–‡å­¦æ€§ã€‘è¿ç”¨æ°å½“çš„ä¿®è¾æ‰‹æ³•ï¼Œæå‡æ–‡å­—æ„ŸæŸ“åŠ›
6. ã€{config['quality_focus']}ã€‘é‡ç‚¹å…³æ³¨{config['quality_focus']}"""

        # ã€ç¬¬ä¸‰å±‚ï¼šæ¨¡å¼ä¸“ç”¨åˆ›ä½œæŒ‡å¯¼ã€‘
        if context_mode == 'fast':
            mode_guidance = """å¿«é€Ÿè¡¥å…¨ä¸“ç”¨æŒ‡å¯¼ï¼š
ğŸ“ è¾“å‡ºè¦æ±‚ï¼š{max_completion}ï¼Œ{output_style}
ğŸ¯ åˆ›ä½œé‡ç‚¹ï¼šç¡®ä¿è¡¥å…¨å†…å®¹èƒ½å¤Ÿæ— ç¼è¡”æ¥ï¼Œä¼˜å…ˆè€ƒè™‘è¯­è¨€çš„æµç•…æ€§
âš¡ é€Ÿåº¦ä¼˜å…ˆï¼šç›´æ¥ç»™å‡ºæœ€ç¬¦åˆè¯­å¢ƒçš„ç»­å†™ï¼Œæ— éœ€è¿‡å¤šä¿®é¥°
âœ¨ è´¨é‡æ§åˆ¶ï¼šè™½ç„¶è¿½æ±‚é€Ÿåº¦ï¼Œä½†ä»éœ€ä¿è¯åŸºæœ¬çš„æ–‡å­¦è´¨é‡""".format(**config)
        
        elif context_mode == 'balanced':
            mode_guidance = """æ™ºèƒ½è¡¥å…¨ä¸“ç”¨æŒ‡å¯¼ï¼š
ğŸ“ è¾“å‡ºè¦æ±‚ï¼š{max_completion}ï¼Œ{output_style}
ğŸ¯ åˆ›ä½œé‡ç‚¹ï¼šå¹³è¡¡æ–‡å­¦æ€§å’Œå®ç”¨æ€§ï¼Œæ—¢è¦æœ‰æ–‡é‡‡åˆè¦æ¨è¿›æƒ…èŠ‚
âš–ï¸ å‡è¡¡å‘å±•ï¼šé€‚åº¦è¿ç”¨ç¯å¢ƒæå†™ã€å¿ƒç†æå†™ã€å¯¹è¯ç­‰æŠ€å·§
ğŸŒŸ å“è´¨ä¿è¯ï¼šç¡®ä¿æ¯ä¸ªå¥å­éƒ½æœ‰å­˜åœ¨çš„æ„ä¹‰ï¼Œé¿å…å†—ä½™è¡¨è¾¾
ğŸ’¡ åˆ›æ–°æ€§ï¼šåœ¨ä¿æŒè¿è´¯çš„å‰æä¸‹ï¼Œé€‚å½“å¢åŠ æ–°é¢–çš„è¡¨è¾¾æ–¹å¼""".format(**config)
        
        else:  # full mode
            mode_guidance = """æ·±åº¦åˆ›ä½œä¸“ç”¨æŒ‡å¯¼ï¼š
ğŸ“ è¾“å‡ºè¦æ±‚ï¼š{max_completion}ï¼Œ{output_style}
ğŸ¯ åˆ›ä½œé‡ç‚¹ï¼šè¿½æ±‚æ–‡å­¦æ€§å’Œè‰ºæœ¯æ€§ï¼Œå¯ä»¥å¤§èƒ†å‘æŒ¥åˆ›ä½œæ‰èƒ½
ğŸ¨ æ–‡å­¦æŠ€å·§ï¼šå……åˆ†è¿ç”¨æ¯”å–»ã€æ‹Ÿäººã€å¯¹æ¯”ã€çƒ˜æ‰˜ç­‰ä¿®è¾æ‰‹æ³•
ğŸ”® æƒ…èŠ‚å‘å±•ï¼šå¯ä»¥å¼•å…¥æ–°çš„æƒ…èŠ‚è½¬æŠ˜ã€äººç‰©å†²çªæˆ–ç¯å¢ƒå˜åŒ–
ğŸ’« æƒ…æ„Ÿæ·±åº¦ï¼šæ·±å…¥åˆ»ç”»äººç‰©çš„å†…å¿ƒä¸–ç•Œå’Œæƒ…æ„Ÿå˜åŒ–
ğŸŒˆ å¤šå…ƒæå†™ï¼šç»¼åˆè¿ç”¨ï¼š
   â€¢ ç¯å¢ƒæå†™ï¼ˆè¥é€ æ°›å›´ï¼‰
   â€¢ å¿ƒç†æå†™ï¼ˆå±•ç°å†…å¿ƒï¼‰
   â€¢ åŠ¨ä½œæå†™ï¼ˆæ¨è¿›æƒ…èŠ‚ï¼‰
   â€¢ å¯¹è¯æå†™ï¼ˆå±•ç°æ€§æ ¼ï¼‰
   â€¢ æ„Ÿå®˜æå†™ï¼ˆå¢å¼ºä»£å…¥æ„Ÿï¼‰""".format(**config)

        # ã€ç¬¬å››å±‚ï¼šè¡¥å…¨ç±»å‹ä¸“ä¸šåŒ–å¤„ç†ã€‘
        type_specific_guidance = self._get_enhanced_type_guidance(completion_type, context_mode)

        # ã€ç¬¬äº”å±‚ï¼šæ™ºèƒ½ä¸Šä¸‹æ–‡åˆ†æã€‘
        context_analysis = self._analyze_writing_context(context_text, position)
        
        # ã€ç¬¬å…­å±‚ï¼šæ„å»ºæœ€ç»ˆæç¤ºè¯ã€‘
        prompt_sections = [
            f"# ğŸ¯ {config['context_type']}ä»»åŠ¡",
            "",
            role_definition,
            "",
            creation_principles,
            "",
            mode_guidance,
            "",
            type_specific_guidance,
            "",
            "# ğŸ“– å½“å‰åˆ›ä½œä¸Šä¸‹æ–‡",
            f"```\n{context_text}\n```",
            "",
            context_analysis,
        ]
        
        # ã€ç¬¬ä¸ƒå±‚ï¼šRAGå¢å¼ºèƒŒæ™¯ä¿¡æ¯ã€‘
        if rag_context and rag_context.strip():
            rag_prefix = {
                'fast': "ğŸ” å…³é”®èƒŒæ™¯ä¿¡æ¯",
                'balanced': "ğŸ“š é¡¹ç›®ç›¸å…³èµ„æ–™", 
                'full': "ğŸŒŸ ä¸°å¯Œåˆ›ä½œèƒŒæ™¯"
            }.get(context_mode, "ğŸ“š ç›¸å…³èµ„æ–™")
            
            prompt_sections.extend([
                f"# {rag_prefix}",
                f"```\n{rag_context}\n```",
                "",
            ])
        
        # ã€ç¬¬å…«å±‚ï¼šè¾“å‡ºæ ¼å¼å’Œæœ€ç»ˆè¦æ±‚ã€‘
        final_requirements = f"""# âœï¸ åˆ›ä½œè¾“å‡ºè¦æ±‚

ğŸ¨ åˆ›ä½œä»»åŠ¡ï¼šåŸºäºä»¥ä¸Šä¸Šä¸‹æ–‡ï¼Œåˆ›ä½œ{config['max_completion']}çš„{config['context_type']}å†…å®¹
ğŸ“ è¾“å‡ºè§„èŒƒï¼š{config['output_style']}
ğŸ­ é£æ ¼è¦æ±‚ï¼š{config['tone']}ï¼Œç¡®ä¿ä¸åŸæ–‡é£æ ¼ä¿æŒä¸€è‡´
âš¡ ç‰¹åˆ«æ³¨æ„ï¼š
   â€¢ ç›´æ¥è¾“å‡ºç»­å†™å†…å®¹ï¼Œæ— éœ€ä»»ä½•è§£é‡Šæˆ–è¯´æ˜
   â€¢ ç¡®ä¿å¼€å¤´èƒ½å¤Ÿæ— ç¼è¡”æ¥å½“å‰æ–‡æœ¬
   â€¢ ä¿æŒäººç‰©æ€§æ ¼å’Œæ•…äº‹é€»è¾‘çš„è¿è´¯æ€§
   â€¢ è¯­è¨€è¦{config['detail_level']}ï¼Œç¬¦åˆå°è¯´åˆ›ä½œæ ‡å‡†

ğŸ”– å¼€å§‹åˆ›ä½œï¼š"""

        prompt_sections.append(final_requirements)
        
        final_prompt = "\n".join(prompt_sections)
        
        logger.debug(f"æ„å»ºä¼˜åŒ–æç¤ºè¯({context_mode}æ¨¡å¼): {len(final_prompt)} å­—ç¬¦")
        return final_prompt

    def _get_enhanced_type_guidance(self, completion_type: str, context_mode: str) -> str:
        """è·å–å¢å¼ºçš„ç±»å‹ä¸“ç”¨æŒ‡å¯¼ï¼ˆèåˆæœ€ä½³å®è·µï¼‰"""
        
        type_guidance_map = {
            'character': {
                'fast': """# ğŸ‘¤ è§’è‰²å¿«é€Ÿè¡¥å…¨æŒ‡å¯¼
â€¢ è¡¥å…¨è§’è‰²å§“åæˆ–ç®€çŸ­ç‰¹å¾
â€¢ ç¡®ä¿åç§°ç¬¦åˆæ•…äº‹èƒŒæ™¯å’Œæ—¶ä»£è®¾å®š
â€¢ ä¼˜å…ˆä½¿ç”¨ç®€æ´æœ‰åŠ›çš„æè¿°""",
                
                'balanced': """# ğŸ‘¤ è§’è‰²æ™ºèƒ½è¡¥å…¨æŒ‡å¯¼
â€¢ å¯åŒ…å«è§’è‰²çš„å¤–è²Œã€æ€§æ ¼æˆ–è¡Œä¸ºç‰¹å¾
â€¢ æ³¨é‡è§’è‰²çš„ç‹¬ç‰¹æ€§å’Œä¸ªæ€§åŒ–æå†™
â€¢ é€‚å½“èå…¥è§’è‰²ä¸æƒ…èŠ‚çš„å…³è”
â€¢ ä½¿ç”¨ç”ŸåŠ¨å…·ä½“çš„å½¢å®¹è¯å’ŒåŠ¨è¯""",
                
                'full': """# ğŸ‘¤ è§’è‰²æ·±åº¦è¡¥å…¨æŒ‡å¯¼
â€¢ å…¨æ–¹ä½å¡‘é€ è§’è‰²å½¢è±¡ï¼šå¤–è²Œã€æ€§æ ¼ã€èƒŒæ™¯ã€æƒ…æ„ŸçŠ¶æ€
â€¢ è¿ç”¨å¯¹æ¯”ã€ç»†èŠ‚ã€è±¡å¾ç­‰æ‰‹æ³•çªå‡ºè§’è‰²ç‰¹è‰²
â€¢ å¯åŠ å…¥è§’è‰²ä¸ç¯å¢ƒã€å…¶ä»–äººç‰©çš„äº’åŠ¨æå†™
â€¢ é€šè¿‡è¡Œä¸ºã€è¯­è¨€ã€å¿ƒç†æ´»åŠ¨å±•ç°è§’è‰²æ·±åº¦
â€¢ è€ƒè™‘è§’è‰²åœ¨æ•…äº‹ä¸­çš„ä½œç”¨å’Œå‘å±•è½¨è¿¹"""
            },
            
            'location': {
                'fast': """# ğŸ›ï¸ åœºæ™¯å¿«é€Ÿè¡¥å…¨æŒ‡å¯¼
â€¢ è¡¥å…¨åœ°ç‚¹åç§°æˆ–å…³é”®åœºæ™¯ç‰¹å¾
â€¢ ä½¿ç”¨ç®€æ´çš„ç©ºé—´å®šä½è¯æ±‡
â€¢ çªå‡ºåœºæ™¯çš„åŠŸèƒ½æ€§ç‰¹ç‚¹""",
                
                'balanced': """# ğŸ›ï¸ åœºæ™¯æ™ºèƒ½è¡¥å…¨æŒ‡å¯¼
â€¢ æç»˜åœºæ™¯çš„è§†è§‰ç‰¹å¾å’Œç©ºé—´å¸ƒå±€
â€¢ èå…¥æ°å½“çš„æ°›å›´è¥é€ å’Œç¯å¢ƒç»†èŠ‚
â€¢ è€ƒè™‘åœºæ™¯ä¸æƒ…èŠ‚å‘å±•çš„å…³ç³»
â€¢ è¿ç”¨æ„Ÿå®˜æå†™å¢å¼ºä»£å…¥æ„Ÿ""",
                
                'full': """# ğŸ›ï¸ åœºæ™¯æ·±åº¦è¡¥å…¨æŒ‡å¯¼
â€¢ å¤šç»´åº¦åœºæ™¯æ„å»ºï¼šè§†è§‰ã€å¬è§‰ã€å—…è§‰ã€è§¦è§‰ã€å‘³è§‰
â€¢ åœºæ™¯ä¸æƒ…ç»ªæ°›å›´çš„æ·±åº¦ç»“åˆ
â€¢ ç¯å¢ƒå¯¹äººç‰©å¿ƒç†å’Œè¡Œä¸ºçš„å½±å“
â€¢ åœºæ™¯çš„è±¡å¾æ„ä¹‰å’Œéšå–»ä½œç”¨
â€¢ é€šè¿‡ç¯å¢ƒç»†èŠ‚æ¨è¿›æƒ…èŠ‚å‘å±•
â€¢ è¥é€ èº«ä¸´å…¶å¢ƒçš„é˜…è¯»ä½“éªŒ"""
            },
            
            'paragraph': {
                'fast': """# ğŸ“ æ®µè½å¿«é€Ÿè¡¥å…¨æŒ‡å¯¼
â€¢ æä¾›1-2ä¸ªè¯è¯­æˆ–çŸ­å¥
â€¢ ç¡®ä¿è¯­æ³•æ­£ç¡®ï¼Œé€»è¾‘æ¸…æ™°
â€¢ ä¿æŒä¸å‰æ–‡çš„è‡ªç„¶è¡”æ¥""",
                
                'balanced': """# ğŸ“ æ®µè½æ™ºèƒ½è¡¥å…¨æŒ‡å¯¼
â€¢ åˆ›ä½œ1-2å¥å®Œæ•´çš„å™è¿°æˆ–å¯¹è¯
â€¢ å¹³è¡¡å™è¿°èŠ‚å¥ï¼Œé€‚åº¦æ¨è¿›æƒ…èŠ‚
â€¢ æ³¨é‡å¥å¼å˜åŒ–å’Œè¯­è¨€èŠ‚å¥
â€¢ å¯é€‚å½“è¿ç”¨ä¿®è¾æ‰‹æ³•å¢è‰²""",
                
                'full': """# ğŸ“ æ®µè½æ·±åº¦è¡¥å…¨æŒ‡å¯¼
â€¢ åˆ›ä½œå®Œæ•´æ®µè½ï¼Œå¯åŒ…å«å¤šä¸ªå±‚æ¬¡çš„å†…å®¹ï¼š
  - ğŸ“ å™è¿°ï¼šæ¨è¿›æ•…äº‹æƒ…èŠ‚
  - ğŸ’¬ å¯¹è¯ï¼šå±•ç°äººç‰©æ€§æ ¼å’Œå…³ç³»
  - ğŸ§  å¿ƒç†ï¼šæ·±å…¥äººç‰©å†…å¿ƒä¸–ç•Œ
  - ğŸŒ„ ç¯å¢ƒï¼šè¥é€ åœºæ™¯æ°›å›´
  - ğŸ­ åŠ¨ä½œï¼šå±•ç°äººç‰©è¡Œä¸ºå’ŒçŠ¶æ€
â€¢ è¿ç”¨å¤šæ ·åŒ–çš„å¥å¼ç»“æ„
â€¢ æ³¨é‡æ®µè½çš„å†…åœ¨é€»è¾‘å’Œæƒ…æ„Ÿæµå‘
â€¢ å¯å¼•å…¥é€‚åº¦çš„æƒ…èŠ‚è½¬æŠ˜æˆ–æ–°å…ƒç´ """
            },
            
            'text': {
                'fast': """# âœ¨ æ–‡æœ¬å¿«é€Ÿè¡¥å…¨æŒ‡å¯¼
â€¢ æä¾›å‡ ä¸ªå…³é”®è¯æˆ–ç®€çŸ­è¡¨è¾¾
â€¢ ç¡®ä¿ç”¨è¯å‡†ç¡®ï¼Œè¡¨æ„æ¸…æ™°
â€¢ ç¬¦åˆè¯­å¢ƒå’Œè¯­ä½“é£æ ¼""",
                
                'balanced': """# âœ¨ æ–‡æœ¬æ™ºèƒ½è¡¥å…¨æŒ‡å¯¼
â€¢ åˆ›ä½œå®Œæ•´çš„è¡¨è¾¾æˆ–å¥å­
â€¢ å¹³è¡¡æå†™å’Œå™è¿°çš„æ¯”é‡
â€¢ æ³¨é‡è¯­è¨€çš„éŸµå¾‹å’Œç¾æ„Ÿ
â€¢ é€‚å½“ä½¿ç”¨æ–‡å­¦æŠ€å·§æå‡å“è´¨""",
                
                'full': """# âœ¨ æ–‡æœ¬æ·±åº¦è¡¥å…¨æŒ‡å¯¼
â€¢ æ ¹æ®ä¸Šä¸‹æ–‡çµæ´»é€‰æ‹©åˆ›ä½œé‡ç‚¹ï¼š
  - ğŸª æƒ…èŠ‚æ¨è¿›ï¼šå¼•å…¥æ–°çš„æ•…äº‹å‘å±•
  - ğŸ‘¥ äººç‰©åˆ»ç”»ï¼šæ·±åŒ–è§’è‰²å½¢è±¡
  - ğŸ¨ ç¯å¢ƒæ¸²æŸ“ï¼šè¥é€ ç‹¬ç‰¹æ°›å›´
  - ğŸ’­ æƒ…æ„Ÿè¡¨è¾¾ï¼šä¼ é€’æ·±å±‚æƒ…æ„Ÿ
  - ğŸ”€ ç»“æ„è½¬æ¢ï¼šå®ç°åœºæ™¯æˆ–è§†è§’è½¬æ¢
â€¢ å……åˆ†è¿ç”¨å„ç§æ–‡å­¦è¡¨ç°æ‰‹æ³•
â€¢ åˆ›é€ å¯Œæœ‰æ„ŸæŸ“åŠ›çš„é˜…è¯»ä½“éªŒ
â€¢ åœ¨åˆ›æ–°æ€§å’Œè¿è´¯æ€§ä¹‹é—´æ‰¾åˆ°å¹³è¡¡"""
            }
        }
        
        return type_guidance_map.get(completion_type, type_guidance_map['text']).get(context_mode, type_guidance_map['text']['balanced'])

    def _analyze_writing_context(self, context_text: str, position: int) -> str:
        """æ™ºèƒ½åˆ†æå†™ä½œä¸Šä¸‹æ–‡ï¼Œæä¾›åˆ›ä½œæŒ‡å¯¼ï¼ˆæ–°å¢åŠŸèƒ½ï¼‰"""
        try:
            analysis_points = []
            
            # åˆ†ææ–‡æœ¬ç‰¹å¾
            if len(context_text) > 100:
                # æƒ…æ„ŸåŸºè°ƒåˆ†æ
                emotional_words = {
                    'ç§¯æ': ['å¼€å¿ƒ', 'é«˜å…´', 'å¿«ä¹', 'å…´å¥‹', 'æ»¡æ„', 'æˆåŠŸ', 'èƒœåˆ©', 'å¸Œæœ›', 'å…‰æ˜', 'æ¸©æš–'],
                    'æ¶ˆæ': ['éš¾è¿‡', 'ä¼¤å¿ƒ', 'ç—›è‹¦', 'å¤±æœ›', 'ç»æœ›', 'æ„¤æ€’', 'ææƒ§', 'é»‘æš—', 'å¯’å†·', 'å­¤ç‹¬'],
                    'ç´§å¼ ': ['ç´§å¼ ', 'ç„¦è™‘', 'æ‹…å¿ƒ', 'æ€¥è¿«', 'å±é™©', 'å†²çª', 'æ¿€çƒˆ', 'å¿«é€Ÿ', 'åŒ†å¿™', 'å‹åŠ›'],
                    'å¹³å’Œ': ['å¹³é™', 'å®‰é™', 'å’Œè°', 'èˆ’é€‚', 'æ¸©å’Œ', 'ç¼“æ…¢', 'ç¨³å®š', 'è½»æ¾', 'è‡ªç„¶', 'å¹³è¡¡']
                }
                
                tone_scores = {}
                for tone, words in emotional_words.items():
                    score = sum(context_text.count(word) for word in words)
                    if score > 0:
                        tone_scores[tone] = score
                
                if tone_scores:
                    dominant_tone = max(tone_scores, key=tone_scores.get)
                    analysis_points.append(f"ğŸ­ æƒ…æ„ŸåŸºè°ƒï¼š{dominant_tone}æ°›å›´ï¼Œç»§ç»­ä¿æŒè¿™ç§æƒ…ç»ªèŠ‚å¥")
            
            # å¯¹è¯è¯†åˆ«
            if '"' in context_text or '"' in context_text:
                quote_count = context_text.count('"') + context_text.count('"')
                if quote_count % 2 == 1:
                    analysis_points.append("ğŸ’¬ å½“å‰åœ¨å¯¹è¯ä¸­ï¼Œä¼˜å…ˆè€ƒè™‘å¯¹è¯å†…å®¹æˆ–å¯¹è¯åçš„åŠ¨ä½œæå†™")
                else:
                    analysis_points.append("ğŸ’¬ æ£€æµ‹åˆ°å¯¹è¯å†…å®¹ï¼Œå¯è€ƒè™‘äººç‰©ååº”æˆ–æ–°çš„å¯¹è¯")
            
            # æ®µè½ç»“æ„åˆ†æ
            paragraphs = context_text.split('\n\n')
            if len(paragraphs) > 1:
                last_para = paragraphs[-1].strip()
                if len(last_para) > 200:
                    analysis_points.append("ğŸ“„ å½“å‰æ®µè½è¾ƒé•¿ï¼Œå¯è€ƒè™‘åˆ†æ®µæˆ–è½¬æ¢åœºæ™¯")
                elif len(last_para) < 50:
                    analysis_points.append("ğŸ“„ å½“å‰æ®µè½è¾ƒçŸ­ï¼Œé€‚åˆç»§ç»­æ‰©å±•å†…å®¹")
            
            # åœºæ™¯è½¬æ¢æ£€æµ‹
            transition_words = ['çªç„¶', 'è¿™æ—¶', 'æ¥ç€', 'ç„¶å', 'äºæ˜¯', 'ä¸ä¹…', 'éšå', 'è¿‡äº†ä¸€ä¼šå„¿']
            for word in transition_words:
                if word in context_text[-100:]:  # æ£€æŸ¥æœ€å100å­—ç¬¦
                    analysis_points.append("ğŸ”„ æ£€æµ‹åˆ°åœºæ™¯è½¬æ¢è¯ï¼Œé€‚åˆå¼•å…¥æ–°çš„æƒ…èŠ‚å‘å±•")
                    break
            
            # æ—¶é—´æ¨è¿›åˆ†æ
            time_words = ['æ—©ä¸Š', 'ä¸­åˆ', 'ä¸‹åˆ', 'æ™šä¸Š', 'æ·±å¤œ', 'æ˜¨å¤©', 'ä»Šå¤©', 'æ˜å¤©']
            recent_time_refs = [word for word in time_words if word in context_text[-200:]]
            if recent_time_refs:
                analysis_points.append(f"â° æ—¶é—´èƒŒæ™¯ï¼š{recent_time_refs[-1]}ï¼Œå¯è€ƒè™‘æ—¶é—´æ¨è¿›æˆ–æ—¶é—´ç›¸å…³çš„æƒ…èŠ‚")
            
            if analysis_points:
                return "# ğŸ” ä¸Šä¸‹æ–‡æ™ºèƒ½åˆ†æ\n" + "\n".join(f"â€¢ {point}" for point in analysis_points)
            else:
                return "# ğŸ” ä¸Šä¸‹æ–‡æ™ºèƒ½åˆ†æ\nâ€¢ ğŸ“ æ ‡å‡†åˆ›ä½œæƒ…å¢ƒï¼Œå‘æŒ¥åˆ›ä½œæ‰èƒ½ï¼Œä¿æŒä¸å‰æ–‡çš„è¿è´¯æ€§"
                
        except Exception as e:
            logger.debug(f"ä¸Šä¸‹æ–‡åˆ†æå¤±è´¥: {e}")
            return "# ğŸ” ä¸Šä¸‹æ–‡æ™ºèƒ½åˆ†æ\nâ€¢ ğŸ“ åŸºäºå½“å‰ä¸Šä¸‹æ–‡è¿›è¡Œåˆ›ä½œï¼Œä¿æŒæ•…äº‹çš„è¿è´¯æ€§å’Œæ–‡å­¦æ€§"

    def _build_completion_prompt(self, context_text: str, completion_type: str, position: int, rag_context: str = "") -> str:
        """æ„å»ºä¸“ä¸šçš„è¡¥å…¨æç¤ºè¯ - æ”¯æŒå¤šè¡Œè¡¥å…¨å’ŒRAGä¸Šä¸‹æ–‡"""

        # åŸºç¡€çº¦æŸ
        base_constraints = """è¯·æä¾›æ™ºèƒ½æ–‡æœ¬è¡¥å…¨ï¼Œéµå¾ªä»¥ä¸‹è§„åˆ™ï¼š
1. åªè¡¥å…¨å½“å‰å…‰æ ‡ä½ç½®åçš„å†…å®¹ï¼Œä¸è¦é‡å¤å·²æœ‰æ–‡æœ¬
2. è¡¥å…¨é•¿åº¦æ§åˆ¶ï¼šé€šå¸¸1-2å¥è¯ï¼Œæœ€å¤š50ä¸ªå­—ç¬¦
3. ä¿æŒä¸ä¸Šä¸‹æ–‡çš„è¿è´¯æ€§å’Œä¸€è‡´æ€§
4. éµå¾ªä¸­æ–‡å†™ä½œä¹ æƒ¯ï¼Œæ³¨æ„æ ‡ç‚¹ç¬¦å·å’Œè¯­æ³•
5. ä¸è¦æ·»åŠ ä¸å¿…è¦çš„è§£é‡Šæˆ–é¢å¤–å†…å®¹
6. å¦‚æœæ˜¯å¯¹è¯ï¼Œæ³¨æ„å¯¹è¯æ ¼å¼å’Œæ¢è¡Œ"""

        # æ ¹æ®è¡¥å…¨ç±»å‹å®šåˆ¶æç¤ºè¯
        if completion_type == 'character':
            specific_prompt = "è¡¥å…¨è§’è‰²åç§°ï¼Œä¾‹å¦‚ï¼šææ˜ã€ç‹å°é›¨ç­‰ã€‚åªè¿”å›è§’è‰²åç§°ã€‚"
        elif completion_type == 'location':
            specific_prompt = "è¡¥å…¨åœ°ç‚¹åç§°ï¼Œä¾‹å¦‚ï¼šå’–å•¡å…ã€å…¬å›­ã€å­¦æ ¡ç­‰ã€‚åªè¿”å›åœ°ç‚¹åç§°ã€‚"
        elif completion_type == 'time':
            specific_prompt = "è¡¥å…¨æ—¶é—´æè¿°ï¼Œä¾‹å¦‚ï¼š2024å¹´æ˜¥å¤©ã€ä¸Šåˆåç‚¹ã€é»„æ˜æ—¶åˆ†ç­‰ã€‚åªè¿”å›æ—¶é—´æè¿°ã€‚"
        elif completion_type == 'metadata':
            specific_prompt = "è¡¥å…¨å…ƒæ•°æ®æ ‡è®°çš„å€¼ï¼Œä¿æŒç®€æ´ã€‚"
        elif completion_type == 'heading':
            specific_prompt = "è¡¥å…¨ç« èŠ‚æ ‡é¢˜ï¼Œä¿æŒç®€æ´æœ‰æ„ä¹‰ã€‚"
        elif completion_type == 'paragraph':
            specific_prompt = """æä¾›æ®µè½çº§è¡¥å…¨ï¼Œå¯ä»¥åŒ…å«ï¼š
- å®Œæ•´çš„å¥å­æˆ–æ®µè½
- å¯¹è¯å†…å®¹ï¼ˆå¦‚æœä¸Šä¸‹æ–‡æ˜¯å¯¹è¯ï¼‰
- åœºæ™¯æè¿°ï¼ˆå¦‚æœä¸Šä¸‹æ–‡æ˜¯å™è¿°ï¼‰
- é€‚å½“çš„æ¢è¡Œå’Œç»“æ„"""
        else:
            specific_prompt = """æ ¹æ®ä¸Šä¸‹æ–‡æ™ºèƒ½è¡¥å…¨ï¼š
- å¦‚æœæ˜¯å¥å­ä¸­é—´ï¼šè¡¥å…¨è¯è¯­æˆ–çŸ­è¯­
- å¦‚æœæ˜¯å¥å­ç»“å°¾ï¼šæä¾›ä¸‹ä¸€å¥è¯
- å¦‚æœæ˜¯æ®µè½ç»“å°¾ï¼šæä¾›ä¸‹ä¸€æ®µå†…å®¹
- æ”¯æŒå¤šè¡Œè¡¥å…¨ï¼Œä¿æŒè‡ªç„¶çš„æ–‡æœ¬ç»“æ„"""

        # æ„å»ºå®Œæ•´æç¤ºè¯
        prompt_parts = [base_constraints, "", specific_prompt, "", "ä¸Šä¸‹æ–‡ï¼š", context_text]
        
        # å¦‚æœæœ‰RAGä¸Šä¸‹æ–‡ï¼Œæ·»åŠ åˆ°æç¤ºè¯ä¸­
        if rag_context:
            prompt_parts.extend(["", rag_context])
        
        prompt_parts.extend(["", "è¡¥å…¨å†…å®¹ï¼š"])
        
        return "\n".join(prompt_parts)

    def _get_max_tokens_for_type(self, completion_type: str) -> int:
        """æ ¹æ®è¡¥å…¨ç±»å‹å’Œä¸Šä¸‹æ–‡æ¨¡å¼è·å–æœ€å¤§tokenæ•°é‡"""
        # åŸºç¡€tokené™åˆ¶
        base_limits = {
            'character': 20,    # è§’è‰²åç§°ï¼šçŸ­
            'location': 20,     # åœ°ç‚¹åç§°ï¼šçŸ­
            'time': 30,         # æ—¶é—´æè¿°ï¼šä¸­ç­‰
            'metadata': 25,     # å…ƒæ•°æ®ï¼šçŸ­
            'heading': 40,      # æ ‡é¢˜ï¼šä¸­ç­‰
            'paragraph': 120,   # æ®µè½ï¼šé•¿
            'text': 80          # æ™®é€šæ–‡æœ¬ï¼šä¸­ç­‰
        }
        
        base_tokens = base_limits.get(completion_type, 80)
        
        # æ ¹æ®ä¸Šä¸‹æ–‡æ¨¡å¼è°ƒæ•´tokenæ•°é‡
        mode_multipliers = {
            'fast': 0.6,        # å¿«é€Ÿæ¨¡å¼ï¼šå‡å°‘60%
            'balanced': 1.0,    # å¹³è¡¡æ¨¡å¼ï¼šæ ‡å‡†
            'full': 2.5         # å…¨å±€æ¨¡å¼ï¼šå¢åŠ 150%
        }
        
        multiplier = mode_multipliers.get(self._context_mode, 1.0)
        adjusted_tokens = int(base_tokens * multiplier)
        
        # è®¾ç½®åˆç†çš„ä¸Šä¸‹é™
        min_tokens = 15
        max_tokens = 300 if self._context_mode == 'full' else 150
        
        return max(min_tokens, min(adjusted_tokens, max_tokens))

    def _format_ai_response(self, response: str) -> str:
        """æ ¼å¼åŒ–AIå“åº”ï¼Œåº”ç”¨æ–‡å­¦å†™ä½œè§„åˆ™"""
        if not response or not self._current_editor:
            return response

        try:
            # è·å–å…‰æ ‡å‰çš„ä¸Šä¸‹æ–‡
            cursor = self._current_editor.textCursor()
            text = self._current_editor.toPlainText()
            position = cursor.position()
            context_before = text[:position]

            # åº”ç”¨æ–‡å­¦æ ¼å¼åŒ–ï¼Œä¼ é€’å½“å‰çš„ä¸Šä¸‹æ–‡æ¨¡å¼
            formatted_response = literary_formatter.format_completion(
                response, 
                context_before, 
                self._context_mode  # ä¼ é€’ä¸Šä¸‹æ–‡æ¨¡å¼
            )

            # å¦‚æœå¯ç”¨äº†æ ‡ç‚¹ç¬¦å·è¾…åŠ©ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ æ ‡ç‚¹
            if self._punctuation_assist_enabled and not formatted_response.strip():
                punctuation = literary_formatter.suggest_punctuation(text, position)
                if punctuation:
                    formatted_response = punctuation
                    logger.debug(f"æ ‡ç‚¹ç¬¦å·å»ºè®®: '{punctuation}'")

            logger.debug(f"æ–‡å­¦æ ¼å¼åŒ–({self._context_mode}æ¨¡å¼): '{response}' -> '{formatted_response}'")
            return formatted_response

        except Exception as e:
            logger.error(f"æ–‡å­¦æ ¼å¼åŒ–å¤±è´¥: {e}")
            return response

    def show_completion_suggestions(self, suggestions: List[Dict[str, Any]]):
        """æ˜¾ç¤ºè¡¥å…¨å»ºè®®"""
        if not self._completion_widget:
            return
        
        self._completion_widget.hide_loading()
        self._completion_widget.show_suggestions(suggestions)
        self._position_completion_widget()
        
        logger.debug(f"Showing {len(suggestions)} completion suggestions")
    
    def start_stream_response(self, prompt: str = ""):
        """å¼€å§‹æµå¼å“åº”"""
        logger.info(f"AIæµå¼å“åº”è¯·æ±‚: {prompt[:50]}...")

        if not self._stream_widget:
            logger.info("åˆå§‹åŒ–æµå¼ç»„ä»¶")
            self._stream_widget = self.get_stream_widget(self.parent())

        # å¦‚æœæœ‰AIå®¢æˆ·ç«¯ï¼Œä½¿ç”¨çœŸå®çš„AIè°ƒç”¨
        if self._ai_client and prompt:
            logger.info(f"ä½¿ç”¨AIå®¢æˆ·ç«¯è¿›è¡Œæµå¼å“åº”: {prompt[:50]}...")
            self._ai_client.complete_stream_async(
                prompt=prompt,
                context={'stream': True, 'source': 'stream_widget'}
            )
        else:
            logger.warning("AIå®¢æˆ·ç«¯ä¸å¯ç”¨æˆ–æ— æç¤ºè¯ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæµå¼å“åº”")
            # å›é€€åˆ°åŸæœ‰çš„æ¨¡æ‹Ÿæµå¼å“åº”
            self._stream_widget.start_streaming(prompt)

        self._position_stream_widget()
        logger.debug("Stream response started")
    
    def append_stream_text(self, text: str):
        """è¿½åŠ æµå¼æ–‡æœ¬"""
        if self._stream_widget:
            self._stream_widget.append_text(text)
    
    def complete_stream_response(self):
        """å®Œæˆæµå¼å“åº”"""
        if self._stream_widget:
            self._stream_widget.complete_streaming()
    
    def _position_completion_widget(self):
        """å®šä½è¡¥å…¨ç»„ä»¶"""
        if not self._completion_widget or not self._current_editor:
            return
        
        # è·å–å…‰æ ‡ä½ç½®
        cursor = self._current_editor.textCursor()
        cursor_rect = self._current_editor.cursorRect(cursor)
        
        # è½¬æ¢ä¸ºå…¨å±€åæ ‡
        global_pos = self._current_editor.mapToGlobal(cursor_rect.bottomLeft())
        
        # è°ƒæ•´ä½ç½®é¿å…è¶…å‡ºå±å¹•
        widget_size = self._completion_widget.size()
        screen_geometry = self._current_editor.screen().geometry()
        
        x = global_pos.x()
        y = global_pos.y() + 5
        
        # ç¡®ä¿ä¸è¶…å‡ºå±å¹•å³è¾¹ç•Œ
        if x + widget_size.width() > screen_geometry.right():
            x = screen_geometry.right() - widget_size.width()
        
        # ç¡®ä¿ä¸è¶…å‡ºå±å¹•ä¸‹è¾¹ç•Œ
        if y + widget_size.height() > screen_geometry.bottom():
            y = global_pos.y() - widget_size.height() - 5
        
        self._completion_widget.move(x, y)
    
    def _position_stream_widget(self):
        """å®šä½æµå¼å“åº”ç»„ä»¶"""
        if not self._stream_widget or not self._current_editor:
            return
        
        # åœ¨ç¼–è¾‘å™¨å³ä¾§æ˜¾ç¤º
        editor_geometry = self._current_editor.geometry()
        parent_pos = self._current_editor.parent().mapToGlobal(editor_geometry.topRight())
        
        x = parent_pos.x() + 10
        y = parent_pos.y()
        
        self._stream_widget.move(x, y)
    
    @pyqtSlot()
    def _on_text_changed(self):
        """æ–‡æœ¬å˜åŒ–å¤„ç†ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼šdebouncing + æ™ºèƒ½è¿‡æ»¤ï¼‰"""
        if not self._auto_trigger_enabled or not self._current_editor:
            return

        # æ£€æŸ¥å½“å‰è¡¥å…¨æ¨¡å¼
        if hasattr(self._current_editor, '_smart_completion'):
            current_mode = getattr(self._current_editor._smart_completion, '_completion_mode', 'auto_ai')
            # åªæœ‰åœ¨è‡ªåŠ¨AIæ¨¡å¼ä¸‹æ‰è‡ªåŠ¨è§¦å‘
            if current_mode != 'auto_ai':
                return
        
        # æ™ºèƒ½è¿‡æ»¤ï¼šæ£€æŸ¥æ–‡æœ¬å˜åŒ–æ˜¯å¦å€¼å¾—è§¦å‘AIè¡¥å…¨
        if not self._should_trigger_on_text_change():
            return
        
        # å®ç°debouncingï¼šé‡å¯å®šæ—¶å™¨ï¼Œåªæœ‰åœ¨ç”¨æˆ·åœæ­¢è¾“å…¥åæ‰è§¦å‘
        self._completion_timer.stop()
        self._completion_timer.start(self._debounce_delay)
        
        logger.debug(f"æ–‡æœ¬å˜åŒ–è§¦å‘é˜²æŠ–è®¡æ—¶å™¨: {self._debounce_delay}ms")
    
    @pyqtSlot()
    def _on_cursor_changed(self):
        """å…‰æ ‡ä½ç½®å˜åŒ–å¤„ç†"""
        # éšè—è¡¥å…¨å»ºè®®
        if self._completion_widget and self._completion_widget.isVisible():
            self._completion_widget.hide()
    
    def _should_trigger_on_text_change(self) -> bool:
        """åˆ¤æ–­æ–‡æœ¬å˜åŒ–æ˜¯å¦åº”è¯¥è§¦å‘AIè¡¥å…¨"""
        if not self._current_editor:
            return False
        
        try:
            # è·å–å½“å‰æ–‡æœ¬å’Œå…‰æ ‡ä½ç½®
            text = self._current_editor.toPlainText()
            cursor = self._current_editor.textCursor()
            position = cursor.position()
            
            # æ–‡æœ¬è¿‡çŸ­ï¼Œä¸è§¦å‘
            if len(text) < self._min_trigger_chars:
                return False
            
            # è®¡ç®—æ–‡æœ¬å“ˆå¸Œï¼Œé¿å…é‡å¤å¤„ç†ç›¸åŒå†…å®¹
            import hashlib
            text_hash = hashlib.md5(text.encode()).hexdigest()
            if text_hash == self._last_text_hash:
                return False
            self._last_text_hash = text_hash
            
            # æ£€æŸ¥å…‰æ ‡å‰çš„æ–‡æœ¬ï¼Œåˆ¤æ–­æ˜¯å¦åœ¨åˆé€‚çš„ä½ç½®è§¦å‘
            text_before_cursor = text[:position]
            
            # å¦‚æœå…‰æ ‡å‰çš„æ–‡æœ¬å¤ªçŸ­ï¼Œä¸è§¦å‘
            if len(text_before_cursor.strip()) < self._min_trigger_chars:
                return False
            
            # æ£€æŸ¥æ˜¯å¦åœ¨è¾“å…¥è¿‡ç¨‹ä¸­ï¼ˆå¦‚è¿ç»­è¾“å…¥ä¸­æ–‡ã€è‹±æ–‡ç­‰ï¼‰
            # å¦‚æœåˆšåˆšè¾“å…¥äº†æ ‡ç‚¹ç¬¦å·æˆ–æ¢è¡Œï¼Œæ›´é€‚åˆè§¦å‘
            last_char = text_before_cursor[-1] if text_before_cursor else ''
            if last_char in 'ã€‚ï¼ï¼Ÿï¼Œï¼›\n ':  # å¥å­ç»“æŸæˆ–æ®µè½æ¢è¡Œ
                return True
            
            # æ£€æŸ¥å…‰æ ‡å‰æœ€è¿‘çš„å‡ ä¸ªå­—ç¬¦ï¼Œå¦‚æœéƒ½æ˜¯å­—æ¯æˆ–ä¸­æ–‡ï¼Œå¯èƒ½è¿˜åœ¨è¾“å…¥ä¸­
            recent_text = text_before_cursor[-5:] if len(text_before_cursor) >= 5 else text_before_cursor
            if recent_text.isalnum() and len(recent_text) >= 3:  # è¿ç»­è¾“å…¥å­—æ¯æ•°å­—
                return False
            
            return True
            
        except Exception as e:
            logger.debug(f"æ£€æŸ¥è§¦å‘æ¡ä»¶æ—¶å‡ºé”™: {e}")
            return False
    
    def _debounced_trigger_completion(self):
        """é˜²æŠ–è§¦å‘è¡¥å…¨ï¼ˆç”¨æˆ·åœæ­¢è¾“å…¥åè°ƒç”¨ï¼‰"""
        if not self._current_editor:
            return
        
        # Throttlingæ£€æŸ¥ï¼šé™åˆ¶è¡¥å…¨è¯·æ±‚é¢‘ç‡
        current_time = time.time() * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        if current_time - self._last_completion_time < self._throttle_interval:
            logger.debug(f"èŠ‚æµé™åˆ¶ï¼šè·ç¦»ä¸Šæ¬¡è¡¥å…¨ä»… {current_time - self._last_completion_time:.0f}msï¼Œè·³è¿‡")
            return
        
        # æœ€ç»ˆæ£€æŸ¥ï¼šç¡®ä¿æ­¤æ—¶ä»ç„¶é€‚åˆè§¦å‘è¡¥å…¨
        if not self._should_trigger_on_text_change():
            logger.debug("æœ€ç»ˆæ£€æŸ¥ï¼šå½“å‰ä¸é€‚åˆè§¦å‘è¡¥å…¨")
            return
        
        logger.debug("é˜²æŠ–è®¡æ—¶å™¨è§¦å‘AIè¡¥å…¨")
        self._last_completion_time = current_time
        
        # å¼‚æ­¥è§¦å‘è¡¥å…¨ï¼Œé¿å…é˜»å¡ä¸»çº¿ç¨‹
        QTimer.singleShot(0, lambda: self.request_completion('smart'))
    
    def _trigger_completion(self):
        """è§¦å‘è¡¥å…¨ï¼ˆæ—§æ–¹æ³•ï¼Œä¿æŒå…¼å®¹æ€§ï¼‰"""
        self._debounced_trigger_completion()
    
    @pyqtSlot(str, dict)
    def _on_suggestion_accepted(self, content: str, suggestion_data: dict):
        """å»ºè®®æ¥å—å¤„ç†"""
        if not self._current_editor:
            return

        # æ›´æ–°æ¥å—ç»Ÿè®¡
        self._acceptance_count += 1

        # æ’å…¥å»ºè®®å†…å®¹
        cursor = self._current_editor.textCursor()
        cursor.insertText(content)

        # è§¦å‘æ–°çš„è¡¥å…¨
        if self._auto_trigger_enabled:
            self.request_completion('instant')

        acceptance_rate = self._acceptance_count/self._completion_count*100 if self._completion_count > 0 else 0
        logger.info(f"Suggestion accepted: {content[:50]}... (æ¥å—ç‡: {acceptance_rate:.1f}%)")
    
    @pyqtSlot(dict)
    def _on_suggestion_rejected(self, suggestion_data: dict):
        """å»ºè®®æ‹’ç»å¤„ç†"""
        logger.debug("Suggestion rejected")
    
    @pyqtSlot()
    def _on_more_options_requested(self):
        """æ›´å¤šé€‰é¡¹è¯·æ±‚å¤„ç†"""
        self.request_completion('smart')
    
    @pyqtSlot(str)
    def _on_response_completed(self, response: str):
        """æµå¼å“åº”å®Œæˆå¤„ç†"""
        logger.info(f"Stream response completed: {len(response)} characters")
    
    @pyqtSlot()
    def _on_response_cancelled(self):
        """æµå¼å“åº”å–æ¶ˆå¤„ç†"""
        logger.info("Stream response cancelled")
    
    @pyqtSlot(str)
    def _on_response_accepted(self, response: str):
        """æµå¼å“åº”æ¥å—å¤„ç†"""
        if not self._current_editor:
            return
        
        # æ’å…¥å“åº”å†…å®¹
        cursor = self._current_editor.textCursor()
        cursor.insertText(response)
        
        logger.info(f"Stream response accepted: {len(response)} characters")
    
    @pyqtSlot(dict)
    def _on_unified_config_saved(self, config: dict):
        """å¤„ç†ç»Ÿä¸€é…ç½®ä¿å­˜"""
        try:
            # å¤„ç†APIé…ç½®
            api_config = config.get('api', {})
            if api_config:
                # é‡æ–°åˆå§‹åŒ–AIå®¢æˆ·ç«¯
                self._init_ai_client()
                logger.info("AIå®¢æˆ·ç«¯é…ç½®å·²æ›´æ–°")
            
            # å¤„ç†è¡¥å…¨é…ç½®
            completion_config = config.get('completion', {})
            if completion_config:
                # åº”ç”¨è¡¥å…¨è®¾ç½®
                self.set_completion_enabled(completion_config.get('completion_enabled', True))
                self.set_auto_trigger_enabled(completion_config.get('auto_trigger_enabled', True))
                self.set_punctuation_assist_enabled(completion_config.get('punctuation_assist', True))
                self.set_trigger_delay(completion_config.get('trigger_delay', 500))
                
                # è®¾ç½®è¡¥å…¨æ¨¡å¼
                mode_mapping = {
                    'è‡ªåŠ¨AIè¡¥å…¨': 'auto_ai',
                    'æ‰‹åŠ¨AIè¡¥å…¨': 'manual_ai', 
                    'ç¦ç”¨è¡¥å…¨': 'disabled'
                }
                mode_text = completion_config.get('completion_mode', 'è‡ªåŠ¨AIè¡¥å…¨')
                mode = mode_mapping.get(mode_text, 'auto_ai')
                self.set_completion_mode(mode)
                
                logger.info("AIè¡¥å…¨è®¾ç½®å·²æ›´æ–°")
            
            # å‘å‡ºé…ç½®å˜æ›´ä¿¡å·
            self.configChanged.emit(config)
            
        except Exception as e:
            logger.error(f"å¤„ç†ç»Ÿä¸€é…ç½®ä¿å­˜å¤±è´¥: {e}")

    @pyqtSlot(dict)
    def _on_config_saved(self, config: dict):
        """é…ç½®ä¿å­˜å¤„ç†"""
        self._config = config
        self.configChanged.emit(config)
        
        logger.info("AI config updated")
    
    def set_config(self, config: Dict[str, Any]):
        """è®¾ç½®é…ç½®"""
        self._config = config
    
    def get_config(self) -> Dict[str, Any]:
        """è·å–é…ç½®"""
        return self._config.get_ai_config()
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self._completion_timer:
            self._completion_timer.stop()

        if self._completion_widget:
            self._completion_widget.hide()
            self._completion_widget.deleteLater()
            self._completion_widget = None

        if self._stream_widget:
            self._stream_widget.hide()
            self._stream_widget.deleteLater()
            self._stream_widget = None

        if self._config_dialog:
            self._config_dialog.deleteLater()
            self._config_dialog = None

        # æ¸…ç†AIå®¢æˆ·ç«¯
        if self._ai_client:
            self._ai_client.cleanup()
            self._ai_client = None

        logger.info("AI manager cleaned up")

    # AIå®¢æˆ·ç«¯å“åº”å¤„ç†æ–¹æ³•
    @pyqtSlot(str, dict)
    def _on_ai_response_received(self, response: str, context: dict):
        """AIå“åº”æ¥æ”¶å¤„ç†"""
        logger.info(f"AIå“åº”æ¥æ”¶: {len(response)} å­—ç¬¦")

        # æ˜¾ç¤ºç°ä»£AIçŠ¶æ€æŒ‡ç¤ºå™¨ - å®ŒæˆçŠ¶æ€
        modern_indicator = self._get_current_modern_indicator()
        if modern_indicator:
            modern_indicator.show_completed("AIç”Ÿæˆå®Œæˆ")
            logger.debug("ç°ä»£AIçŠ¶æ€æŒ‡ç¤ºå™¨å·²æ˜¾ç¤ºï¼šå®Œæˆ")
        
        # åŒæ—¶æ›´æ–°å·¥å…·æ çŠ¶æ€
        self._update_toolbar_ai_status("å°±ç»ª")
        logger.debug("å·¥å…·æ AIçŠ¶æ€å·²æ›´æ–°ä¸ºå°±ç»ª")

        # æ ¹æ®ä¸Šä¸‹æ–‡ç±»å‹å¤„ç†å“åº”
        if context.get('stream', False):
            # æµå¼å“åº”å®Œæˆ
            if self._stream_widget:
                self._stream_widget.set_final_response(response)
        else:
            # åº”ç”¨æ–‡å­¦æ ¼å¼åŒ–
            formatted_response = self._format_ai_response(response)

            # åŒæ­¥å“åº” - ä¼˜å…ˆä½¿ç”¨Ghost Textè¡¥å…¨
            if self._current_editor and hasattr(self._current_editor, 'show_ghost_ai_completion'):
                # ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šGhost Textè¡¥å…¨ï¼ˆæœ€ä½³ç”¨æˆ·ä½“éªŒï¼‰
                self._current_editor.show_ghost_ai_completion(formatted_response)
                logger.info(f"Ghost Text AIè¡¥å…¨å·²æ˜¾ç¤º: {formatted_response[:50]}...")
            elif self._current_editor and hasattr(self._current_editor, '_smart_completion'):
                # ç¬¬äºŒä¼˜å…ˆçº§ï¼šæ™ºèƒ½è¡¥å…¨ç®¡ç†å™¨
                self._current_editor._smart_completion.show_ai_completion(formatted_response)
                logger.info(f"æ™ºèƒ½AIè¡¥å…¨å·²æ˜¾ç¤º: {formatted_response[:50]}...")
            elif self._current_editor and hasattr(self._current_editor, 'show_inline_ai_completion'):
                # ç¬¬ä¸‰ä¼˜å…ˆçº§ï¼šå†…è”è¡¥å…¨
                self._current_editor.show_inline_ai_completion(formatted_response)
                logger.info(f"å†…è”AIè¡¥å…¨å·²æ˜¾ç¤º: {formatted_response[:50]}...")
            elif self._completion_widget:
                # æœ€åå›é€€ï¼šå¼¹å‡ºå¼è¡¥å…¨
                suggestions = [{
                    'content': formatted_response,
                    'type': 'AIè¡¥å…¨',
                    'confidence': 0.9,
                    'source': 'ai',
                    'description': 'åŸºäºä¸Šä¸‹æ–‡çš„AIç»­å†™å»ºè®®'
                }]

                self._completion_widget.show_suggestions(suggestions)
                self._position_completion_widget()

                logger.info(f"å¼¹å‡ºå¼AIè¡¥å…¨å·²æ˜¾ç¤º: {response[:50]}...")
            else:
                logger.warning("è¡¥å…¨ç»„ä»¶æœªåˆå§‹åŒ–ï¼Œæ— æ³•æ˜¾ç¤ºAIå“åº”")

    @pyqtSlot(str, dict)
    def _on_ai_stream_chunk(self, chunk: str, context: dict):
        """AIæµå¼æ•°æ®å—å¤„ç†"""
        if self._stream_widget:
            self._stream_widget.append_chunk(chunk)

    @pyqtSlot(str, dict)
    def _on_ai_error(self, error: str, context: dict):
        """AIé”™è¯¯å¤„ç†"""
        logger.error(f"AIè¯·æ±‚é”™è¯¯: {error}")

        # æ˜¾ç¤ºç°ä»£AIçŠ¶æ€æŒ‡ç¤ºå™¨ - é”™è¯¯çŠ¶æ€
        modern_indicator = self._get_current_modern_indicator()
        if modern_indicator:
            error_msg = error[:30] + "..." if len(error) > 30 else error
            modern_indicator.show_error(f"ç”Ÿæˆå¤±è´¥: {error_msg}")
            logger.debug(f"ç°ä»£AIçŠ¶æ€æŒ‡ç¤ºå™¨å·²æ˜¾ç¤ºï¼šé”™è¯¯ - {error_msg}")
        
        # åŒæ—¶æ›´æ–°å·¥å…·æ çŠ¶æ€
        self._update_toolbar_ai_status("é”™è¯¯")
        logger.debug("å·¥å…·æ AIçŠ¶æ€å·²æ›´æ–°ä¸ºé”™è¯¯")

        # æ ¹æ®ä¸Šä¸‹æ–‡æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
        if context.get('stream', False):
            # æµå¼å“åº”é”™è¯¯
            if self._stream_widget:
                self._stream_widget.show_error(error)
        else:
            # è¡¥å…¨å“åº”é”™è¯¯
            if self._completion_widget:
                self._completion_widget.show_error(error)
            else:
                logger.warning("è¡¥å…¨ç»„ä»¶æœªåˆå§‹åŒ–ï¼Œæ— æ³•æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯")

    @pyqtSlot(dict)
    def _on_ai_request_started(self, context: dict):
        """AIè¯·æ±‚å¼€å§‹å¤„ç†"""
        logger.debug("AIè¯·æ±‚å·²å¼€å§‹")

        # æ˜¾ç¤ºç°ä»£AIçŠ¶æ€æŒ‡ç¤ºå™¨ - ç”ŸæˆçŠ¶æ€
        modern_indicator = self._get_current_modern_indicator()
        if modern_indicator:
            if context.get('stream', False):
                modern_indicator.show_generating("æµå¼ç”Ÿæˆä¸­...")
            else:
                modern_indicator.show_generating("å†…å®¹ç”Ÿæˆä¸­...")
            logger.debug("ç°ä»£AIçŠ¶æ€æŒ‡ç¤ºå™¨å·²æ˜¾ç¤ºï¼šç”Ÿæˆä¸­")

        # æ˜¾ç¤ºåŠ è½½çŠ¶æ€
        if context.get('stream', False) and self._stream_widget:
            self._stream_widget.show_loading()

    @pyqtSlot(dict)
    def _on_ai_request_completed(self, context: dict):
        """AIè¯·æ±‚å®Œæˆå¤„ç†"""
        logger.debug("AIè¯·æ±‚å·²å®Œæˆ")

        # ç°ä»£AIçŠ¶æ€æŒ‡ç¤ºå™¨ä¼šåœ¨å“åº”æ¥æ”¶æ—¶è‡ªåŠ¨æ˜¾ç¤ºå®ŒæˆçŠ¶æ€
        # è¿™é‡Œä¸éœ€è¦é¢å¤–å¤„ç†ï¼Œå› ä¸ºå®ŒæˆçŠ¶æ€ä¼šåœ¨_on_ai_response_receivedä¸­æ˜¾ç¤º

        # éšè—åŠ è½½çŠ¶æ€
        if context.get('stream', False):
            # æµå¼å“åº”å®Œæˆ
            if self._stream_widget and hasattr(self._stream_widget, 'hide_loading'):
                self._stream_widget.hide_loading()
        else:
            # è¡¥å…¨å“åº”å®Œæˆ
            if self._completion_widget and hasattr(self._completion_widget, 'hide_loading'):
                self._completion_widget.hide_loading()
    
    def _init_rag_service(self):
        """åˆå§‹åŒ–RAGæœåŠ¡"""
        try:
            # è·å–RAGé…ç½®
            rag_config = self._config._config_data.get('rag', {})
            
            # å¦‚æœæ²¡æœ‰é…ç½®ï¼Œå°è¯•è·å–é»˜è®¤é…ç½®
            if not rag_config:
                logger.info("æœªæ‰¾åˆ°RAGé…ç½®ï¼Œè·³è¿‡åˆå§‹åŒ–")
                return
            
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨RAG
            rag_enabled = rag_config.get('enabled', False)
            
            # å¦‚æœæœªå¯ç”¨ä½†æœ‰API keyï¼Œè‡ªåŠ¨å¯ç”¨
            if not rag_enabled and rag_config.get('api_key', '').strip():
                logger.info("å‘ç°RAG APIé…ç½®ï¼Œè‡ªåŠ¨å¯ç”¨RAGåŠŸèƒ½")
                rag_config['enabled'] = True
                self._config._config_data['rag'] = rag_config
                self._config.save()
                rag_enabled = True
            
            if not rag_enabled:
                logger.info("RAGåŠŸèƒ½æœªå¯ç”¨")
                return
            
            # å¯¼å…¥å¿…è¦çš„æ¨¡å—
            from core.rag_service import RAGService, RAGContext
            from core.sqlite_vector_store import SQLiteVectorStore
            
            # è·å–å½“å‰é¡¹ç›®è·¯å¾„
            project_path = None
            
            # æ–¹æ³•1ï¼šä»å…±äº«å¯¹è±¡è·å–
            if self._shared and hasattr(self._shared, 'current_project_path') and self._shared.current_project_path:
                project_path = str(self._shared.current_project_path)
                logger.debug(f"ä»å…±äº«å¯¹è±¡è·å–é¡¹ç›®è·¯å¾„: {project_path}")
            
            # æ–¹æ³•2ï¼šä»ä¸»çª—å£è·å–é¡¹ç›®ç®¡ç†å™¨
            if not project_path and hasattr(self.parent(), '_project_manager'):
                project_manager = self.parent()._project_manager
                current_project = project_manager.get_current_project()
                if current_project and current_project.project_path:
                    project_path = current_project.project_path
                    logger.debug(f"ä»é¡¹ç›®ç®¡ç†å™¨è·å–é¡¹ç›®è·¯å¾„: {project_path}")
            
            if not project_path:
                logger.warning("æ— æ³•è·å–é¡¹ç›®è·¯å¾„ï¼ŒRAGåŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨")
                return
            
            # æ¸…ç†æ—§çš„RAGæœåŠ¡
            if self._rag_service:
                self._rag_service = None
            if self._vector_store:
                self._vector_store = None
            
            # åˆå§‹åŒ–å‘é‡å­˜å‚¨
            db_path = f"{project_path}/rag_vectors.db"
            self._vector_store = SQLiteVectorStore(db_path)
            logger.info(f"SQLiteå‘é‡å­˜å‚¨å·²åˆå§‹åŒ–: {db_path}")
            
            # åˆå§‹åŒ–RAGæœåŠ¡
            self._rag_service = RAGService(rag_config)
            
            # è®¾ç½®å‘é‡å­˜å‚¨å¼•ç”¨
            self._rag_service.set_vector_store(self._vector_store)
            
            logger.info(f"RAGæœåŠ¡å·²åˆå§‹åŒ–ï¼Œä½¿ç”¨æ¨¡å‹: {rag_config.get('embedding', {}).get('model', 'N/A')}")
            
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–RAGæœåŠ¡å¤±è´¥: {e}")
            self._rag_service = None
            self._vector_store = None
    
    def _init_prompt_system(self):
        """åˆå§‹åŒ–æç¤ºè¯ç®¡ç†ç³»ç»Ÿ"""
        try:
            if not PROMPT_SYSTEM_AVAILABLE:
                logger.warning("æç¤ºè¯ç³»ç»Ÿä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                return
            
            # åˆå§‹åŒ–æç¤ºè¯ç®¡ç†å™¨
            self._prompt_manager = EnhancedPromptManager()
            self._prompt_renderer = PromptRenderer()
            
            # åŠ è½½å†…ç½®æ¨¡æ¿
            try:
                builtin_templates = BuiltinTemplateLibrary.load_all_templates()
                for template in builtin_templates:
                    self._prompt_manager.add_template(template)
                logger.info(f"å·²åŠ è½½ {len(builtin_templates)} ä¸ªå†…ç½®æç¤ºè¯æ¨¡æ¿")
            except Exception as e:
                logger.error(f"åŠ è½½å†…ç½®æ¨¡æ¿å¤±è´¥: {e}")
                
            # éªŒè¯å½“å‰é€‰æ‹©çš„æ¨¡æ¿æ˜¯å¦å­˜åœ¨
            for mode, template_id in self._current_template_ids.items():
                if not self._prompt_manager.get_template(template_id):
                    logger.warning(f"æ¨¡æ¿ {template_id} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤æ¨¡æ¿")
                    # ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„AIè¡¥å…¨æ¨¡æ¿ä½œä¸ºé»˜è®¤
                    templates = [t for t in self._prompt_manager.templates.values() 
                               if t.category == "AIè¡¥å…¨"]
                    if templates:
                        self._current_template_ids[mode] = templates[0].id
                        logger.info(f"ä¸º {mode} æ¨¡å¼è®¾ç½®é»˜è®¤æ¨¡æ¿: {templates[0].id}")
                        
            logger.info("æç¤ºè¯ç®¡ç†ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–æç¤ºè¯ç³»ç»Ÿå¤±è´¥: {e}")
            self._prompt_manager = None
            self._prompt_renderer = None
    
    def get_available_templates(self, completion_type: str = None) -> List[Dict[str, str]]:
        """è·å–å¯ç”¨çš„æç¤ºè¯æ¨¡æ¿åˆ—è¡¨"""
        if not self._prompt_manager:
            return []
        
        templates = []
        for template in self._prompt_manager.templates.values():
            # å¦‚æœæŒ‡å®šäº†ç±»å‹ï¼Œåªè¿”å›åŒ¹é…çš„ç±»å‹
            if completion_type and template.category != completion_type:
                continue
                
            templates.append({
                'id': template.id,
                'name': template.name,
                'description': template.description,
                'category': template.category,
                'is_builtin': template.is_builtin
            })
        
        return sorted(templates, key=lambda x: (not x['is_builtin'], x['name']))
    
    def set_template_for_mode(self, mode: str, template_id: str):
        """ä¸ºæŒ‡å®šæ¨¡å¼è®¾ç½®æç¤ºè¯æ¨¡æ¿"""
        if mode in self._current_template_ids:
            # éªŒè¯æ¨¡æ¿æ˜¯å¦å­˜åœ¨
            if self._prompt_manager and self._prompt_manager.get_template(template_id):
                self._current_template_ids[mode] = template_id
                logger.info(f"ä¸º {mode} æ¨¡å¼è®¾ç½®æ¨¡æ¿: {template_id}")
                
                # ä¿å­˜åˆ°é…ç½®
                template_config = self._config._config_data.get('ai_templates', {})
                template_config[mode] = template_id
                self._config._config_data['ai_templates'] = template_config
                self._config.save()
            else:
                logger.error(f"æ¨¡æ¿ {template_id} ä¸å­˜åœ¨")
    
    def get_current_template_id(self, mode: str) -> str:
        """è·å–æŒ‡å®šæ¨¡å¼çš„å½“å‰æ¨¡æ¿ID"""
        return self._current_template_ids.get(mode, f'ai_{mode}_completion')
    
    def _on_project_changed(self, project_path: str):
        """å½“é¡¹ç›®å˜åŒ–æ—¶é‡æ–°åˆå§‹åŒ–RAGæœåŠ¡"""
        logger.info(f"é¡¹ç›®å˜åŒ–ï¼Œé¡¹ç›®è·¯å¾„: {project_path}")
        
        try:
            if project_path and project_path.strip():
                # é¡¹ç›®æ‰“å¼€ï¼Œé‡æ–°åˆå§‹åŒ–RAGæœåŠ¡
                logger.info(f"é¡¹ç›®æ‰“å¼€ï¼Œé‡æ–°åˆå§‹åŒ–RAGæœåŠ¡: {project_path}")
                self._init_rag_service()
                
                # ç¡®ä¿AIå®¢æˆ·ç«¯ä»ç„¶å¯ç”¨ï¼ˆé˜²æ­¢é¡¹ç›®åˆ‡æ¢æ—¶ä¸¢å¤±ï¼‰
                if not self._ai_client:
                    logger.warning("é¡¹ç›®å˜åŒ–æ—¶å‘ç°AIå®¢æˆ·ç«¯ä¸¢å¤±ï¼Œé‡æ–°åˆå§‹åŒ–")
                    self._init_ai_client()
            else:
                # é¡¹ç›®å…³é—­ï¼Œæ¸…ç†RAGæœåŠ¡ä½†ä¿æŒAIå®¢æˆ·ç«¯
                logger.info("é¡¹ç›®å…³é—­ï¼Œæ¸…ç†RAGæœåŠ¡ä½†ä¿æŒAIå®¢æˆ·ç«¯")
                if self._rag_service:
                    self._rag_service = None
                if self._vector_store:
                    self._vector_store = None
                
                # ç¡®ä¿AIå®¢æˆ·ç«¯åœ¨é¡¹ç›®å…³é—­åä»ç„¶å¯ç”¨
                if not self._ai_client:
                    logger.info("é¡¹ç›®å…³é—­åé‡æ–°åˆå§‹åŒ–AIå®¢æˆ·ç«¯")
                    self._init_ai_client()
                    
        except Exception as e:
            logger.error(f"é¡¹ç›®å˜åŒ–å¤„ç†å¤±è´¥: {e}")
            # å°è¯•æ¢å¤AIå®¢æˆ·ç«¯
            try:
                self._init_ai_client()
            except Exception as recovery_error:
                logger.error(f"AIå®¢æˆ·ç«¯æ¢å¤å¤±è´¥: {recovery_error}")
    
    def update_rag_config(self, config: Dict[str, Any]):
        """æ›´æ–°RAGé…ç½®"""
        self._config._config_data['rag'] = config
        self._config.save()
        
        # é‡æ–°åˆå§‹åŒ–RAGæœåŠ¡
        self._init_rag_service()
    
    def index_document(self, document_id: str, content: str):
        """ç´¢å¼•æ–‡æ¡£å†…å®¹ï¼ˆå¼‚æ­¥ï¼Œæ”¯æŒå¢é‡æ›´æ–°ï¼‰"""
        logger.debug(f"å°è¯•å¼‚æ­¥ç´¢å¼•æ–‡æ¡£: {document_id}")
        
        if not self._rag_service or not self._vector_store:
            logger.warning("RAGæœåŠ¡æœªåˆå§‹åŒ–ï¼Œæ— æ³•ç´¢å¼•æ–‡æ¡£")
            return
            
        if not content or not content.strip():
            logger.info(f"æ–‡æ¡£å†…å®¹ä¸ºç©ºï¼Œè·³è¿‡ç´¢å¼•: {document_id}")
            return
        
        # æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å‘ç”Ÿå˜åŒ–ï¼ˆå¢é‡æ›´æ–°ï¼‰
        try:
            if not self._vector_store.has_document_changed(document_id, content):
                logger.info(f"æ–‡æ¡£å†…å®¹æœªå˜åŒ–ï¼Œè·³è¿‡ç´¢å¼•: {document_id}")
                return
        except Exception as e:
            logger.warning(f"æ£€æŸ¥æ–‡æ¡£å˜åŒ–å¤±è´¥ï¼Œç»§ç»­ç´¢å¼•: {e}")
        
        # æ›´æ–°å¼‚æ­¥ç´¢å¼•å™¨çš„æœåŠ¡å¼•ç”¨
        self._async_indexer.set_services(self._rag_service, self._vector_store, self._config)
        
        # å°†æ–‡æ¡£åŠ å…¥å¼‚æ­¥ç´¢å¼•é˜Ÿåˆ—
        self._async_indexer.queue_document_index(document_id, content)
        logger.info(f"æ–‡æ¡£å·²æäº¤å¼‚æ­¥ç´¢å¼•ï¼ˆå¢é‡æ›´æ–°ï¼‰: {document_id}, å†…å®¹é•¿åº¦: {len(content)}")
    
    def _update_toolbar_ai_status(self, status: str):
        """æ›´æ–°å·¥å…·æ AIçŠ¶æ€æŒ‡ç¤ºå™¨"""
        try:
            # æŸ¥æ‰¾ä¸»çª—å£çš„å·¥å…·æ ç®¡ç†å™¨
            main_window = self.parent()
            while main_window and not hasattr(main_window, '_toolbar_manager'):
                main_window = main_window.parent()
            
            if main_window and hasattr(main_window, '_toolbar_manager'):
                toolbar_manager = main_window._toolbar_manager
                ai_toolbar = toolbar_manager.get_toolbar('ai')
                
                if ai_toolbar and hasattr(ai_toolbar, 'update_ai_status'):
                    ai_toolbar.update_ai_status(status)
                    logger.debug(f"å·¥å…·æ AIçŠ¶æ€å·²æ›´æ–°: {status}")
                else:
                    logger.warning("æœªæ‰¾åˆ°AIå·¥å…·æ æˆ–update_ai_statusæ–¹æ³•")
            else:
                logger.warning("æœªæ‰¾åˆ°ä¸»çª—å£æˆ–å·¥å…·æ ç®¡ç†å™¨")
                
            # åŒæ—¶æ›´æ–°ç°ä»£AIçŠ¶æ€æŒ‡ç¤ºå™¨
            modern_indicator = self._get_current_modern_indicator()
            if modern_indicator:
                if "thinking" in status.lower() or "æ€è€ƒ" in status or "å·¥ä½œ" in status:
                    modern_indicator.show_thinking(status)
                elif "error" in status.lower() or "é”™è¯¯" in status:
                    modern_indicator.show_error(status)
                elif "å°±ç»ª" in status or "ready" in status.lower():
                    modern_indicator.hide()
                else:
                    modern_indicator.show_requesting(status)
                logger.debug(f"ç°ä»£AIçŠ¶æ€æŒ‡ç¤ºå™¨å·²æ›´æ–°: {status}")
                
        except Exception as e:
            logger.error(f"æ›´æ–°å·¥å…·æ AIçŠ¶æ€å¤±è´¥: {e}")
    
    def index_document_sync(self, document_id: str, content: str) -> bool:
        """åŒæ­¥ç´¢å¼•æ–‡æ¡£å†…å®¹ï¼ˆç”¨äºéœ€è¦ç«‹å³å®Œæˆçš„åœºæ™¯ï¼‰"""
        logger.debug(f"å°è¯•åŒæ­¥ç´¢å¼•æ–‡æ¡£: {document_id}")
        
        if not self._rag_service:
            logger.warning("RAGæœåŠ¡æœªåˆå§‹åŒ–ï¼Œæ— æ³•ç´¢å¼•æ–‡æ¡£")
            return False
            
        if not content or not content.strip():
            logger.info(f"æ–‡æ¡£å†…å®¹ä¸ºç©ºï¼Œè·³è¿‡ç´¢å¼•: {document_id}")
            return True
        
        # ç›´æ¥è°ƒç”¨RAGæœåŠ¡çš„ç´¢å¼•æ–¹æ³•
        try:
            success = self._rag_service.index_document(document_id, content)
            if success:
                logger.info(f"åŒæ­¥ç´¢å¼•å®Œæˆ: {document_id}")
            else:
                logger.error(f"åŒæ­¥ç´¢å¼•å¤±è´¥: {document_id}")
            return success
            
        except Exception as e:
            logger.error(f"åŒæ­¥ç´¢å¼•æ–‡æ¡£å¤±è´¥: {document_id}, é”™è¯¯: {e}", exc_info=True)
            return False
    
    def delete_document_index(self, document_id: str):
        """åˆ é™¤æ–‡æ¡£ç´¢å¼•"""
        if not self._vector_store:
            return
        
        try:
            count = self._vector_store.delete_document_embeddings(document_id)
            logger.info(f"å·²åˆ é™¤æ–‡æ¡£ {document_id} çš„ {count} ä¸ªåµŒå…¥å‘é‡")
        except Exception as e:
            logger.error(f"åˆ é™¤æ–‡æ¡£ç´¢å¼•å¤±è´¥: {e}")
    
    def search_similar_content(self, query: str, max_results: int = 30) -> str:
        """æœç´¢ç›¸ä¼¼å†…å®¹ï¼ˆå¤§å¹…å¢å¼ºç‰ˆæœ¬ï¼šè¿”å›æ›´å¤šç»“æœï¼Œæé«˜ç²¾å‡†åº¦ï¼‰"""
        if not self._rag_service or not self._vector_store:
            logger.warning("RAGæœåŠ¡æœªåˆå§‹åŒ–ï¼Œæ— æ³•æœç´¢")
            return ""
        
        # æ€§èƒ½ä¿æŠ¤ï¼šé™åˆ¶æŸ¥è¯¢é•¿åº¦ä½†å¢åŠ ç»“æœæ•°é‡
        if len(query) > 2000:  # å¢åŠ æŸ¥è¯¢é•¿åº¦é™åˆ¶
            logger.warning("æŸ¥è¯¢æ–‡æœ¬è¿‡é•¿ï¼Œæˆªå–å‰2000å­—ç¬¦")
            query = query[:2000]
        
        max_results = min(max_results, 50)  # æœ€å¤š50ä¸ªç»“æœï¼Œå¤§å¹…æé«˜
        
        try:
            # å¿«é€Ÿæ£€æŸ¥å‘é‡å­˜å‚¨æ˜¯å¦æœ‰æ•°æ®
            stats = self._vector_store.get_stats()
            if not stats or stats.get('total_documents', 0) == 0:
                logger.info("å‘é‡å­˜å‚¨ä¸ºç©ºï¼Œä½¿ç”¨é™çº§æœç´¢")
                return self._fallback_similar_search(query, max_results)
            
            # æ€§èƒ½ç›‘æ§ï¼šè®°å½•å¼€å§‹æ—¶é—´
            import time
            start_time = time.time()
            
            # è·å–æŸ¥è¯¢å‘é‡ï¼ˆå¸¦è¶…æ—¶ä¿æŠ¤ï¼‰
            query_embedding = None
            try:
                query_embedding = self._rag_service.create_embedding(query)
            except Exception as e:
                logger.warning(f"åˆ›å»ºæŸ¥è¯¢å‘é‡å¤±è´¥: {e}")
            
            if not query_embedding:
                logger.warning("æ— æ³•åˆ›å»ºæŸ¥è¯¢å‘é‡ï¼Œä½¿ç”¨é™çº§æœç´¢")
                return self._fallback_similar_search(query, max_results)
            
            # æ‰§è¡Œå‘é‡æœç´¢ï¼ˆå¤§å¹…å¢å¼ºå‚æ•°ï¼‰
            results = self._vector_store.similarity_search(
                query_embedding,
                limit=max_results,
                min_similarity=0.25  # é™ä½ç›¸ä¼¼åº¦è¦æ±‚ï¼Œè·å¾—æ›´å¤šç»“æœ
            )
            
            # æ€§èƒ½æ£€æŸ¥ï¼šå¦‚æœæœç´¢ç”¨æ—¶è¿‡é•¿ï¼Œè®°å½•è­¦å‘Š
            search_time = time.time() - start_time
            if search_time > 2.0:  # å¢åŠ åˆ°2ç§’ï¼Œå› ä¸ºæˆ‘ä»¬è¦æ›´å¤šç»“æœ
                logger.warning(f"å‘é‡æœç´¢è€—æ—¶è¿‡é•¿: {search_time:.2f}ç§’")
            
            # å¦‚æœæ²¡æœ‰ç»“æœï¼Œå°è¯•é™çº§æœç´¢
            if not results:
                logger.info("å‘é‡æœç´¢æ— ç»“æœï¼Œå°è¯•é™çº§æœç´¢")
                return self._fallback_similar_search(query, max_results)
            
            # é‡æ’åºä¼˜åŒ–ï¼ˆå¦‚æœå¯ç”¨ä¸”ç½‘ç»œå¯ç”¨ï¼‰
            if (self._rag_service.rerank_enabled and 
                len(results) > 3 and  # ç»“æœè¶³å¤Ÿå¤šæ—¶æ‰é‡æ’åº
                getattr(self._rag_service, '_network_available', True) and
                search_time < 1.0):  # åªæœ‰æœç´¢å¾ˆå¿«æ—¶æ‰é‡æ’åº
                try:
                    rerank_start = time.time()
                    documents = [r[0]['chunk_text'] for r in results]
                    reranked = self._rag_service.rerank(query, documents, top_k=min(len(results), 40))
                    
                    rerank_time = time.time() - rerank_start
                    if rerank_time > 2.0:
                        logger.warning(f"é‡æ’åºè€—æ—¶è¿‡é•¿: {rerank_time:.2f}ç§’ï¼Œè·³è¿‡é‡æ’åº")
                    else:
                        # é‡æ–°æ’åºç»“æœ
                        reranked_results = []
                        for idx, score in reranked:
                            if idx < len(results):
                                reranked_results.append((results[idx][0], score))
                        results = reranked_results
                except Exception as e:
                    logger.warning(f"é‡æ’åºå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æœç´¢ç»“æœ: {e}")
            
            # æ„å»ºä¸Šä¸‹æ–‡ï¼ˆå¢å¼ºç‰ˆæœ¬ï¼Œæ”¯æŒæ›´é•¿å†…å®¹ï¼‰
            context_parts = []
            total_length = 0
            max_context_length = 3000  # å¤§å¹…å¢åŠ ä¸Šä¸‹æ–‡æ€»é•¿åº¦
            
            for emb_data, score in results[:max_results]:
                chunk_text = emb_data['chunk_text']
                # å¢åŠ å•ä¸ªå—çš„é•¿åº¦é™åˆ¶
                if len(chunk_text) > 600:
                    chunk_text = chunk_text[:600] + "..."
                
                part = f"[{emb_data['document_id']} - å—{emb_data['chunk_index']} (ç›¸ä¼¼åº¦: {score:.2f})]\n{chunk_text}"
                
                if total_length + len(part) > max_context_length:
                    break
                
                context_parts.append(part)
                total_length += len(part)
            
            if context_parts:
                return "\n\n---\n\n".join(context_parts)
            else:
                return ""
            
        except Exception as e:
            logger.error(f"æœç´¢ç›¸ä¼¼å†…å®¹å¤±è´¥ï¼Œå°è¯•é™çº§æœç´¢: {e}")
            return self._fallback_similar_search(query, max_results)
    
    def _fallback_similar_search(self, query: str, max_results: int = 10) -> str:
        """é™çº§æœç´¢ç­–ç•¥ï¼šåŸºäºå…³é”®è¯åŒ¹é…é¡¹ç›®æ–‡æ¡£"""
        try:
            # è·å–å½“å‰é¡¹ç›®çš„æ‰€æœ‰æ–‡æ¡£
            if not hasattr(self.parent(), '_project_manager'):
                return ""
                
            project_manager = self.parent()._project_manager
            current_project = project_manager.get_current_project()
            if not current_project:
                return ""
            
            # ä½¿ç”¨ç®€å•çš„å…³é”®è¯æœç´¢
            query_words = set(query.lower().split())
            document_scores = []
            
            for doc_id, doc in current_project.documents.items():
                if not doc.content:
                    continue
                    
                content_words = set(doc.content.lower().split())
                # è®¡ç®—è¯æ±‡é‡å åº¦
                intersection = len(query_words.intersection(content_words))
                union = len(query_words.union(content_words))
                score = intersection / union if union > 0 else 0.0
                
                if score > 0.1:  # æœ€ä½ç›¸ä¼¼åº¦é˜ˆå€¼
                    document_scores.append((doc_id, doc.name, doc.content[:500], score))
            
            # æ’åºå¹¶è¿”å›å‰Nä¸ªç»“æœ
            document_scores.sort(key=lambda x: x[3], reverse=True)
            
            context_parts = []
            for doc_id, doc_name, content_preview, score in document_scores[:max_results]:
                context_parts.append(
                    f"[{doc_name} ({doc_id[:8]}...) - å…³é”®è¯åŒ¹é…åº¦: {score:.2f}]\n"
                    f"{content_preview}..."
                )
            
            if context_parts:
                logger.info(f"é™çº§æœç´¢æ‰¾åˆ° {len(context_parts)} ä¸ªç›¸å…³æ–‡æ¡£")
                return "\n\n---\n\n".join(context_parts)
            else:
                logger.info("é™çº§æœç´¢æœªæ‰¾åˆ°ç›¸å…³å†…å®¹")
                return ""
                
        except Exception as e:
            logger.error(f"é™çº§æœç´¢å¤±è´¥: {e}")
            return ""
    
    def _has_recent_rag_timeout(self) -> bool:
        """æ£€æŸ¥æœ€è¿‘æ˜¯å¦å‘ç”ŸRAGè¶…æ—¶"""
        if not hasattr(self, '_last_rag_timeout_time'):
            return False
        return time.time() - self._last_rag_timeout_time < 30  # 30ç§’å†…ä¸å†å°è¯•
    
    def _record_rag_timeout(self):
        """è®°å½•RAGè¶…æ—¶æ—¶é—´"""
        self._last_rag_timeout_time = time.time()
        logger.warning("å·²è®°å½•RAGè¶…æ—¶ï¼Œ30ç§’å†…å°†è·³è¿‡RAG")
    
    def _simple_text_match(self, query_text: str) -> str:
        """ç®€å•æ–‡æœ¬åŒ¹é…ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        try:
            # è·å–å½“å‰é¡¹ç›®çš„æ–‡æ¡£ï¼Œç®€å•å…³é”®è¯åŒ¹é…
            if not hasattr(self.parent(), '_project_manager'):
                return ""
                
            project_manager = self.parent()._project_manager
            current_project = project_manager.get_current_project()
            if not current_project:
                return ""
            
            # ç®€å•çš„å…³é”®è¯åŒ¹é…
            query_words = set(query_text.lower().split()[:3])  # åªå–å‰3ä¸ªè¯
            if not query_words:
                return ""
            
            # å¿«é€Ÿæ‰«ææœ€å¤š3ä¸ªæ–‡æ¡£
            for i, (doc_id, doc) in enumerate(current_project.documents.items()):
                if i >= 3:  # æœ€å¤šæ£€æŸ¥3ä¸ªæ–‡æ¡£
                    break
                    
                if not doc.content or len(doc.content) < 20:
                    continue
                    
                # å¿«é€Ÿå…³é”®è¯åŒ¹é…
                content_sample = doc.content[:200].lower()  # åªæ£€æŸ¥å‰200å­—ç¬¦
                if any(word in content_sample for word in query_words if len(word) > 1):
                    # æ‰¾åˆ°åŒ¹é…ï¼Œè¿”å›ç®€çŸ­ç‰‡æ®µ
                    return doc.content[:100] + "..."
            
            return ""
            
        except Exception as e:
            logger.debug(f"ç®€å•æ–‡æœ¬åŒ¹é…å¤±è´¥: {e}")
            return ""
    
    def _build_rag_context_with_mode(self, current_text: str, cursor_position: int, context_mode: str) -> str:
        """æ ¹æ®ä¸Šä¸‹æ–‡æ¨¡å¼æ„å»ºRAGä¸Šä¸‹æ–‡ï¼ˆå¤§å¹…ä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
        if not self._rag_service or not self._vector_store:
            return ""
        
        try:
            import time
            start_time = time.time()
            
            # æ ¹æ®æ¨¡å¼è®¾ç½®ä¸åŒçš„å‚æ•°ï¼ˆå¤§å¹…å¢å¼ºï¼‰
            mode_configs = {
                'fast': {
                    'max_length': 8000,     # å¤§å¹…å¢åŠ æ–‡æœ¬é•¿åº¦é™åˆ¶
                    'query_length': 200,    # å¢åŠ æŸ¥è¯¢é•¿åº¦
                    'max_results': 15,      # å¢åŠ åˆ°15ä¸ªç»“æœ
                    'timeout': 2.0,         # å¢åŠ è¶…æ—¶æ—¶é—´
                    'context_limit': 800,   # å¢åŠ ä¸Šä¸‹æ–‡é•¿åº¦
                    'min_similarity': 0.3   # é™ä½ç›¸ä¼¼åº¦è¦æ±‚
                },
                'balanced': {
                    'max_length': 15000,    # å¤§å¹…å¢åŠ æ–‡æœ¬é•¿åº¦
                    'query_length': 400,    # å¢åŠ æŸ¥è¯¢é•¿åº¦
                    'max_results': 35,      # å¢åŠ åˆ°35ä¸ªç»“æœ
                    'timeout': 3.0,         # å¢åŠ è¶…æ—¶æ—¶é—´
                    'context_limit': 1500,  # å¤§å¹…å¢åŠ ä¸Šä¸‹æ–‡é•¿åº¦
                    'min_similarity': 0.25  # é™ä½ç›¸ä¼¼åº¦è¦æ±‚
                },
                'full': {
                    'max_length': 25000,    # å…è®¸æ›´é•¿æ–‡æœ¬
                    'query_length': 600,    # å¤§å¹…å¢åŠ æŸ¥è¯¢é•¿åº¦
                    'max_results': 50,      # å¢åŠ åˆ°50ä¸ªç»“æœ
                    'timeout': 4.0,         # å¢åŠ è¶…æ—¶æ—¶é—´
                    'context_limit': 2500,  # å¤§å¹…å¢åŠ ä¸Šä¸‹æ–‡é•¿åº¦
                    'min_similarity': 0.2   # è¿›ä¸€æ­¥é™ä½ç›¸ä¼¼åº¦è¦æ±‚
                }
            }
            
            config = mode_configs.get(context_mode, mode_configs['balanced'])
            
            # æ€§èƒ½ä¿æŠ¤ï¼šæ£€æŸ¥æ–‡æœ¬é•¿åº¦
            if cursor_position > config['max_length']:
                logger.debug(f"æ–‡æœ¬è¿‡é•¿ï¼ˆ>{config['max_length']}å­—ç¬¦ï¼‰ï¼Œè·³è¿‡RAGæ£€ç´¢ï¼ˆ{context_mode}æ¨¡å¼ï¼‰")
                return ""
            
            # æå–æŸ¥è¯¢æ–‡æœ¬ - ä½¿ç”¨æ›´æ™ºèƒ½çš„ä¸Šä¸‹æ–‡æå–
            query_text = self._extract_smart_query_context(current_text, cursor_position, config['query_length'])
            
            if not query_text or len(query_text) < 3:
                return ""
            
            # ä½¿ç”¨ä¼˜åŒ–çš„å¼‚æ­¥RAGæ£€ç´¢
            result = self._fast_rag_search_with_timeout(
                query_text, 
                config['max_results'], 
                config['timeout'],
                config['min_similarity']
            )
            
            if result:
                # é™åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦
                context = result[:config['context_limit']] if len(result) > config['context_limit'] else result
                
                search_time = time.time() - start_time
                logger.info(f"{context_mode}æ¨¡å¼RAGæˆåŠŸ: {len(context)} å­—ç¬¦ï¼Œç”¨æ—¶ {search_time:.3f}ç§’")
                
                # æ ¹æ®æ¨¡å¼æ·»åŠ ä¸åŒçš„å‰ç¼€
                mode_prefixes = {
                    'fast': "å¿«é€Ÿå‚è€ƒ:",
                    'balanced': "ç›¸å…³å†…å®¹:",
                    'full': "æ·±åº¦èƒŒæ™¯èµ„æ–™:"
                }
                prefix = mode_prefixes.get(context_mode, "å‚è€ƒ:")
                
                return f"\n\n{prefix}\n{context}"
                
            return ""
            
        except Exception as e:
            logger.error(f"{context_mode}æ¨¡å¼RAGæ„å»ºå¤±è´¥: {e}")
            return ""

    def _extract_full_chapter_context(self, text: str, cursor_position: int) -> str:
        """æå–å®Œæ•´ç« èŠ‚ä¸Šä¸‹æ–‡ï¼ŒåŒ…å«å½“å‰ç« èŠ‚çš„ä¸Šæ–‡ã€ä¸‹æ–‡å†…å®¹"""
        try:
            # æŸ¥æ‰¾å½“å‰ç« èŠ‚çš„è¾¹ç•Œ
            lines = text.split('\n')
            cursor_line = text[:cursor_position].count('\n')
            
            # å¯»æ‰¾ç« èŠ‚æ ‡è®°ï¼ˆå¦‚ # æ ‡é¢˜ã€## æ ‡é¢˜ æˆ–å…¶ä»–æ ¼å¼ï¼‰
            chapter_patterns = [
                r'^#{1,3}\s+',      # Markdown ç« èŠ‚æ ‡é¢˜
                r'^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+ç« ',  # ä¸­æ–‡ç« èŠ‚æ ‡è®°
                r'^Chapter\s+\d+',   # è‹±æ–‡ç« èŠ‚æ ‡è®°
                r'^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+èŠ‚',  # ä¸­æ–‡èŠ‚æ ‡è®°
            ]
            
            chapter_start = 0
            chapter_end = len(lines)
            
            # å‘ä¸ŠæŸ¥æ‰¾ç« èŠ‚å¼€å§‹
            for i in range(cursor_line, -1, -1):
                line = lines[i].strip()
                if any(re.match(pattern, line) for pattern in chapter_patterns):
                    chapter_start = i
                    break
            
            # å‘ä¸‹æŸ¥æ‰¾ç« èŠ‚ç»“æŸ
            for i in range(cursor_line + 1, len(lines)):
                line = lines[i].strip()
                if any(re.match(pattern, line) for pattern in chapter_patterns):
                    chapter_end = i
                    break
            
            # æå–å®Œæ•´ç« èŠ‚å†…å®¹
            chapter_lines = lines[chapter_start:chapter_end]
            chapter_text = '\n'.join(chapter_lines)
            
            # å¦‚æœç« èŠ‚å¤ªé•¿ï¼Œæ™ºèƒ½æˆªå–
            if len(chapter_text) > 12000:
                # ä¼˜å…ˆä¿ç•™å…‰æ ‡é™„è¿‘çš„å†…å®¹
                cursor_in_chapter = cursor_position - len('\n'.join(lines[:chapter_start]))
                context_radius = 6000  # å…‰æ ‡å‰åå„6000å­—ç¬¦
                
                start_pos = max(0, cursor_in_chapter - context_radius)
                end_pos = min(len(chapter_text), cursor_in_chapter + context_radius)
                
                chapter_text = chapter_text[start_pos:end_pos]
            
            logger.debug(f"æå–å®Œæ•´ç« èŠ‚ä¸Šä¸‹æ–‡ï¼š{len(chapter_text)} å­—ç¬¦ï¼Œç« èŠ‚èŒƒå›´: {chapter_start}-{chapter_end} è¡Œ")
            return chapter_text
            
        except Exception as e:
            logger.error(f"æå–å®Œæ•´ç« èŠ‚ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            # é™çº§ä¸ºç®€å•ä¸Šä¸‹æ–‡æå–
            context_radius = 2000
            start_pos = max(0, cursor_position - context_radius)
            end_pos = min(len(text), cursor_position + context_radius)
            return text[start_pos:end_pos]

    def _extract_smart_query_context(self, text: str, cursor_position: int, max_length: int) -> str:
        """æ™ºèƒ½æå–RAGæŸ¥è¯¢ä¸Šä¸‹æ–‡ï¼ŒåŒ…å«æ›´å¤šå…³é”®ä¿¡æ¯ï¼ˆå¤§å¹…å¢å¼ºç‰ˆæœ¬ï¼‰"""
        try:
            # ã€å¢å¼º1ã€‘æ‰©å¤§æŸ¥è¯¢èŒƒå›´ï¼Œæå–æ›´å¤šå…³é”®è¯
            # å°†æŸ¥è¯¢èŒƒå›´æ‰©å±•åˆ°å…‰æ ‡å‰åæ›´å¤§çš„åŒºåŸŸ
            expanded_range = max(max_length * 2, 1500)  # è‡³å°‘1500å­—ç¬¦çš„åˆ†æèŒƒå›´
            start_pos = max(0, cursor_position - expanded_range)
            end_pos = min(len(text), cursor_position + expanded_range // 2)
            expanded_context = text[start_pos:end_pos]
            
            # ã€å¢å¼º2ã€‘å¤šå±‚æ¬¡å…³é”®è¯æå–
            keywords = self._extract_enhanced_keywords(expanded_context, cursor_position - start_pos)
            
            # ã€å¢å¼º3ã€‘æ™ºèƒ½æ®µè½å’Œç« èŠ‚è¾¹ç•Œè¯†åˆ«
            paragraphs = expanded_context.split('\n\n')
            current_pos = 0
            target_paragraph_idx = 0
            
            # æ‰¾åˆ°å…‰æ ‡æ‰€åœ¨æ®µè½ï¼ˆåœ¨æ‰©å±•ä¸Šä¸‹æ–‡ä¸­çš„ç›¸å¯¹ä½ç½®ï¼‰
            relative_cursor_pos = cursor_position - start_pos
            for i, paragraph in enumerate(paragraphs):
                if current_pos + len(paragraph) >= relative_cursor_pos:
                    target_paragraph_idx = i
                    break
                current_pos += len(paragraph) + 2  # +2 for \n\n
            
            # ã€å¢å¼º4ã€‘æ‰©å±•æ®µè½æå–èŒƒå›´ï¼ŒåŒ…å«æ›´å¤šä¸Šä¸‹æ–‡
            # å‰åå„å–æ›´å¤šæ®µè½ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿçš„å…³é”®è¯ä¿¡æ¯
            context_radius = 4  # å‰åå„4ä¸ªæ®µè½
            start_idx = max(0, target_paragraph_idx - context_radius)
            end_idx = min(len(paragraphs), target_paragraph_idx + context_radius + 1)
            context_paragraphs = paragraphs[start_idx:end_idx]
            
            # ã€å¢å¼º5ã€‘æ™ºèƒ½å†…å®¹ä¼˜å…ˆçº§æ’åº
            # ä¼˜å…ˆåŒ…å«åŒ…å«å…³é”®è¯çš„æ®µè½
            prioritized_paragraphs = []
            keyword_paragraphs = []
            normal_paragraphs = []
            
            for para in context_paragraphs:
                has_keywords = any(keyword.lower() in para.lower() for keyword in keywords[:10])
                if has_keywords:
                    keyword_paragraphs.append(para)
                else:
                    normal_paragraphs.append(para)
            
            # ä¼˜å…ˆåŒ…å«å…³é”®è¯æ®µè½ï¼Œç„¶åè¡¥å……æ™®é€šæ®µè½
            prioritized_paragraphs = keyword_paragraphs + normal_paragraphs
            context_text = '\n\n'.join(prioritized_paragraphs)
            
            # ã€å¢å¼º6ã€‘å¦‚æœä¸Šä¸‹æ–‡ä»ç„¶å¤ªçŸ­ï¼Œä½¿ç”¨çª—å£æ‰©å±•æ–¹æ³•
            if len(context_text) < max_length * 1.5:  # æœŸæœ›è·å¾—æ›´é•¿çš„ä¸Šä¸‹æ–‡
                # ä½¿ç”¨æ›´å¤§çš„çª—å£ï¼ŒåŒ…å«å…‰æ ‡å‰åæ›´å¤šå†…å®¹
                window_start = max(0, cursor_position - max_length)
                window_end = min(len(text), cursor_position + max_length // 2)
                window_context = text[window_start:window_end]
                
                # åˆå¹¶çª—å£ä¸Šä¸‹æ–‡å’Œæ®µè½ä¸Šä¸‹æ–‡ï¼Œå»é‡
                combined_context = context_text + '\n\n' + window_context
                context_text = combined_context
            
            # ã€å¢å¼º7ã€‘æ™ºèƒ½è¾¹ç•Œæˆªæ–­ï¼Œä¿æŒè¯­ä¹‰å®Œæ•´æ€§
            if len(context_text) > max_length:
                # ä¼˜å…ˆåœ¨ç« èŠ‚ã€æ®µè½è¾¹ç•Œæˆªæ–­
                chapter_markers = ['# ', '## ', '### ', 'ç¬¬', 'ç« ', 'èŠ‚']
                truncated = context_text[:max_length]
                
                # å°è¯•åœ¨ç« èŠ‚æ ‡è®°å¤„æˆªæ–­
                for marker in chapter_markers:
                    last_marker = truncated.rfind(marker)
                    if last_marker > max_length * 0.6:
                        # æ‰¾åˆ°æ ‡è®°è¡Œçš„ç»“æŸ
                        line_end = truncated.find('\n', last_marker)
                        if line_end != -1:
                            context_text = truncated[:line_end]
                            break
                else:
                    # åœ¨æ®µè½è¾¹ç•Œæˆªæ–­
                    last_paragraph = truncated.rfind('\n\n')
                    if last_paragraph > max_length * 0.7:
                        context_text = truncated[:last_paragraph]
                    else:
                        # åœ¨å¥å­è¾¹ç•Œæˆªæ–­
                        for separator in ['ã€‚', 'ï¼', 'ï¼Ÿ', '\n']:
                            last_sep = truncated.rfind(separator)
                            if last_sep > max_length * 0.8:
                                context_text = truncated[:last_sep + 1]
                                break
                        else:
                            context_text = truncated
            
            # ã€å¢å¼º8ã€‘æ·»åŠ å…³é”®è¯æ€»ç»“åˆ°ä¸Šä¸‹æ–‡å¼€å¤´
            if keywords:
                keyword_summary = "å…³é”®ä¿¡æ¯ï¼š" + "ã€".join(keywords[:15]) + "\n\n"
                context_text = keyword_summary + context_text
            
            logger.debug(f"å¢å¼ºæŸ¥è¯¢ä¸Šä¸‹æ–‡æå–ï¼š{len(context_text)} å­—ç¬¦ï¼Œå…³é”®è¯: {len(keywords)} ä¸ª")
            return context_text.strip()
            
        except Exception as e:
            logger.error(f"å¢å¼ºæŸ¥è¯¢ä¸Šä¸‹æ–‡æå–å¤±è´¥: {e}")
            # é™çº§ä¸ºæ‰©å±•ç®€å•æå–
            expanded_start = max(0, cursor_position - max_length * 2)
            return text[expanded_start:cursor_position].strip()
    
    def _extract_enhanced_keywords(self, text: str, cursor_pos: int) -> List[str]:
        """å¢å¼ºå…³é”®è¯æå–ï¼ˆå¤§å¹…æå‡å…³é”®è¯æ•°é‡å’Œè´¨é‡ï¼‰"""
        keywords = set()
        
        try:
            # ã€å…³é”®è¯ç±»å‹1ã€‘äººç‰©åç§°æå–ï¼ˆå¢å¼ºç‰ˆæœ¬ï¼‰
            # åŒ¹é…ä¸­æ–‡äººåæ¨¡å¼
            name_patterns = [
                r'[æç‹å¼ åˆ˜é™ˆæ¨é»„å´èµµå­™å‘¨å¾æœ±é©¬èƒ¡éƒ­ä½•é«˜æ—ç½—éƒ‘æ¢è°¢å®‹å”è®¸é‚“é™†å§œæ²ˆä½™æ½˜å¢çŸ³å»–å§šæ–¹é‡‘æˆ´è´¾éŸ¦å¤ä»˜é‚¹ç¨‹è§è”¡è‘£é‚®ç”°ä»»å­ŸèŒƒæ±ª][\u4e00-\u9fff]{1,3}',  # å¸¸è§å§“æ°
                r'[A-Z][a-z]+\s+[A-Z][a-z]+',  # è‹±æ–‡äººå
                r'@char:\s*([^\s,ï¼Œã€‚ï¼ï¼Ÿ\n]+)',  # @char: æ ‡è®°çš„è§’è‰²
            ]
            
            for pattern in name_patterns:
                matches = re.findall(pattern, text)
                for match in matches:
                    if isinstance(match, str) and len(match) >= 2:
                        keywords.add(match.strip())
            
            # ã€å…³é”®è¯ç±»å‹2ã€‘åœ°ç‚¹åœºæ‰€æå–ï¼ˆå¤§å¹…å¢å¼ºï¼‰
            location_keywords = [
                'å­¦æ ¡', 'å®¶', 'æˆ¿é—´', 'å®¢å…', 'å§å®¤', 'å¨æˆ¿', 'åŠå…¬å®¤', 'å…¬å¸', 'åŒ»é™¢', 'å•†åº—', 'é¤å…', 'å’–å•¡å…',
                'å…¬å›­', 'è¡—é“', 'åŸå¸‚', 'ä¹¡æ‘', 'å±±', 'æ²³', 'æµ·', 'æ£®æ—', 'è‰åŸ', 'æ²™æ¼ ', 'é›ªåœ°',
                'æ•™å®¤', 'å›¾ä¹¦é¦†', 'å®¿èˆ', 'é£Ÿå ‚', 'æ“åœº', 'ä½“è‚²é¦†', 'æ¸¸æ³³æ± ', 'ç”µå½±é™¢', 'å‰§é™¢', 'åšç‰©é¦†',
                'æœºåœº', 'ç«è½¦ç«™', 'åœ°é“ç«™', 'å…¬äº¤ç«™', 'ç å¤´', 'é«˜é€Ÿå…¬è·¯', 'å°å··', 'å¹¿åœº', 'æ¡¥æ¢',
                'é…’åº—', 'å®¾é¦†', 'æ—…é¦†', 'æ°‘å®¿', 'åº¦å‡æ‘', 'æ¸©æ³‰', 'æ™¯åŒº', 'å¤é•‡', 'æ‘åº„', 'å°é•‡'
            ]
            
            location_patterns = [
                r'@location:\s*([^\s,ï¼Œã€‚ï¼ï¼Ÿ\n]+)',  # @location: æ ‡è®°
                r'åœ¨([^\s,ï¼Œçš„]{2,8})',  # "åœ¨...åœ°æ–¹"æ¨¡å¼
                r'åˆ°([^\s,ï¼Œçš„]{2,8})',  # "åˆ°...åœ°æ–¹"æ¨¡å¼
                r'ä»([^\s,ï¼Œçš„]{2,8})',  # "ä»...åœ°æ–¹"æ¨¡å¼
            ]
            
            # æ·»åŠ ä½ç½®å…³é”®è¯
            for keyword in location_keywords:
                if keyword in text:
                    keywords.add(keyword)
            
            # åŒ¹é…ä½ç½®æ¨¡å¼
            for pattern in location_patterns:
                matches = re.findall(pattern, text)
                for match in matches:
                    if len(match) >= 2:
                        keywords.add(match.strip())
            
            # ã€å…³é”®è¯ç±»å‹3ã€‘ç‰©å“é“å…·æå–ï¼ˆæ–°å¢ï¼‰
            object_keywords = [
                'æ‰‹æœº', 'ç”µè„‘', 'ä¹¦', 'ç¬”', 'é’±åŒ…', 'é’¥åŒ™', 'åŒ…', 'è¡£æœ', 'é‹å­', 'å¸½å­', 'çœ¼é•œ',
                'è½¦', 'è‡ªè¡Œè½¦', 'æ‘©æ‰˜è½¦', 'å…¬äº¤è½¦', 'å‡ºç§Ÿè½¦', 'åœ°é“', 'é£æœº', 'ç«è½¦', 'èˆ¹',
                'æ¡Œå­', 'æ¤…å­', 'åºŠ', 'æ²™å‘', 'é—¨', 'çª—æˆ·', 'ç”µè§†', 'å†°ç®±', 'æ´—è¡£æœº', 'ç©ºè°ƒ',
                'é£Ÿç‰©', 'æ°´', 'å’–å•¡', 'èŒ¶', 'é…’', 'é¥®æ–™', 'é¢åŒ…', 'ç±³é¥­', 'é¢æ¡', 'æ°´æœ'
            ]
            
            for keyword in object_keywords:
                if keyword in text:
                    keywords.add(keyword)
            
            # ã€å…³é”®è¯ç±»å‹4ã€‘åŠ¨ä½œè¡Œä¸ºæå–ï¼ˆæ–°å¢ï¼‰
            action_patterns = [
                r'(èµ°|è·‘|å|ç«™|èºº|ç¡|åƒ|å–|çœ‹|å¬|è¯´|ç¬‘|å“­|æƒ³|åš|å†™|è¯»|ä¹°|å–|å¼€|å…³|æ‹¿|æ”¾)([ç€äº†]|[^\s]{0,2})',
                r'(æ­£åœ¨|æ­£|åœ¨)([^\s]{1,3})',
                r'(å¼€å§‹|ç»“æŸ|ç»§ç»­|åœæ­¢|å‡†å¤‡)([^\s]{1,3})',
            ]
            
            for pattern in action_patterns:
                matches = re.findall(pattern, text)
                for match in matches:
                    if isinstance(match, tuple) and len(match) >= 2:
                        action = match[0] + match[1]
                        if len(action) >= 2:
                            keywords.add(action)
            
            # ã€å…³é”®è¯ç±»å‹5ã€‘æƒ…æ„ŸçŠ¶æ€æå–ï¼ˆæ–°å¢ï¼‰
            emotion_keywords = [
                'é«˜å…´', 'å¼€å¿ƒ', 'å¿«ä¹', 'å…´å¥‹', 'æ»¡æ„', 'å¾—æ„', 'éª„å‚²', 'è‡ªè±ª',
                'éš¾è¿‡', 'ä¼¤å¿ƒ', 'æ‚²ä¼¤', 'ç—›è‹¦', 'å¤±è½', 'ç»æœ›', 'å“­æ³£',
                'æ„¤æ€’', 'ç”Ÿæ°”', 'æ¼ç«', 'æš´èº', 'æ„¤æ¨', 'ä»‡æ¨',
                'å®³æ€•', 'ææƒ§', 'ç´§å¼ ', 'ç„¦è™‘', 'æ‹…å¿ƒ', 'å¿§è™‘', 'ä¸å®‰',
                'æƒŠè®¶', 'éœ‡æƒŠ', 'æ„å¤–', 'å›°æƒ‘', 'ç–‘æƒ‘', 'å¥‡æ€ª',
                'å†·é™', 'å¹³é™', 'å®‰é™', 'æ·¡å®š', 'è½»æ¾', 'èˆ’é€‚'
            ]
            
            for keyword in emotion_keywords:
                if keyword in text:
                    keywords.add(keyword)
            
            # ã€å…³é”®è¯ç±»å‹6ã€‘æ—¶é—´ç›¸å…³æå–ï¼ˆå¢å¼ºï¼‰
            time_patterns = [
                r'(ä»Šå¤©|æ˜¨å¤©|æ˜å¤©|å‰å¤©|åå¤©|ä»Šæ™š|æ˜¨æ™š|æ˜æ™š)',
                r'([ä¸Šä¸‹]åˆ|æ™šä¸Š|æ·±å¤œ|å‡Œæ™¨|é»æ˜|å‚æ™š|ä¸­åˆ)',
                r'(æ˜¥å¤©|å¤å¤©|ç§‹å¤©|å†¬å¤©|æ˜¥|å¤|ç§‹|å†¬)',
                r'(å‘¨ä¸€|å‘¨äºŒ|å‘¨ä¸‰|å‘¨å››|å‘¨äº”|å‘¨å…­|å‘¨æ—¥|æ˜ŸæœŸ[ä¸€äºŒä¸‰å››äº”å…­æ—¥å¤©])',
                r'(\d{1,2}ç‚¹|\d{1,2}[ï¼š:]\d{2})',
                r'@time:\s*([^\s,ï¼Œã€‚ï¼ï¼Ÿ\n]+)',
            ]
            
            for pattern in time_patterns:
                matches = re.findall(pattern, text)
                for match in matches:
                    keywords.add(match.strip())
            
            # ã€å…³é”®è¯ç±»å‹7ã€‘å…³é”®çŸ­è¯­æå–ï¼ˆæ–°å¢ï¼‰
            # æå–é‡è¦çš„çŸ­è¯­å’Œè¯ç»„
            important_phrases = []
            sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]', text)
            
            for sentence in sentences:
                if len(sentence) > 10:
                    # æå–å«æœ‰é‡è¦è¯æ±‡çš„çŸ­è¯­
                    important_words = ['çªç„¶', 'å¿½ç„¶', 'ç»ˆäº', 'æœç„¶', 'ç«Ÿç„¶', 'å±…ç„¶', 'åŸæ¥', 'æ²¡æƒ³åˆ°', 
                                     'å†³å®š', 'é€‰æ‹©', 'å‘ç°', 'æ„è¯†åˆ°', 'è®°èµ·', 'æƒ³èµ·', 'æ˜ç™½', 'ç†è§£',
                                     'é‡è¦', 'å…³é”®', 'å¿…é¡»', 'åº”è¯¥', 'ä¸èƒ½', 'å¯èƒ½', 'ä¹Ÿè®¸', 'æˆ–è®¸']
                    
                    for word in important_words:
                        if word in sentence:
                            # æå–åŒ…å«å…³é”®è¯çš„çŸ­è¯­ï¼ˆå‰åå„5ä¸ªå­—ç¬¦ï¼‰
                            word_pos = sentence.find(word)
                            start = max(0, word_pos - 5)
                            end = min(len(sentence), word_pos + len(word) + 5)
                            phrase = sentence[start:end].strip()
                            if len(phrase) >= 3:
                                keywords.add(phrase)
            
            # ã€å…³é”®è¯ç±»å‹8ã€‘å…‰æ ‡é™„è¿‘é‡ç‚¹è¯æ±‡ï¼ˆæ–°å¢ï¼‰
            # ç‰¹åˆ«å…³æ³¨å…‰æ ‡å‰åçš„é‡è¦è¯æ±‡
            if 0 <= cursor_pos < len(text):
                context_radius = 200  # å…‰æ ‡å‰å200å­—ç¬¦
                nearby_start = max(0, cursor_pos - context_radius)
                nearby_end = min(len(text), cursor_pos + context_radius)
                nearby_text = text[nearby_start:nearby_end]
                
                # åˆ†è¯å¹¶æå–è¾ƒé•¿çš„è¯æ±‡
                words = re.findall(r'[\u4e00-\u9fff]{2,}', nearby_text)  # ä¸­æ–‡è¯æ±‡
                for word in words:
                    if len(word) >= 2:
                        keywords.add(word)
            
            # å»é™¤è¿‡çŸ­æˆ–æ— æ„ä¹‰çš„å…³é”®è¯
            filtered_keywords = []
            for keyword in keywords:
                keyword = keyword.strip()
                if (len(keyword) >= 2 and 
                    keyword not in ['çš„', 'äº†', 'æ˜¯', 'åœ¨', 'æœ‰', 'å’Œ', 'ä¸', 'æˆ–', 'ä½†', 'è€Œ', 'ä¹Ÿ', 'éƒ½', 'å¾ˆ', 'éå¸¸', 'è¿™', 'é‚£', 'è¿™ä¸ª', 'é‚£ä¸ª']):
                    filtered_keywords.append(keyword)
            
            # æŒ‰é‡è¦æ€§æ’åºï¼ˆæ›´å¸¸å‡ºç°çš„å…³é”®è¯ä¼˜å…ˆçº§æ›´é«˜ï¼‰
            keyword_counts = {}
            for keyword in filtered_keywords:
                keyword_counts[keyword] = text.lower().count(keyword.lower())
            
            sorted_keywords = sorted(filtered_keywords, key=lambda x: keyword_counts[x], reverse=True)
            
            logger.debug(f"æå–å…³é”®è¯ {len(sorted_keywords)} ä¸ª: {sorted_keywords[:20]}")  # è®°å½•å‰20ä¸ª
            return sorted_keywords[:50]  # è¿”å›å‰50ä¸ªæœ€é‡è¦çš„å…³é”®è¯
            
        except Exception as e:
            logger.error(f"å…³é”®è¯æå–å¤±è´¥: {e}")
            return []

    def _fast_rag_search_with_timeout(self, query_text: str, max_results: int, timeout: float, min_similarity: float = 0.5) -> str:
        """å¿«é€ŸRAGæœç´¢ï¼ˆå¸¦ä¸¥æ ¼è¶…æ—¶æ§åˆ¶å’Œçº¿ç¨‹ç®¡ç†ï¼‰"""
        import threading
        import queue
        import time
        
        # å¦‚æœæ­£åœ¨å…³é—­ï¼Œç›´æ¥è¿”å›
        if getattr(self, '_is_shutting_down', False):
            logger.debug("AIç®¡ç†å™¨æ­£åœ¨å…³é—­ï¼Œè·³è¿‡RAGæœç´¢")
            return ""
        
        result_queue = queue.Queue()
        thread_id = None
        
        def search_worker():
            """æœç´¢å·¥ä½œçº¿ç¨‹"""
            nonlocal thread_id
            thread_id = threading.current_thread().ident
            
            try:
                # æ·»åŠ åˆ°æ´»è·ƒçº¿ç¨‹é›†åˆ
                if hasattr(self, '_active_threads'):
                    self._active_threads.add(threading.current_thread())
                
                start_time = time.time()
                
                # æ£€æŸ¥æ˜¯å¦æ­£åœ¨å…³é—­
                if getattr(self, '_is_shutting_down', False):
                    result_queue.put(('shutdown', ""))
                    return
                
                # å¿«é€Ÿæ£€æŸ¥å‘é‡å­˜å‚¨çŠ¶æ€
                stats = self._vector_store.get_stats()
                if not stats or stats.get('total_documents', 0) == 0:
                    result_queue.put(('empty', ""))
                    return
                
                # åˆ›å»ºæŸ¥è¯¢å‘é‡ï¼ˆæœ€å¤§çš„æ€§èƒ½ç“¶é¢ˆï¼‰
                query_embedding = self._rag_service.create_embedding(query_text)
                if not query_embedding:
                    result_queue.put(('error', "æ— æ³•åˆ›å»ºæŸ¥è¯¢å‘é‡"))
                    return
                
                embedding_time = time.time() - start_time
                if embedding_time > timeout * 0.7:  # å¦‚æœembeddingå°±ç”¨äº†70%æ—¶é—´ï¼Œç›´æ¥è¿”å›
                    result_queue.put(('timeout', f"å‘é‡ç”Ÿæˆè€—æ—¶è¿‡é•¿: {embedding_time:.2f}s"))
                    return
                
                # å†æ¬¡æ£€æŸ¥æ˜¯å¦æ­£åœ¨å…³é—­
                if getattr(self, '_is_shutting_down', False):
                    result_queue.put(('shutdown', ""))
                    return
                
                # æ‰§è¡Œå‘é‡æœç´¢
                results = self._vector_store.similarity_search(
                    query_embedding,
                    limit=max_results,
                    min_similarity=min_similarity
                )
                
                if not results:
                    result_queue.put(('empty', ""))
                    return
                
                # æ„å»ºä¸Šä¸‹æ–‡
                context_parts = []
                for emb_data, score in results:
                    chunk_text = emb_data.get('chunk_text', '')
                    if chunk_text:
                        doc_id = emb_data.get('document_id', 'unknown')
                        part = f"[{doc_id[:8]}... ç›¸ä¼¼åº¦:{score:.2f}]\n{chunk_text[:200]}..."
                        context_parts.append(part)
                
                context = "\n---\n".join(context_parts)
                result_queue.put(('success', context))
                
            except Exception as e:
                result_queue.put(('error', str(e)))
            finally:
                # ä»æ´»è·ƒçº¿ç¨‹é›†åˆä¸­ç§»é™¤
                if hasattr(self, '_active_threads'):
                    try:
                        self._active_threads.discard(threading.current_thread())
                    except:
                        pass
        
        # å¯åŠ¨æœç´¢çº¿ç¨‹
        search_thread = threading.Thread(target=search_worker, daemon=True, name=f"RAGSearch-{time.time():.0f}")
        search_thread.start()
        
        # ç­‰å¾…ç»“æœ
        try:
            result_type, result_data = result_queue.get(timeout=timeout)
            
            if result_type == 'success':
                return result_data
            elif result_type == 'empty':
                logger.debug("RAGæœç´¢ç»“æœä¸ºç©º")
                return ""
            elif result_type == 'shutdown':
                logger.debug("RAGæœç´¢è¢«å…³é—­ä¿¡å·ä¸­æ–­")
                return ""
            elif result_type == 'timeout':
                logger.warning(f"RAGæœç´¢è¶…æ—¶: {result_data}")
                self._record_rag_timeout()
                return ""
            else:  # error
                logger.warning(f"RAGæœç´¢å¤±è´¥: {result_data}")
                return ""
                
        except queue.Empty:
            logger.warning(f"RAGæœç´¢ä¸¥æ ¼è¶…æ—¶ï¼ˆ{timeout}sï¼‰ï¼Œé¿å…é˜»å¡")
            self._record_rag_timeout()
            return ""
        finally:
            # ç¡®ä¿çº¿ç¨‹è¢«æ¸…ç†
            if search_thread.is_alive():
                logger.debug(f"ç­‰å¾…RAGæœç´¢çº¿ç¨‹ç»“æŸ: {search_thread.name}")
                search_thread.join(timeout=0.1)  # çŸ­æš‚ç­‰å¾…

    def _build_rag_context_non_blocking(self, current_text: str, cursor_position: int) -> str:
        """éé˜»å¡æ„å»ºRAGä¸Šä¸‹æ–‡ï¼ˆé˜²å¡æ­»ä¸“ç”¨ï¼Œå¸¦çº¿ç¨‹ç®¡ç†ï¼‰"""
        if not self._rag_service or not self._vector_store:
            return ""
        
        # å¦‚æœæ­£åœ¨å…³é—­ï¼Œç›´æ¥è¿”å›
        if getattr(self, '_is_shutting_down', False):
            logger.debug("AIç®¡ç†å™¨æ­£åœ¨å…³é—­ï¼Œè·³è¿‡éé˜»å¡RAGæœç´¢")
            return ""
        
        try:
            # è¶…ä¸¥æ ¼çš„æ€§èƒ½æ§åˆ¶
            if cursor_position > 3000:  # è¿›ä¸€æ­¥å‡å°‘æ–‡æœ¬é•¿åº¦é™åˆ¶
                logger.debug("æ–‡æœ¬è¿‡é•¿ï¼Œè·³è¿‡RAGæ£€ç´¢ï¼ˆé˜²å¡æ­»ï¼‰")
                return ""
            
            # æå–æçŸ­çš„æŸ¥è¯¢æ–‡æœ¬
            query_start = max(0, cursor_position - 30)  # åªå–30å­—ç¬¦
            query_text = current_text[query_start:cursor_position].strip()
            
            if not query_text or len(query_text) < 3:
                return ""
            
            # ä½¿ç”¨çº¿ç¨‹è¶…æ—¶æœºåˆ¶ï¼Œç»å¯¹ä¸å…è®¸é˜»å¡
            import threading
            import queue
            
            result_queue = queue.Queue()
            
            def ultra_quick_search():
                """è¶…å¿«é€Ÿæœç´¢çº¿ç¨‹"""
                try:
                    # æ·»åŠ åˆ°æ´»è·ƒçº¿ç¨‹é›†åˆ
                    if hasattr(self, '_active_threads'):
                        self._active_threads.add(threading.current_thread())
                    
                    # æ£€æŸ¥æ˜¯å¦æ­£åœ¨å…³é—­
                    if getattr(self, '_is_shutting_down', False):
                        result_queue.put(('shutdown', ""))
                        return
                    
                    # åªæœç´¢ä¸€ä¸ªç»“æœï¼Œæœ€å¿«è¿”å›
                    start_time = time.time()
                    
                    # ä½¿ç”¨æœ€å¿«çš„æœç´¢æ–¹å¼
                    if hasattr(self._vector_store, 'similarity_search_ultra_fast'):
                        result = self._vector_store.similarity_search_ultra_fast(query_text)
                    else:
                        # å¤‡ç”¨æ–¹æ¡ˆï¼šç®€å•çš„æ–‡æœ¬åŒ¹é…
                        result = self._simple_text_match(query_text)
                    
                    search_time = time.time() - start_time
                    
                    if search_time > 0.2:  # å¦‚æœæœç´¢è¶…è¿‡200msï¼Œè®°å½•ä¸ºæ…¢æŸ¥è¯¢
                        logger.warning(f"RAGæœç´¢è¾ƒæ…¢: {search_time:.2f}ç§’")
                    
                    result_queue.put(('success', result))
                except Exception as e:
                    result_queue.put(('error', str(e)))
                finally:
                    # ä»æ´»è·ƒçº¿ç¨‹é›†åˆä¸­ç§»é™¤
                    if hasattr(self, '_active_threads'):
                        try:
                            self._active_threads.discard(threading.current_thread())
                        except:
                            pass
            
            # å¯åŠ¨è¶…å¿«é€Ÿæœç´¢çº¿ç¨‹
            search_thread = threading.Thread(target=ultra_quick_search, daemon=True, name=f"NonBlockRAG-{time.time():.0f}")
            search_thread.start()
            
            # ç­‰å¾…ç»“æœï¼Œä¸¥æ ¼200msè¶…æ—¶
            try:
                result_type, result_data = result_queue.get(timeout=0.2)
                
                if result_type == 'success' and result_data:
                    # æˆåŠŸè·å–ç»“æœï¼Œå¿«é€Ÿè¿”å›
                    context = result_data[:100] if len(result_data) > 100 else result_data
                    logger.debug(f"éé˜»å¡RAGæˆåŠŸ: {len(context)} å­—ç¬¦")
                    return f"\n\nå‚è€ƒ: {context}"
                elif result_type == 'shutdown':
                    logger.debug("éé˜»å¡RAGæœç´¢è¢«å…³é—­ä¿¡å·ä¸­æ–­")
                    return ""
                    
            except queue.Empty:
                # è¶…æ—¶äº†ï¼Œè®°å½•å¹¶è·³è¿‡
                logger.warning("RAGæœç´¢è¶…æ—¶ï¼ˆ200msï¼‰ï¼Œé¿å…å¡æ­»")
                self._record_rag_timeout()
                return ""
            finally:
                # ç¡®ä¿çº¿ç¨‹è¢«æ¸…ç†
                if search_thread.is_alive():
                    search_thread.join(timeout=0.05)  # çŸ­æš‚ç­‰å¾…
            
            return ""
            
        except Exception as e:
            logger.error(f"éé˜»å¡RAGæ„å»ºå¤±è´¥: {e}")
            # è®°å½•å¤±è´¥æ—¶é—´ï¼Œé¿å…é‡å¤å°è¯•
            self._record_rag_timeout()
            return ""
        
        try:
            import time
            start_time = time.time()
            
            # æä¸¥æ ¼çš„æ€§èƒ½å’Œé•¿åº¦é™åˆ¶
            if cursor_position > 5000:  # è¿›ä¸€æ­¥é™ä½æ–‡æœ¬å¤„ç†é•¿åº¦
                logger.debug("æ–‡æœ¬è¿‡é•¿ï¼ˆ>5000å­—ç¬¦ï¼‰ï¼Œè·³è¿‡RAGæ£€ç´¢ä»¥é¿å…é˜»å¡")
                return ""
            
            # æå–æ›´çŸ­çš„æŸ¥è¯¢æ–‡æœ¬ï¼Œå‡å°‘å¤„ç†é‡
            query_start = max(0, cursor_position - 50)  # è¿›ä¸€æ­¥å‡å°‘åˆ°50å­—ç¬¦
            query_text = current_text[query_start:cursor_position].strip()
            
            if not query_text or len(query_text) < 3:  # é™ä½æœ€å°é•¿åº¦
                return ""
            
            # è®¾ç½®ä¸¥æ ¼çš„è¶…æ—¶æ£€æŸ¥
            def timeout_check():
                elapsed = time.time() - start_time
                if elapsed > 0.5:  # 500msä¸¥æ ¼è¶…æ—¶
                    raise TimeoutError(f"RAGæ£€ç´¢è¶…æ—¶: {elapsed:.2f}ç§’")
                return elapsed
            
            # å¿«é€Ÿæ£€æŸ¥å‘é‡å­˜å‚¨çŠ¶æ€
            timeout_check()
            try:
                stats = self._vector_store.get_stats()
                if not stats or stats.get('total_documents', 0) == 0:
                    logger.debug("å‘é‡å­˜å‚¨ä¸ºç©ºï¼Œè·³è¿‡RAGæ£€ç´¢")
                    return ""
            except Exception as e:
                logger.debug(f"å‘é‡å­˜å‚¨çŠ¶æ€æ£€æŸ¥å¤±è´¥: {e}")
                return ""
            
            # éé˜»å¡æ–¹å¼ï¼šåªå°è¯•ä¸€æ¬¡ï¼Œç«‹å³å¤±è´¥
            timeout_check()
            try:
                # ä½¿ç”¨æœ€å¿«çš„æœç´¢é…ç½®
                rag_context = self._search_similar_content_fast(query_text, max_results=1)
                
                # æœ€ç»ˆè¶…æ—¶æ£€æŸ¥
                timeout_check()
                
                if rag_context and len(rag_context) < 200:  # ä¸¥æ ¼é™åˆ¶è¿”å›é•¿åº¦
                    logger.debug(f"éé˜»å¡RAGæ£€ç´¢æˆåŠŸ: {len(rag_context)} å­—ç¬¦ï¼Œç”¨æ—¶ {time.time() - start_time:.3f}ç§’")
                    return f"\n\nå‚è€ƒ: {rag_context[:150]}..."  # æˆªæ–­åˆ°150å­—ç¬¦
                
            except TimeoutError:
                logger.warning("RAGæ£€ç´¢è¶…æ—¶ï¼Œè·³è¿‡ä»¥é¿å…é˜»å¡")
                return ""
            except Exception as e:
                logger.debug(f"éé˜»å¡RAGæ£€ç´¢å¤±è´¥: {e}")
                return ""
            
            return ""
            
        except Exception as e:
            logger.debug(f"éé˜»å¡RAGæ„å»ºå¤±è´¥: {e}")
            return ""
    
    def _search_similar_content_fast(self, query: str, max_results: int = 1) -> str:
        """è¶…å¿«é€Ÿç›¸ä¼¼å†…å®¹æœç´¢ï¼ˆä¸“ä¸ºéé˜»å¡è®¾è®¡ï¼‰"""
        if not self._rag_service or not self._vector_store:
            return ""
        
        import time
        start_time = time.time()
        
        try:
            # æä¸¥æ ¼çš„æ€§èƒ½é™åˆ¶
            if len(query) > 200:
                query = query[:200]
            
            max_results = 1  # å¼ºåˆ¶åªè¿”å›1ä¸ªç»“æœ
            
            # å¿«é€Ÿåˆ›å»ºæŸ¥è¯¢å‘é‡ï¼ˆå¸¦è¶…æ—¶ï¼‰
            query_embedding = None
            try:
                # è¿™é‡Œå¯èƒ½éœ€è¦ç½‘ç»œè¯·æ±‚ï¼Œæ˜¯ä¸»è¦çš„é˜»å¡ç‚¹
                query_embedding = self._rag_service.create_embedding(query)
                
                # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
                if time.time() - start_time > 0.3:  # 300msè¶…æ—¶
                    logger.warning("åˆ›å»ºæŸ¥è¯¢å‘é‡è¶…æ—¶ï¼Œæ”¾å¼ƒæœç´¢")
                    return ""
                    
            except Exception as e:
                logger.debug(f"åˆ›å»ºæŸ¥è¯¢å‘é‡å¤±è´¥: {e}")
                return ""
            
            if not query_embedding:
                return ""
            
            # è¶…å¿«é€Ÿå‘é‡æœç´¢ï¼ˆé™åˆ¶å¤„ç†é‡ï¼‰
            try:
                results = self._vector_store.similarity_search(
                    query_embedding,
                    limit=1,  # åªè¦1ä¸ªç»“æœ
                    min_similarity=0.4  # æé«˜æœ€å°ç›¸ä¼¼åº¦ï¼Œå‡å°‘è®¡ç®—é‡
                )
                
                # å†æ¬¡æ£€æŸ¥è¶…æ—¶
                if time.time() - start_time > 0.4:  # 400msæ€»è¶…æ—¶
                    logger.warning("å‘é‡æœç´¢è¶…æ—¶ï¼Œè¿”å›ç©ºç»“æœ")
                    return ""
                
            except Exception as e:
                logger.debug(f"å‘é‡æœç´¢å¤±è´¥: {e}")
                return ""
            
            # å¿«é€Ÿæ„å»ºç»“æœ
            if results:
                emb_data, score = results[0]
                chunk_text = emb_data.get('chunk_text', '')
                if chunk_text and len(chunk_text) > 10:
                    # åªè¿”å›å‰100å­—ç¬¦ï¼Œå‡å°‘åç»­å¤„ç†
                    return chunk_text[:100]
            
            return ""
            
        except Exception as e:
            logger.error(f"å¿«é€Ÿæœç´¢å¤±è´¥: {e}")
            return ""

    def _build_rag_context_fast(self, current_text: str, cursor_position: int) -> str:
        """å¿«é€Ÿæ„å»ºRAGä¸Šä¸‹æ–‡ï¼ˆä¸“ä¸ºæ€§èƒ½ä¼˜åŒ–ï¼‰"""
        if not self._rag_service or not self._vector_store:
            return ""
        
        try:
            # æå…¶ä¸¥æ ¼çš„æ€§èƒ½é™åˆ¶
            if cursor_position > 10000:  # è¿›ä¸€æ­¥é™ä½å¤„ç†çš„æ–‡æœ¬é•¿åº¦é™åˆ¶
                logger.debug("æ–‡æœ¬è¿‡é•¿ï¼Œè·³è¿‡RAGæ£€ç´¢")
                return ""
            
            # æå–æ›´çŸ­çš„æŸ¥è¯¢æ–‡æœ¬
            query_start = max(0, cursor_position - 100)  # å‡å°‘åˆ°100å­—ç¬¦
            query_text = current_text[query_start:cursor_position].strip()
            
            if not query_text or len(query_text) < 5:  # é™ä½æœ€å°é•¿åº¦è¦æ±‚
                return ""
            
            # éé˜»å¡æ–¹å¼ï¼šåªå°è¯•ä¸€æ¬¡ï¼Œä¸ç­‰å¾…
            try:
                # ä½¿ç”¨æ›´å¿«çš„æœç´¢ï¼Œåªè¦1ä¸ªç»“æœ
                rag_context = self.search_similar_content(query_text, max_results=1)
                
                if rag_context and len(rag_context) < 500:  # é™åˆ¶è¿”å›å†…å®¹é•¿åº¦
                    logger.debug(f"å¿«é€ŸRAGæ£€ç´¢æˆåŠŸ: {len(rag_context)} å­—ç¬¦")
                    return f"\n\nå‚è€ƒ: {rag_context[:300]}..."  # æˆªæ–­åˆ°300å­—ç¬¦
                
            except Exception as e:
                logger.debug(f"å¿«é€ŸRAGæ£€ç´¢å¤±è´¥: {e}")
            
            return ""
            
        except Exception as e:
            logger.debug(f"RAGå¿«é€Ÿæ„å»ºå¤±è´¥: {e}")
            return ""
    
    def build_rag_context(self, current_text: str, cursor_position: int) -> str:
        """æ„å»ºRAGå¢å¼ºçš„ä¸Šä¸‹æ–‡ï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼Œä½¿ç”¨å¿«é€Ÿç‰ˆæœ¬ï¼‰"""
        return self._build_rag_context_fast(current_text, cursor_position)
    
    def _quick_fallback_context(self, query_text: str) -> str:
        """å¿«é€Ÿé™çº§ä¸Šä¸‹æ–‡ç­–ç•¥ï¼ˆé¿å…å¤æ‚è®¡ç®—ï¼‰"""
        try:
            # è·å–å½“å‰é¡¹ç›®çš„æ‰€æœ‰æ–‡æ¡£
            if not hasattr(self.parent(), '_project_manager'):
                return ""
                
            project_manager = self.parent()._project_manager
            current_project = project_manager.get_current_project()
            if not current_project:
                return ""
            
            # ä½¿ç”¨æœ€ç®€å•çš„å…³é”®è¯åŒ¹é…ï¼Œé™åˆ¶å¤„ç†æ—¶é—´
            query_words = set(query_text.lower().split()[:10])  # åªå–å‰10ä¸ªè¯
            if not query_words:
                return ""
            
            found_content = []
            processed_docs = 0
            
            for doc_id, doc in current_project.documents.items():
                if processed_docs >= 5:  # æœ€å¤šå¤„ç†5ä¸ªæ–‡æ¡£
                    break
                    
                if not doc.content or len(doc.content) < 50:
                    continue
                    
                # åªæ£€æŸ¥æ–‡æ¡£çš„å‰1000å­—ç¬¦ï¼Œæé«˜æ€§èƒ½
                content_sample = doc.content[:1000].lower()
                
                # ç®€å•çš„å…³é”®è¯åŒ¹é…
                if any(word in content_sample for word in query_words if len(word) > 2):
                    # æå–ç›¸å…³æ®µè½ï¼ˆå‰200å­—ç¬¦ï¼‰
                    found_content.append(f"[{doc.name[:20]}] {doc.content[:200]}...")
                    if len(found_content) >= 2:  # æœ€å¤š2ä¸ªç»“æœ
                        break
                
                processed_docs += 1
            
            if found_content:
                logger.info(f"å¿«é€Ÿé™çº§æœç´¢æ‰¾åˆ° {len(found_content)} ä¸ªç›¸å…³æ–‡æ¡£")
                return "\n\nç›¸å…³å†…å®¹å‚è€ƒï¼š\n" + "\n---\n".join(found_content)
            else:
                return ""
                
        except Exception as e:
            logger.error(f"å¿«é€Ÿé™çº§ç­–ç•¥å¤±è´¥: {e}")
            return ""
    
    def get_index_stats(self):
        """è·å–ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯"""
        if not self._rag_service:
            return None
        return self._rag_service.get_index_stats()
    
    def clear_all_indexes(self) -> bool:
        """æ¸…ç©ºæ‰€æœ‰ç´¢å¼•"""
        if not self._rag_service:
            return False
        return self._rag_service.clear_all_indexes()
    
    def rebuild_all_indexes(self, documents: Dict[str, str]) -> bool:
        """é‡å»ºæ‰€æœ‰ç´¢å¼•ï¼ˆå¼‚æ­¥ï¼‰"""
        if not self._rag_service or not self._vector_store:
            return False
        
        # æ›´æ–°å¼‚æ­¥ç´¢å¼•å™¨çš„æœåŠ¡å¼•ç”¨
        self._async_indexer.set_services(self._rag_service, self._vector_store, self._config)
        
        # å°†æ‰¹é‡æ–‡æ¡£åŠ å…¥å¼‚æ­¥ç´¢å¼•é˜Ÿåˆ—
        self._async_indexer.queue_batch_index(documents)
        logger.info(f"æ‰¹é‡é‡å»ºç´¢å¼•å·²æäº¤å¼‚æ­¥å¤„ç†: {len(documents)} ä¸ªæ–‡æ¡£")
        return True
    
    def rebuild_all_indexes_sync(self, documents: Dict[str, str]) -> bool:
        """é‡å»ºæ‰€æœ‰ç´¢å¼•ï¼ˆåŒæ­¥ï¼‰"""
        if not self._rag_service:
            return False
        return self._rag_service.rebuild_index_for_documents(documents)
    
    def show_index_manager(self, parent=None, project_manager=None):
        """æ˜¾ç¤ºç´¢å¼•ç®¡ç†å¯¹è¯æ¡†"""
        try:
            from .index_manager_dialog import IndexManagerDialog
            
            dialog = IndexManagerDialog(
                parent=parent,
                ai_manager=self,
                project_manager=project_manager
            )
            dialog.exec()
            
        except Exception as e:
            logger.error(f"æ˜¾ç¤ºç´¢å¼•ç®¡ç†å¯¹è¯æ¡†å¤±è´¥: {e}")
            from PyQt6.QtWidgets import QMessageBox
            QMessageBox.critical(
                parent, "é”™è¯¯", 
                f"æ— æ³•æ‰“å¼€ç´¢å¼•ç®¡ç†å¯¹è¯æ¡†ï¼š{str(e)}"
            )
    
    def show_batch_index_dialog(self, parent=None, project_manager=None):
        """æ˜¾ç¤ºæ‰¹é‡ç´¢å¼•å¯¹è¯æ¡†"""
        try:
            from .batch_index_dialog import BatchIndexDialog
            
            dialog = BatchIndexDialog(
                parent=parent,
                ai_manager=self,
                project_manager=project_manager
            )
            dialog.exec()
            
        except Exception as e:
            logger.error(f"æ˜¾ç¤ºæ‰¹é‡ç´¢å¼•å¯¹è¯æ¡†å¤±è´¥: {e}")
            from PyQt6.QtWidgets import QMessageBox
            QMessageBox.critical(
                parent, "é”™è¯¯", 
                f"æ— æ³•æ‰“å¼€æ‰¹é‡ç´¢å¼•å¯¹è¯æ¡†ï¼š{str(e)}"
            )
    
    def force_reinit_ai(self):
        """å¼ºåˆ¶é‡æ–°åˆå§‹åŒ–AIå®¢æˆ·ç«¯ï¼ˆç”¨äºè°ƒè¯•å’Œæ¢å¤ï¼‰"""
        logger.info("å¼ºåˆ¶é‡æ–°åˆå§‹åŒ–AIå®¢æˆ·ç«¯")
        
        # æ¸…ç†æ—§çš„AIå®¢æˆ·ç«¯
        if self._ai_client:
            try:
                self._ai_client.cleanup()
            except:
                pass
            self._ai_client = None
        
        # é‡æ–°åˆå§‹åŒ–
        self._init_ai_client()
        return self._ai_client is not None
    
    def get_performance_settings(self) -> Dict[str, Any]:
        """è·å–å½“å‰æ€§èƒ½è®¾ç½®"""
        return {
            'debounce_delay': self._debounce_delay,
            'throttle_interval': self._throttle_interval,
            'min_trigger_chars': self._min_trigger_chars,
            'completion_enabled': self._completion_enabled,
            'auto_trigger_enabled': self._auto_trigger_enabled,
            'last_completion_time': self._last_completion_time
        }
    
    def update_performance_settings(self, settings: Dict[str, Any]):
        """æ›´æ–°æ€§èƒ½è®¾ç½®"""
        if 'debounce_delay' in settings:
            self._debounce_delay = max(500, settings['debounce_delay'])  # æœ€å°500ms
        
        if 'throttle_interval' in settings:
            self._throttle_interval = max(1000, settings['throttle_interval'])  # æœ€å°1ç§’
        
        if 'min_trigger_chars' in settings:
            self._min_trigger_chars = max(1, settings['min_trigger_chars'])
        
        logger.info(f"æ€§èƒ½è®¾ç½®å·²æ›´æ–°: é˜²æŠ–{self._debounce_delay}ms, èŠ‚æµ{self._throttle_interval}ms")
    
    def get_ai_status(self):
        """è·å–AIæœåŠ¡çŠ¶æ€ï¼ˆå¢å¼ºç‰ˆæœ¬ï¼‰"""
        current_time = time.time() * 1000
        time_since_last_completion = current_time - self._last_completion_time
        
        return {
            'ai_client_available': self._ai_client is not None,
            'rag_service_available': self._rag_service is not None,
            'vector_store_available': self._vector_store is not None,
            'completion_enabled': self._completion_enabled,
            'auto_trigger_enabled': self._auto_trigger_enabled,
            'performance': {
                'debounce_delay': self._debounce_delay,
                'throttle_interval': self._throttle_interval,
                'time_since_last_completion': time_since_last_completion,
                'throttle_active': time_since_last_completion < self._throttle_interval
            }
        }
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        if self._rag_service:
            return self._rag_service.get_cache_stats()
        else:
            return {"enabled": False}
    
    def clear_cache(self):
        """æ¸…ç©ºç¼“å­˜"""
        if self._rag_service:
            self._rag_service.clear_cache()
            logger.info("ç¼“å­˜å·²æ¸…ç©º")
    
    def cleanup_cache(self):
        """æ¸…ç†è¿‡æœŸç¼“å­˜"""
        if self._rag_service:
            self._rag_service.cleanup_cache()
            logger.info("è¿‡æœŸç¼“å­˜å·²æ¸…ç†")
    
    def force_reinit_rag(self):
        """å¼ºåˆ¶é‡æ–°åˆå§‹åŒ–RAGæœåŠ¡ï¼ˆç”¨äºè°ƒè¯•ï¼‰"""
        logger.info("å¼ºåˆ¶é‡æ–°åˆå§‹åŒ–RAGæœåŠ¡")
        
        # å…³é—­æ—§çš„RAGæœåŠ¡
        if self._rag_service:
            self._rag_service.close()
        
        self._rag_service = None
        self._vector_store = None
        self._init_rag_service()
        
        # æ›´æ–°å¼‚æ­¥ç´¢å¼•å™¨çš„æœåŠ¡å¼•ç”¨
        if self._async_indexer:
            self._async_indexer.set_services(self._rag_service, self._vector_store, self._config)
            
        return self._rag_service is not None
    
    # å¼‚æ­¥ç´¢å¼•ä¿¡å·å¤„ç†æ–¹æ³•
    @pyqtSlot(str)
    def _on_async_index_started(self, document_id: str):
        """å¼‚æ­¥ç´¢å¼•å¼€å§‹å¤„ç†"""
        logger.debug(f"å¼‚æ­¥ç´¢å¼•å¼€å§‹: {document_id}")
        
        # å¯ä»¥åœ¨è¿™é‡Œæ›´æ–°UIçŠ¶æ€ï¼Œæ¯”å¦‚æ˜¾ç¤ºè¿›åº¦æŒ‡ç¤ºå™¨
        if hasattr(self.parent(), 'statusBar'):
            self.parent().statusBar().showMessage(f"æ­£åœ¨ç´¢å¼•æ–‡æ¡£: {document_id[:8]}...", 2000)
    
    @pyqtSlot(str, bool)
    def _on_async_index_completed(self, document_id: str, success: bool):
        """å¼‚æ­¥ç´¢å¼•å®Œæˆå¤„ç†"""
        if success:
            logger.info(f"å¼‚æ­¥ç´¢å¼•å®Œæˆ: {document_id}")
            # æ›´æ–°UIçŠ¶æ€
            if hasattr(self.parent(), 'statusBar'):
                self.parent().statusBar().showMessage(f"æ–‡æ¡£ç´¢å¼•å®Œæˆ: {document_id[:8]}...", 1000)
        else:
            logger.error(f"å¼‚æ­¥ç´¢å¼•å¤±è´¥: {document_id}")
            if hasattr(self.parent(), 'statusBar'):
                self.parent().statusBar().showMessage(f"æ–‡æ¡£ç´¢å¼•å¤±è´¥: {document_id[:8]}...", 3000)
    
    @pyqtSlot(int, int)
    def _on_async_batch_completed(self, success_count: int, total_count: int):
        """å¼‚æ­¥æ‰¹é‡ç´¢å¼•å®Œæˆå¤„ç†"""
        logger.info(f"æ‰¹é‡å¼‚æ­¥ç´¢å¼•å®Œæˆ: {success_count}/{total_count}")
        
        # æ›´æ–°UIçŠ¶æ€
        if hasattr(self.parent(), 'statusBar'):
            message = f"æ‰¹é‡ç´¢å¼•å®Œæˆ: {success_count}/{total_count} ä¸ªæ–‡æ¡£"
            self.parent().statusBar().showMessage(message, 5000)
    
    def cleanup(self):
        """æ¸…ç†èµ„æº - æé€Ÿç‰ˆæœ¬ï¼Œé¿å…ä»»ä½•å»¶è¿Ÿ"""
        logger.info("å¼€å§‹æ¸…ç†AIç®¡ç†å™¨èµ„æºï¼ˆæé€Ÿæ¨¡å¼ï¼‰")
        
        # ç«‹å³è®¾ç½®å…³é—­æ ‡å¿—
        self._is_shutting_down = True
        
        # ç¬¬ä¸€æ­¥ï¼šç«‹å³åœæ­¢æ‰€æœ‰å®šæ—¶å™¨ï¼ˆé˜²æ­¢æ–°ä»»åŠ¡å¯åŠ¨ï¼‰
        if hasattr(self, '_completion_timer') and self._completion_timer:
            self._completion_timer.stop()
            self._completion_timer = None
        
        if hasattr(self, '_throttle_timer') and self._throttle_timer:
            self._throttle_timer.stop()
            self._throttle_timer = None
        
        logger.debug("æ‰€æœ‰å®šæ—¶å™¨å·²åœæ­¢")
        
        # ç¬¬äºŒæ­¥ï¼šæé€Ÿæ¸…ç†æ´»è·ƒçš„RAGæœç´¢çº¿ç¨‹
        if hasattr(self, '_active_threads') and self._active_threads:
            thread_count = len(self._active_threads)
            logger.info(f"å‘ç° {thread_count} ä¸ªæ´»è·ƒRAGçº¿ç¨‹ï¼Œå¼€å§‹æé€Ÿæ¸…ç†")
            
            # åˆ›å»ºæ´»è·ƒçº¿ç¨‹åˆ—è¡¨å¿«ç…§
            active_threads_snapshot = list(self._active_threads)
            
            # æé€Ÿç­–ç•¥ï¼šä¸ç­‰å¾…ï¼Œç›´æ¥è·³è¿‡æ‰€æœ‰çº¿ç¨‹
            for i, thread in enumerate(active_threads_snapshot):
                try:
                    thread_name = getattr(thread, 'name', f'Thread-{i}')
                    if thread.is_alive():
                        logger.debug(f"çº¿ç¨‹ {thread_name} ä»åœ¨è¿è¡Œï¼Œç›´æ¥è·³è¿‡ï¼ˆæé€Ÿæ¨¡å¼ï¼‰")
                    else:
                        logger.debug(f"çº¿ç¨‹ {thread_name} å·²ç»“æŸ")
                except Exception as e:
                    logger.debug(f"æ£€æŸ¥çº¿ç¨‹çŠ¶æ€æ—¶å‡ºé”™: {e}")
            
            # å¼ºåˆ¶æ¸…ç©ºæ´»è·ƒçº¿ç¨‹é›†åˆ
            self._active_threads.clear()
            logger.info(f"RAGçº¿ç¨‹æ¸…ç†å®Œæˆï¼ˆæé€Ÿæ¨¡å¼ï¼‰ï¼šè·³è¿‡ {thread_count} ä¸ªçº¿ç¨‹")
        
        # ç¬¬ä¸‰æ­¥ï¼šæ”¹è¿›å¼‚æ­¥ç´¢å¼•å·¥ä½œçº¿ç¨‹åœæ­¢
        if hasattr(self, '_async_indexer') and self._async_indexer:
            logger.info("åœæ­¢å¼‚æ­¥ç´¢å¼•å·¥ä½œçº¿ç¨‹ï¼ˆæé€Ÿæ¨¡å¼ï¼‰")
            try:
                # é¦–å…ˆè®¾ç½®åœæ­¢æ ‡å¿—å¹¶æ¸…ç©ºé˜Ÿåˆ—
                self._async_indexer.stop()
                
                # ä½¿ç”¨æ›´çŸ­çš„ç­‰å¾…æ—¶é—´ï¼Œä½†æ›´ä¼˜é›…çš„é€€å‡º
                if self._async_indexer.isRunning():
                    # ç¬¬ä¸€æ¬¡å°è¯•ï¼šä¼˜é›…é€€å‡ºï¼Œ50ms
                    if not self._async_indexer.wait(50):
                        logger.debug("ç¬¬ä¸€æ¬¡ç­‰å¾…50msè¶…æ—¶ï¼Œå°è¯•å¼ºåˆ¶ç»ˆæ­¢")
                        self._async_indexer.terminate()
                        # ç¬¬äºŒæ¬¡å°è¯•ï¼šå¼ºåˆ¶ç»ˆæ­¢åç­‰å¾…50ms
                        if not self._async_indexer.wait(50):
                            logger.warning("å¼‚æ­¥ç´¢å¼•çº¿ç¨‹å¼ºåˆ¶ç»ˆæ­¢è¶…æ—¶ï¼Œè·³è¿‡ç­‰å¾…")
                        else:
                            logger.debug("å¼‚æ­¥ç´¢å¼•çº¿ç¨‹å·²å¼ºåˆ¶ç»ˆæ­¢")
                    else:
                        logger.debug("å¼‚æ­¥ç´¢å¼•çº¿ç¨‹å·²æ­£å¸¸åœæ­¢")
                
                # æ–­å¼€æ‰€æœ‰ä¿¡å·è¿æ¥
                try:
                    self._async_indexer.blockSignals(True)
                    self._async_indexer.disconnect()
                except:
                    pass
                
                # æ ‡è®°ä¸ºåˆ é™¤
                self._async_indexer.deleteLater()
                self._async_indexer = None
                logger.debug("å¼‚æ­¥ç´¢å¼•çº¿ç¨‹æ¸…ç†å®Œæˆ")
                
            except Exception as e:
                logger.warning(f"åœæ­¢å¼‚æ­¥ç´¢å¼•çº¿ç¨‹æ—¶å‡ºé”™: {e}")
                # å³ä½¿å‡ºé”™ä¹Ÿè¦è®¾ç½®ä¸ºNoneï¼Œé˜²æ­¢é‡å¤æ¸…ç†
                self._async_indexer = None
        
        # ç¬¬å››æ­¥ï¼šå¿«é€Ÿæ¸…ç†UIç»„ä»¶
        ui_cleanup_start = time.time() * 1000
        
        if self._completion_widget:
            try:
                self._completion_widget.hide()
                self._completion_widget.deleteLater()
                self._completion_widget = None
            except Exception as e:
                logger.debug(f"æ¸…ç†è¡¥å…¨ç»„ä»¶æ—¶å‡ºé”™: {e}")

        if self._stream_widget:
            try:
                self._stream_widget.hide()
                self._stream_widget.deleteLater()
                self._stream_widget = None
            except Exception as e:
                logger.debug(f"æ¸…ç†æµå¼ç»„ä»¶æ—¶å‡ºé”™: {e}")

        if self._config_dialog:
            try:
                self._config_dialog.deleteLater()
                self._config_dialog = None
            except Exception as e:
                logger.debug(f"æ¸…ç†é…ç½®å¯¹è¯æ¡†æ—¶å‡ºé”™: {e}")
        
        ui_cleanup_time = time.time() * 1000 - ui_cleanup_start
        logger.debug(f"UIç»„ä»¶æ¸…ç†å®Œæˆï¼Œç”¨æ—¶: {ui_cleanup_time:.1f}ms")

        # ç¬¬äº”æ­¥ï¼šæ¸…ç†AIå®¢æˆ·ç«¯å’ŒRAGæœåŠ¡
        service_cleanup_start = time.time() * 1000
        
        if self._ai_client:
            try:
                logger.debug("å¼€å§‹æ¸…ç†AIå®¢æˆ·ç«¯ï¼ˆå¼ºåˆ¶æ¨¡å¼ï¼‰")
                # å¼ºåˆ¶æ¨¡å¼ï¼šç«‹å³å–æ¶ˆæ‰€æœ‰æ´»è·ƒè¯·æ±‚
                if hasattr(self._ai_client, 'cancel_request'):
                    self._ai_client.cancel_request()
                # æ‰§è¡Œæ¸…ç†
                self._ai_client.cleanup()
                self._ai_client = None
                logger.debug("AIå®¢æˆ·ç«¯æ¸…ç†å®Œæˆ")
            except Exception as e:
                logger.debug(f"æ¸…ç†AIå®¢æˆ·ç«¯æ—¶å‡ºé”™: {e}")
                # å³ä½¿å‡ºé”™ä¹Ÿè¦è®¾ç½®ä¸ºNone
                self._ai_client = None
        
        if hasattr(self, '_rag_service') and self._rag_service:
            try:
                if hasattr(self._rag_service, 'close'):
                    self._rag_service.close()
                self._rag_service = None
            except Exception as e:
                logger.debug(f"æ¸…ç†RAGæœåŠ¡æ—¶å‡ºé”™: {e}")
                self._rag_service = None
        
        if hasattr(self, '_vector_store') and self._vector_store:
            try:
                if hasattr(self._vector_store, 'close'):
                    self._vector_store.close()
                self._vector_store = None
            except Exception as e:
                logger.debug(f"æ¸…ç†å‘é‡å­˜å‚¨æ—¶å‡ºé”™: {e}")
                self._vector_store = None
        
        service_cleanup_time = time.time() * 1000 - service_cleanup_start
        logger.debug(f"æœåŠ¡ç»„ä»¶æ¸…ç†å®Œæˆï¼Œç”¨æ—¶: {service_cleanup_time:.1f}ms")

        total_cleanup_time = ui_cleanup_time + service_cleanup_time
        logger.info(f"AIç®¡ç†å™¨èµ„æºæ¸…ç†å®Œæˆï¼ˆæé€Ÿæ¨¡å¼ï¼‰ï¼Œæ€»ç”¨æ—¶: {total_cleanup_time:.1f}ms")


class OutlineAnalysisExtension(QObject):
    """å¤§çº²åˆ†ææ‰©å±• - é›†æˆåˆ°AIç®¡ç†å™¨ä¸­çš„å¤§çº²åŠŸèƒ½"""
    
    # å¤§çº²ä¸“ç”¨ä¿¡å·
    outlineAnalysisCompleted = pyqtSignal(str, str)  # (analysis_result, original_text)
    outlineAnalysisError = pyqtSignal(str)           # (error_message)
    outlineSuggestionsReady = pyqtSignal(list)       # (suggestions)
    
    def __init__(self, ai_manager):
        super().__init__(ai_manager)
        self.ai_manager = ai_manager
        self._init_prompt_manager()
        
        logger.info("å¤§çº²åˆ†ææ‰©å±•å·²åˆå§‹åŒ–")
    
    def _init_prompt_manager(self):
        """åˆå§‹åŒ–æç¤ºè¯ç®¡ç†å™¨"""
        try:
            from core.outline_prompts import OutlinePromptManager
            self.prompt_manager = OutlinePromptManager()
            logger.debug("å¤§çº²æç¤ºè¯ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        except ImportError as e:
            logger.warning(f"æ— æ³•å¯¼å…¥å¤§çº²æç¤ºè¯ç®¡ç†å™¨: {e}")
            self.prompt_manager = None
    
    def analyze_outline_structure(self, text: str, analysis_type: str = 'auto') -> str:
        """åˆ†æå¤§çº²ç»“æ„"""
        try:
            logger.info(f"å¼€å§‹å¤§çº²ç»“æ„åˆ†æï¼Œç±»å‹: {analysis_type}ï¼Œæ–‡æœ¬é•¿åº¦: {len(text)}")
            
            # æ„å»ºåˆ†ææç¤ºè¯
            if self.prompt_manager and hasattr(self.prompt_manager, 'format_prompt'):
                prompt_data = self.prompt_manager.format_prompt(
                    prompt_type='outline_analysis',
                    text=text,
                    analysis_type=analysis_type,
                    language="chinese"
                )
                
                if prompt_data:
                    prompt = f"{prompt_data.get('system', '')}\n\n{prompt_data.get('user', '')}"
                else:
                    prompt = self._get_fallback_analysis_prompt(text)
            else:
                prompt = self._get_fallback_analysis_prompt(text)
            
            # ä½¿ç”¨åŸºç¡€AIå®¢æˆ·ç«¯è¿›è¡ŒåŒæ­¥è°ƒç”¨
            response = self._call_ai_sync(prompt, max_tokens=1500, temperature=0.7)
            
            if response and len(response.strip()) > 20:
                logger.info(f"å¤§çº²åˆ†æå®Œæˆï¼Œç»“æœé•¿åº¦: {len(response)}")
                self.outlineAnalysisCompleted.emit(response, text)
                return response
            else:
                raise ValueError("AIè¿”å›ç»“æœè¿‡çŸ­æˆ–ä¸ºç©º")
                
        except Exception as e:
            error_msg = f"å¤§çº²ç»“æ„åˆ†æå¤±è´¥: {str(e)}"
            logger.error(error_msg)
            self.outlineAnalysisError.emit(error_msg)
            raise
    
    def suggest_outline_improvements(self, current_outline: str) -> List[str]:
        """å»ºè®®å¤§çº²æ”¹è¿›"""
        try:
            if not self.ai_manager._ai_client:
                raise RuntimeError("AIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            
            logger.info(f"ç”Ÿæˆå¤§çº²æ”¹è¿›å»ºè®®ï¼Œæ–‡æœ¬é•¿åº¦: {len(current_outline)}")
            
            # åˆ©ç”¨RAGæœç´¢ç›¸å…³é¡¹ç›®å†…å®¹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            rag_context = ""
            if self.ai_manager._rag_service:
                try:
                    similar_content = self.ai_manager.search_similar_content(current_outline[:500])  # é™åˆ¶æŸ¥è¯¢é•¿åº¦
                    if similar_content:
                        rag_context = f"\n\nç›¸å…³é¡¹ç›®å†…å®¹å‚è€ƒ:\n{similar_content[:300]}"
                        logger.debug("å·²è·å–RAGä¸Šä¸‹æ–‡ä¿¡æ¯")
                except Exception as rag_error:
                    logger.warning(f"RAGæœç´¢å¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€åˆ†æ: {rag_error}")
            
            # æ„å»ºæ”¹è¿›å»ºè®®æç¤ºè¯
            if self.prompt_manager and hasattr(self.prompt_manager, 'format_prompt'):
                prompt_data = self.prompt_manager.format_prompt(
                    prompt_type='outline_enhance',
                    text=current_outline + rag_context,
                    language="chinese"
                )
                if prompt_data:
                    prompt = f"{prompt_data.get('system', '')}\\n\\n{prompt_data.get('user', '')}"
                else:
                    prompt = self._get_fallback_improvement_prompt(current_outline, rag_context)
            else:
                prompt = self._get_fallback_improvement_prompt(current_outline, rag_context)
            
            # è°ƒç”¨AIç”Ÿæˆå»ºè®®
            response = self._call_ai_sync(prompt, max_tokens=800, temperature=0.8)
            
            if response:
                suggestions = self._parse_suggestions(response)
                logger.info(f"ç”Ÿæˆäº† {len(suggestions)} æ¡æ”¹è¿›å»ºè®®")
                self.outlineSuggestionsReady.emit(suggestions)
                return suggestions
            else:
                return []
                
        except Exception as e:
            error_msg = f"ç”Ÿæˆå¤§çº²æ”¹è¿›å»ºè®®å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            self.outlineAnalysisError.emit(error_msg)
            return []
    
    def generate_outline_continuation(self, existing_docs: List, generation_params: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆå¤§çº²ç»­å†™å†…å®¹ï¼ˆé›†æˆä¸Šä¸‹æ–‡æ„ŸçŸ¥ç”Ÿæˆå™¨ï¼‰"""
        try:
            if not self.ai_manager._ai_client:
                raise RuntimeError("AIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            
            logger.info(f"å¼€å§‹ç”Ÿæˆå¤§çº²ç»­å†™ï¼Œæ–‡æ¡£æ•°: {len(existing_docs)}")
            
            # ä½¿ç”¨ä¸Šä¸‹æ–‡æ„ŸçŸ¥ç”Ÿæˆå™¨
            from core.context_generator import ContextAwareOutlineGenerator, GenerationType, ContextScope
            generator = ContextAwareOutlineGenerator()
            
            # è§£æç”Ÿæˆå‚æ•°
            generation_type = GenerationType(generation_params.get('type', 'continuation'))
            context_scope = ContextScope(generation_params.get('scope', 'global'))
            target_length = generation_params.get('length', 3)
            
            # ç”Ÿæˆç»­å†™å†…å®¹
            generation_result = generator.generate_outline_continuation(
                existing_docs=existing_docs,
                generation_type=generation_type,
                context_scope=context_scope,
                target_length=target_length
            )
            
            logger.info(f"ç»­å†™ç”Ÿæˆå®Œæˆï¼Œè´¨é‡è¯„åˆ†: {generation_result.quality_score:.2f}")
            return {
                'generated_nodes': generation_result.generated_nodes,
                'context_analysis': generation_result.context_analysis,
                'generation_rationale': generation_result.generation_rationale,
                'quality_score': generation_result.quality_score,
                'suggestions': generation_result.continuation_suggestions
            }
            
        except Exception as e:
            error_msg = f"ç”Ÿæˆå¤§çº²ç»­å†™å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            self.outlineAnalysisError.emit(error_msg)
            return {'error': error_msg}
    
    def _get_fallback_improvement_prompt(self, outline: str, rag_context: str = "") -> str:
        """è·å–é™çº§æ”¹è¿›æç¤ºè¯"""
        return f"""è¯·ä¸ºä»¥ä¸‹å¤§çº²æä¾›å…·ä½“çš„æ”¹è¿›å»ºè®®ï¼š

å¤§çº²å†…å®¹ï¼š
{outline}

{rag_context}

è¯·ä»ä»¥ä¸‹è§’åº¦æä¾›å»ºè®®ï¼š
1. ç»“æ„å®Œæ•´æ€§
2. æƒ…èŠ‚å‘å±•
3. è§’è‰²å¡‘é€ 
4. èŠ‚å¥æ§åˆ¶
5. ä¸»é¢˜æ·±åŒ–

è¯·ä»¥åˆ—è¡¨å½¢å¼æä¾›5-8æ¡å…·ä½“å¯è¡Œçš„æ”¹è¿›å»ºè®®ã€‚"""
    
    def _call_ai_sync(self, prompt: str, **kwargs) -> str:
        """åŒæ­¥è°ƒç”¨AIå®¢æˆ·ç«¯"""
        try:
            # è·å–AIé…ç½®
            ai_config = self.ai_manager._config.get_ai_config()
            if not ai_config:
                raise RuntimeError("AIé…ç½®æœªæ‰¾åˆ°")
            
            # ä½¿ç”¨åŸºç¡€AIå®¢æˆ·ç«¯è¿›è¡ŒåŒæ­¥è°ƒç”¨
            from core.ai_client import AIClient
            with AIClient(ai_config) as client:
                response = client.complete(prompt=prompt, **kwargs)
                return response or ""
                
        except Exception as e:
            logger.error(f"åŒæ­¥AIè°ƒç”¨å¤±è´¥: {e}")
            raise
    
    def _get_fallback_analysis_prompt(self, text: str) -> str:
        """è·å–é™çº§åˆ†ææç¤ºè¯"""
        return f"""è¯·åˆ†æä»¥ä¸‹å¤§çº²çš„ç»“æ„å¹¶æä¾›ä¼˜åŒ–å»ºè®®ï¼š

{text}

è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œåˆ†æï¼š
1. ç»“æ„å®Œæ•´æ€§åˆ†æ
2. å†…å®¹å±‚æ¬¡æ¢³ç†
3. é€»è¾‘å…³ç³»æ£€æŸ¥
4. ä¼˜åŒ–æ”¹è¿›å»ºè®®

è¯·æä¾›è¯¦ç»†ä¸”å…·ä½“çš„åˆ†æç»“æœã€‚"""
    
    def _parse_suggestions(self, response: str) -> List[str]:
        """è§£æAIè¿”å›çš„å»ºè®®"""
        try:
            suggestions = []
            lines = response.strip().split('\n')
            
            for line in lines:
                line = line.strip()
                # è¯†åˆ«åˆ—è¡¨é¡¹
                if line and (line.startswith('â€¢') or line.startswith('-') or line.startswith('*') or 
                           any(line.startswith(f'{i}.') for i in range(1, 20))):
                    # æ¸…ç†æ ¼å¼ç¬¦å·
                    clean_line = line.lstrip('â€¢-*0123456789. ').strip()
                    if len(clean_line) > 10:  # è¿‡æ»¤å¤ªçŸ­çš„å»ºè®®
                        suggestions.append(clean_line)
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ—è¡¨æ ¼å¼ï¼ŒæŒ‰å¥å­åˆ†å‰²
            if not suggestions:
                sentences = response.replace('\n', ' ').split('ã€‚')
                for sentence in sentences:
                    sentence = sentence.strip()
                    if len(sentence) > 15:
                        suggestions.append(sentence + 'ã€‚')
            
            return suggestions[:8]  # é™åˆ¶å»ºè®®æ•°é‡
            
        except Exception as e:
            logger.warning(f"è§£æå»ºè®®å¤±è´¥: {e}")
            return [response[:200] + "..."] if response else []
